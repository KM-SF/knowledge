# 一. CAP原则

+ CAP定理又称CAP原则，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），最多只能同时三个特性中的两个，三者不可兼得。
+ **Consistency (一致性)**：更新操作成功并返回客户端后，所有节点在同一时间的数据完全一致，这就是分布式的一致性。一致性的问题在并发系统中不可避免，对于客户端来说，一致性指的是并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。
+ **Availability (可用性)**：服务一直可用，而且是正常响应时间。好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。
+ **Partition Tolerance (分区容错性)**：分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，对于用户而言并没有什么体验上的影响。

# 二. Base理论

BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网分布式系统实践的总结，是基于CAP定律逐步演化而来。**其核心思想是即使无法做到强一致性**，但每个应用都可以根据自身业务特点，才用适当的方式来使系统打到**最终一致性**。

+ 基本可用（Basically Available）
+ 软状态（Soft State）
+ 最终一致性（Eventually Consistent）

### 1. 基本可用

什么是基本可用呢？假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言：

+ **响应时间上的损失**：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果。
+ **功能上的损失**：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面

### 2. 软状态

什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种“硬状态”。

软状态指的是：允许系统中的数据存在**中间状态**，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。

### 3. 最终一致性

上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。

最终一致性分为5种：因果一致性，读己之所写，会话一致性，单调读一致性，单调写一致性

#### 3.1 因果一致性（Causal consistency）

因果一致性指的是：如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。

#### 3.2 读己之所写（Read your writes）

读己之所写指的是：节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。

#### 3.3 会话一致性（Session consistency）

会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。

#### 3.4 单调读一致性（Monotonic read consistency）

单调读一致性指的是：如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。

#### 3.5 单调写一致性（Monotonic write consistency）

单调写一致性指的是：一个系统要能够保证来自同一个节点的写操作被顺序的执行。

# 三. 强一致性算法 -- Paxos

### 1. Basic Paxos

+ Client：系统外部角色，请求发起者（像民众）
+ Proposer：接收Client请求，向集群提出提议（propose）。并再冲突发生时，起到冲突调解的作用。（像议员，替民众提出议案）
+ Acceptor（Voter）：提议投票和接收者，只有在形成法定人数（Quorum，一般即为majority多数派）时，提议才会最终被接收（像国会）
+ Learner：提议接受者，backup，备份，对集群一致性没有什么影响（像记录员）

### 2. 步骤

1. Prepare：proposer提出一个提案，编号为N。此时N大于这个proposer之前提出的提案编号。请求acceptors的大多数接受。
2. Promise：如果N大于此acceptor之前接受的任何提案编号则接受，否则拒绝。（一次只能接受一个提案，且以大的为主）
3. Accept：如果达到了多数派，proposer会发出accept请求，此请求包含提案编号N，且提案内容
4. Accepted：如果此acceptor在此期间没有收到任何编号大于N的提案，则接受此天内容，否则忽略

### 3. 问题

+ 活锁：
  + 由于有一个proposerA发起提案1给acceptor。acceptor超过半数同意告诉proposerA处理该提案，让proposerA把内容告诉acceptor。
  + 但是在proposerA告诉acceptor内容的时候，又有一个proposerB发起了提案2给acceptor。然后acceptor超过半数同意，此时的提案2的编号大于提案1，则放弃处理提案1而改成处理提案2。
  + proposerA发现提案1被拒绝了，又发起proposerA发起提案3（内容相同）。然后又出现上面的情况，一直死循环。
  + **解决方案：当proposerB发现提案发生冲突了，然后等待随机时间再提交提案。**
+ 难实现，且效率低（2轮RPC，一轮发起提案，一轮发送提案内容）

### 4. Multi Paxos

+ Leader：唯一的propser，所有请求都需要经过Leader
+ 需要有第一次提案，该提案的作用是选举Leader

# 四. 强一致性算法 -- Raft

+ **动画演示：http://thesecretlivesofdata.com/raft/**
+ 场景演示：https://raft.github.io/

### 1. 划分三个子问题：

+ 选举Leader
+ 日志同步到其他节点上（日志复制）
+ 所有节点的共识一致（分区共识）

### 2. 重定义角色：

+ Leader（一个集群只能有一个Leader）
+ Follower
+ Candidate（临时状态，当Leader挂了，需要重新选举Leader的时候。Follower改变成Candidate，然后参加竞选）

### 3. Leader选举过程：

+ 所有节点都有一个定时器（每个节点的定时器都是随机值）。该定时器表示收到Leader的心跳包。
+ 如果在定时器内没有收到Leader的心跳包，则自己变成Candidate状态，参与竞选Leader。（选举超时，自己当成候选者）
+ 然后所有任参与选票，候选者的投票只会投给自己，其他人则投给某个候选者（可能出现多个候选者情况）
+ 如果自己的票数过半，则成为新的Leader。
+ 如果此时有人跟自己一样同时竞选Leader，那么这两个人都会在起一个定时器（随机值），进行在一轮的选票

### 4. 日志同步过程：

+ 当leader接收到请求后，将该请求写到自己的日志中
+ leader将该请求发送给其他节点，要求其他节点也写到日志中
+ 其他节点将请求写到日志后，回一个ack给leader
+ leader统计有过半节点回复了ack后，将请求数据更新
+ leader发送请求给其他节点，要求其他节点将数据更新

### 5. 节点共识：

+ 集群5个节点，一开始1个leader和4个Follower
+ 然后网络出现问题，把1个leader和1个Follower划分为一个区A。而其他三个节点为另外一个区B
+ 另外三个节点为一个区A后，进行重新选举leader
+ 有个clientA向分区A发送请求，但是这个时候分区只有两个节点，没有超过半数所以该请求无效
+ 有个clientB向分区B发送器请求，有过半节点同意该请求，所以请求有效，更新数据
+ 当网络恢复后，出现了两个leaderA和leaderB。因为leaderB是新一代的leader，所以leaderA放弃做leader。并且将分区B的数据更新到分区A的每个节点上

+ 问题：一致性并不一定代表完全正确性！三个可能结果：成功，失败，unknown

# 强一致性算法 -- ZAB

+ 基本与raft相同
+ raft保证日志连续性，心跳方向为leader至Follower。ZAB则相反

------

参考：

https://baijiahao.baidu.com/s?id=1634401106583534524&wfr=spider&for=pc