### go的grpc相关的协议

grpc是远程调用的一个开源框架。远程调用一般分为三个核心功能：服务寻址，数据编解码，网络传输。

1. 服务寻址：我们要想远程调用像本地调用一样。就需要给提供的所有函数都提供一个唯一ID和对应服务端的ip和port。服务端保存这个ID和函数的映射关系。客户端通过ip和port建立连接进行远程调用时，需要将这个ID传递过来，然后服务端进行查找并调用
2. 数据编解码：客户端远程调用需要将对象序列化成二进制流，再通过网络传输。服务端也需要将二进制流反序列化成可识别的对象
3. 网络传输：客户端和服务端之间的通信协议。具体协议没有限制，可以是TCP，可以是HTTP等。

grpc的数据编解码使用的是：protobuf。网络传输使用的是http2.0

### go的协程和线程的区别，GMP模型

> 进程：是应用程序的启动实例，每个进程都有独立的内存空间，不同的进程通过进程间的通信方式来通信。
>
> 线程：从属于进程，每个进程至少包含一个线程，线程是 CPU 调度的基本单位，多个线程之间可以共享进程的资源并通过共享内存等线程间的通信方式来通信。
>
> 协程：为轻量级线程，与线程相比，协程不受操作系统的调度，协程的调度器由用户应用程序提供，协程调度器按照调度策略把协程调度到线程中运行

> +  **G（Goroutine）** : 每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数
>
> - **M（Machine）**: 对OS内核级线程的封装，数量对应真实的CPU数(真正干活的对象).
> - **P (Processor)**: 逻辑处理器,即为G和M的调度对象，用来调度G和M之间的关联关系，其数量可通过 GOMAXPROCS()来设置，默认为核心数。
>
> P和M是11关系，但是会存在M>=P的情况。G的创建会优先保存到P的本地队列上，如果P的本地队列已满则扔到全局队列。当一个G要执行时，则M上运行的goroutine切换为G0，G0负责调度时协程的切换，会优先从P的本地队列取到G，如果本地队列为空，则从全局队列或者其他P的队列偷取G，并开始运行G。

### go的匿名函数访问外部变量是复制还是引用

是引用

```go
func main() {
	i := 1
	f := func() {
		i = 2
	}
	f()
	fmt.Println(i) // 结果是2
}
```

### mysql的隔离级别

+ **读未提交**：所有事务都能够读取其他事务未提交的数据，会导致賍读、不可重复读、幻读
+ **读已提交**：所有事务只能读取其他事务已经提交的数据，可以解决賍读！但是会出现在一个事务中前后读取内容不一致的问题，即不可重复读、幻读
+ **可重复读**：在一个事务中，不允许Update操作，允许Add操作，因此能保证在一个事务中读取数据内容是一致的(能解决不可重复读，即对同一个数据多次读取的val都是一样的)，但是不能保证读取到数据条目数一致(会发生幻读)
+ **可串行化**：所有的事务都顺序串行执行，不存在冲突

### 默认隔离级别是哪个

可重复读

### innodb的主键和索引有什么区别

索引分为：聚簇索引和非聚餐索引，或者主键索引和辅助索引。而主键就是聚簇索引。

+ 聚簇索引：将数据存储与索引放到一块，索引结构的叶子节点保持行数据。1个表只能有1个聚簇索引。innodb一定会有聚簇索引，如果没有主键则用唯一键，如果没有唯一键则会自动生成自定id隐藏列作为聚簇索引
+ 非聚簇索引：将数据与索引分开存储，索引结构的叶子节点指向了数据对应的位置。又称为辅助索引或者二级索引

### 我要在mysql插入一个emoji表情 要用什么类型

用varchar可变长字符串

### 如果用varchar类型，有什么要注意的吗，会不会乱码什么的

mysql数据库的默认编码是UTF-8，普通字符是3个字节，然而emoji表情占用4个字节，UTF-8格式无法容纳

解决方式就是更改数据库的默认编码：**utf8mb4**是utf8的超集，能够在兼容utf8的前提下提供更强的包容性。

在mysql中查看到会是乱码，但是页面可以显示表情包

### mysql的快照（mysqldump）是什么

快照就是某一时刻：mysql中所有数据的备份，一般用于主从同步和备份数据用。

### redis有哪些类型

string，list，hash，set和zset

### zset的底层数据结构

zset底层数据结构是有两种：ziplist和跳表。当数据量比较少的时候用压缩链表，数据量超过一定阈值时用跳表

### 如果redis的内存满了，有什么应对措施

当内存满了会触发内存淘汰策略：

> noeviction：不淘汰任何数据，当内存不足时，执行新增操作会报错，默认策略
>
> allkeys-lru：淘汰整个键值中最久未使用的键值
>
> allkeys-lfu：淘汰整个键值中最少使用的键值
>
> allkeys-random：随机淘汰任意键值
>
> volatile-lru：淘汰所有设置了过期的键值中最久未使用的键值
>
> volatile-lfu：淘汰所有设置了过期的键值中最少使用的键值
>
> volatile-random：随机淘汰所有设置了过期的键值
>
> volatile-ttl：优先淘汰更短过期时间的键值

### 一个key设置了过期时间，那他是怎么过期的呢

key的过期删除分为两个策略：惰性删除和定期删除

+ 惰性过期：只有当访问一个key时，才会判断key是否过期，过期则清理。该策略可以最大化的节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被删除，占用大量内存。
+ 定期过期：每隔一定的时间，会扫描**一定数量**的数据库的expire字典中一定数量的key，并且清除其中过期的key。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使用CPU和内存资源达到最优的平衡效果

### 定时扫描的话，是拿所有key吗还是只拿一部分

https://www.cnblogs.com/bruceChan0018/p/15768823.html

不会拿所有key，而是会轮询数据库并且只拿一部分key进行扫描，这样做是为了避免cpu的突增。

### redis的持久化方式有什么

redis提供了两种持久化机制：RDB和AOF

RDB：保存某一时间点之前的快照数据。恢复数据时直接将快照数据解析到内存

AOF：指所有命令行记录以redis命令请求协议的格式完全持久保存在aof文件中。恢复数据时，则根据redis命令依次执行。

混合持久化：可以通过aof-use-rdb-preamble yes开启。rdb和aof混合的方式，aof文件的头部添加了rdb的数据

### aof如果过大怎么办

随着命令不断写入到AOF，文件会越来越大。为了解决这个问题，redis引入了AOF写入机制压缩文件大小。

AOF文件重写是把**redis进程内存的数据**转化为写命令同步到新AOF文件的过程。

AOF重写机制可以通过**手动触发（bgrewriteaof）**和**自动触发**

### 什么是幂等性

幂等性就是一个方法短时间内被多次调用，但是产生的结果和只调用一次的结果相同，那么这个操作就是幂等的。比如select操作天然幂等。

### 你们是怎么实现的

一般就是给这类消息带上一个全局的唯一id（我回答了用redis保存id，应该用mysql比较好）

### 如果并发情况下，可能会出现都读到id，你们怎么解决（我上面回答了用唯一id保证幂等性）

用set nx ex插入唯一id，如果插入成功就之前不存在，插入不成功则已经处理

### 除了唯一id能解决幂等性，还有什么方法吗

用cas加锁

### 分布式锁有什么方案

在目前分布式锁实现方案中，比较成熟、主流的方案有两种：

（1）基于Redis的分布式锁

（2）基于ZooKeeper的分布式锁

两种锁，分别适用的场景为：

（1）基于ZooKeeper的分布式锁，适用于高可靠（高可用）而并发量不是太大的场景；

（2）基于Redis的分布式锁，适用于并发量很大、性能要求很高的、而可靠性问题可以通过其他方案去弥补的场景。

### 说下zk的共识协议

zk的共识协议是用zab协议。就是三个模块：leader选举，数据同步和分区共识

> 选举过程：
>
> 1. 投票开始
> 2. 先临时投给自己
> 3. 跟别人进行交流
> 4. 比较后，选出更厉害的人
> 5. 将票投入到投票箱
> 6. 统计下每个主机的投票个数（过半则票数有效）
> 7. 投票结束
>
> 选择更厉害的人的方法：
>
> + 通过日志持久化的zxid，判断每个主机的zxid的大小。选出最大的
> + 如果日志zxid相同的话，就再通过每个主机myid，再从myid中选择最大的

> 数据同步：
>
> + leader节点将日志持久化
> + leader节点预提交（将日志持久化的操作发给其他节点）（2PC的预提交阶段）
> + 其他节点日志持久化成功后，回一个ack（2PC的ack阶段）
> + leader收到ack个数超过一半之后，提交commit给其他节点。（将数据更新到内存，数据持久化）（2PC的commit阶段）
> + leader收到ack个数超过一半之后，本主机执行commit。（将数据更新到内存，数据持久化）

### 什么是分布式事务

就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。

### 分布式事务的解决方案

https://blog.csdn.net/JavaShark/article/details/125350886

1. **两阶段提交方案/XA方案**
2. **TCC方案**

### 补偿机制怎么做

https://blog.csdn.net/ibigboy/article/details/118994071

主流的补偿方式就是两种：回滚(事务的补偿)，和重试

### kafka和RocketMQ的区别（不记得RocketMQ了，就介绍了kafka）

| 名称          | 解释                                                         |
| ------------- | ------------------------------------------------------------ |
| Broker        | 消息中间件处理阶节点，一个kafka节点就是一个broker，一个或者多个broker可以组成一个kafka集群 |
| Topic         | kafka根据topic对消息进行归类，发布到kafka集群的每条消息都需要指定一个topic |
| Producer      | 消息生产者，也就是发送消息的一方。生产者负责创建消息，然后将其投递到 Kafka中。 |
| Consumer      | 消息消费者，也就是接收消息的一方，从Broker读取消息的客户端。消费者连接到 Kafka 上并接收消息，进而进行相应的业务逻辑处理。 |
| ConsumerGroup | 每个consumer术语一个特定的ConsumerGroup，一个消息可以被多个不同的Consumer Group消费。但是一个Consumer Group只能有一个Consumer能够消费该消息 |
| partition     | 物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的 |

### linux的文件名是存储在哪里的

在 Linux 中，[元数据](https://so.csdn.net/so/search?q=元数据&spm=1001.2101.3001.7020)中的 inode 号(inode 是文件元数据的一部分但其并不包含文件名， inode 号即索引节点号)才是 文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过 inode 号寻找正确的文件数据块。

inode包含文件的元信息，具体来说有以下内容：

+ 文件的字节数
+ 文件拥有者的User ID
+ 文件的Group ID
+ 文件的读、写、执行权限
+ 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。
+ 硬链接数，即有多少文件名指向这个inode
+ 文件数据block的位置

在Linux操作系统中，目录就是目录文件。**目录项中存放文件名和一个指向索引节点的指针。**

### inode编号怎么跟文件名产生关系的

Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。

目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。

### tcp的4次断开

1. 客户端向服务器发送断开连接报文（客户端进入**FIN-WAIT-1**阶段），FIN标记位为1，seq为X（随机值）
2. 服务器收到客户端发来的断开连接报文后，发送确认报文（服务器结束**ESTABLISHEN**，进去**CLOSE-WAIT**阶段），ACK标记位位1，ack确认序号**X+1**，seq序号为Y随机值。客户端收到服务器回的的确认报文后，客户端进入**半关闭状态**（退出**FIN-WAIT-1**阶段，进入**FIN-WAIT-2**阶段）
3. 服务器发送断开连接报文（服务器退出**CLOSE-WAIT**阶段，进入**LAST-ACK**阶段）。FIN标记为为1，seq序号位为Z随机值。客户端收到服务器发送的断开连接报文后，客户端退出**FIN-WAIT-2**阶段，进入**TIME-WAIT**阶段
4. 客户端进入TIME-WAIT阶段时，会立即发送最后一个确认报文，ACK标记位为1，ack确认序号位**Z+1**。服务器收到客户端发送的确认报文后，退出**LAST-ACK**阶段，进入**CLOSED**阶段
5. 如果这个2MSL时间内服务器没有再一次发送FIN报文的话，那个2MSL时长 后，客户端退出TIME-WAIT阶段，进入**CLOSED**阶段

### 你对k8s了解吗，他里面的类型你知道什么