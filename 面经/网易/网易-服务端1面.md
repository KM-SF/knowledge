### 数组和切片的区别

**相同点：**

1. 只能存储一组相同类型的数据结构

2. 都是通过下标来访问，并且有容量长度，长度通过 len 获取，容量通过 cap 获取

**区别：**

1. 数组是定长，访问和复制不能超过数组定义的长度，否则就会下标越界，切片长度和容量可以自动扩容

2. 数组是值类型，切片是引用类型，每个切片都引用了一个底层数组，切片本身不能存储任何数据，都是这底层数组存储数据，所以修改切片的时候修改的是底层数组中的数据。切片一旦扩容，指向一个新的底层数组，内存地址也就随之改变

### 一个数组进行不同长度的两个切片，两个切片会互相影响吗

会互相影响，因为两个切片底层都是指向同一数组，所以会互相影响

```go
func main() {
	a := [10]int{}
	a1 := a[:5]
	a2 := a[:8]
	fmt.Println(a1, a2)
	a1[0] = 10
	fmt.Println(a1, a2)
	a2[0] = 100
	fmt.Println(a1, a2)
}
```

### 切片的扩容是在原来数组上变长还是重新分配一个

切片一旦扩容，指向一个新的底层数组（重新分配），内存地址也就随之改变

### make和new的区别

new 的参数要求传入一个类型，而不是一个值，它会申请该类型的内存大小空间，并初始化为对应的零值，返回该指向类型空间的一个指针

make 也用于内存分配，但它只用于引用对象 slice、map、channel的内存创建，返回的类型是类型本身

new 分配的空间被清零。make 分配空间后，会进行初始化；

### 介绍下defer

defer用来声明一个延迟函数，把这个函数放入到一个栈上，当外部的包含方法return之前，返回参数到调用方法之前调用，也可以说是运行到最外层方法体时调用

### 一般哪些场景下会用defer

1. 可以用来释放资源
2. 可以在defer中捕获下panic，防止进程因为panic崩溃
3. 可以用来统计该函数的运行时间

### 一个函数有多个defer，那运行的顺序

一个函数中含有有多个 defer，调用顺序采用压栈式执行，后入先出（LIFO）。

### go之间的通信方式，官方推荐用什么

Go 语言采用了 CSP 模式。这是一种用于描述两个独立的并发实体通过共享的通讯 Channel（管道）进行通信的并发模型。

Go语言的CSP模型是由协程Goroutine与通道Channel实现：

### 往一个只读的chan写入，结果会怎么样

会无法写入，编译不通过

### 往一个关闭的chan读的话，那会读到什么

从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值 

### 往一个关闭的chan写入，结果会怎么样

给一个已经关闭的 channel 发送数据，引起 panic 

### 介绍select

select 为 golang 提供了多路 IO 复用机制，和其他 IO 复用一样，用于检测是否有读写事件是否 ready。linux 的系统 IO 模型有 select，poll，epoll，go 的 select 和 linux 系统 select 非常相似。

select 结构组成主要是由 case 语句和执行的函数组成 select 实现的多路复用是：每个线程或者进程都先到注册和接受的 channel（装置）注册，然后阻塞，然后只有一个线程在运输，当注册的线程和进程准备好数据后，装置会根据注册的信息得到相应的数据。

### select有多个case的话，那是触发哪个case

多个 case 语句的执行顺序是随机的。

### 如果select里面没有一个case，但是需要一个默认的处理方式要怎么写

可以有default语句，默认处理。这样select就不会阻塞，但是对性能有影响

### 如果一个空的select，那会发生什么

会引发死锁，整个进程卡主，然后panic。

### sync.waitgroup一般是用来干嘛的

用于阻塞等待一组 Go 程的结束。

主 Go 程调用 Add() 来设置等待的 Go 程数，然后该组中的每个 Go 程都需要在运行结束时调用 Done()， 递减 WaitGroup 的 Go 程计数器 counter。当 counter 变为 0 时，主 Go 程被唤醒继续执行。

### sync.once一般是用来做什么

`sync.Once`用来保证函数只执行一次。要达到这个效果，需要做到两点：

1. 计数器，统计函数执行次数；
2. 线程安全，保障在多 Go 程的情况下，函数仍然只执行一次，比如锁。

### sync.map底层实现机制

支持并发读写，采用了“空间换时间”的机制，冗余了两份数据结构：readMap和dirtyMap。和原始map+RWMutex相比，减少了加锁的性能影响。它做了一些优化，可以无锁访问redaMap，而且会优先操作readMap。适用于读多写少的场景，如果写多会导致readMap缓存失效，需要加锁，性能下降。

### sync.map中的dirty作用是什么

https://www.jianshu.com/p/cfdcf18cd25a

dirtyMap是最终的数据，readMap类似于缓存数据。需要保证readMap和dirtyMap一致性

### 有个读少写多的场景，要对map怎么优化

可以用hash分流的方式减少锁的粒度，参考bigcache

### 什么情况下会发生协程泄露

goroutine由于channel的读/写端退出而一直阻塞，导致goroutine一直占用资源，而无法退出
goroutine进入死循环中，导致资源一直无法释放

### 协程泄露有什么表现

每申请一个协程都会创建一个4k的协程数据，如果一直泄露的话，会导致oom发生。

### 如果有内存泄露的话，要怎么定位

https://blog.csdn.net/ByteDanceTech/article/details/124113705

1. 观察服务器实例，查看内存使用情况，确定内存泄漏问题；
2. 判断 goroutine 问题：使用 pprof 进行采样判断，判断 goroutine 数量是否出现了异常增长。
3. 判断代码问题：利用 pprof，通过函数名称定位具体代码行数，可以通过 pprof 的 graph、source 等手段去定位；
4. 排查整个调用链是否出现了上述场景中的问题，如 select 阻塞、channel 阻塞、slice 使用不当等问题，优先考虑自身代码逻辑问题，其次考虑框架是否存在不合理地方；

### pprof有哪两种模式

1. 一种是项目中导入runtime/pprof,主要用来产生dump文件，然后再使用 Go Tool PProf 来分析这运行日志，此种方式在普通的单机程序未使用http网络服务上使用。
2. 另一种方式是项目中导入net/http/pprof,net/http/pprof是对runtime/pprof的封装，如果当前程序已启用http服务，使用此种方式非常方便，以做到直接在web上看到当前 web 服务的状态，包括 CPU 占用情况和内存使用情况等

### pprof捕获profile的实现原理吗

https://blog.csdn.net/phantom_111/article/details/112547713

CPU采集依赖SIGPROF 信号，但是该信号将被发送给主程序的 SIGPROF 信号处理程序(如果有的话)，而不是 Go 使用的信号处理程序。

具体实现过程其实很简单就是一个简单的生产者和消费者模型。

程序收到 SIGPROF信号，将 CPU 采样数据写入到 cpuprof.log 的 buffer 缓存中
然后 profileWriter 中死循环调用 readProfle，读取采样数据，将数据写入到指定的 cpu.prof 文件中

### profile是一个准确的cpu情况，还是一个采样的cpu情况

具体实现是注入正在运行的进程，高频地去探测函数调用栈。根据[大数定律](https://zh.wikipedia.org/wiki/大数定律)探测次数越多的函数运行时间越长。

### 下面代码输出结果

不确定，可能是00，12，02，10都有可能。因为多个协程并发执行，那个指令谁先执行都是不确定的

```go
var a, b int

func f() {
	a = 1
	b = 2
}

func p() {
	fmt.Println(a)
	fmt.Println(b)
}

func main() {
	go f()
	p()
}
```

### 介绍下跳表

是一个**多层次**的链表，每个节点都有一个next指针（指向下个元素）和一个down指针（指向下一层）

每层节点的**next跨度**大小都不同，从上到下依次减小

最底层为原始链表，是有序的链表

时间复杂度：最好O（lgN），最差O（N） 

### 跳表的层数是怎么定的

跳表的层高由掷硬币算法，每次插入元素都有1/2概率增加层高

### 介绍下redis的三种部署模式

> 主从模式：主库提供读写操作，从库负责同步主库数据提供读操作。当主挂了之后，主节点挂了，从节点不会作为新的主节点，还是从节点。需要人手动切换主节点

> 哨兵模式：就是在主从模式上做的改进，增加了哨兵节点实时监控主节点是否在线，如果不在线则由从节点接管主。

> cluster集群
>
> + 通过哈希的方式，将数据分片，每个节点均分存储一定的哈希槽（哈希值）区间的数据，默认分配了16384个槽位
> + 数据分片存储在多个互为主从的多个节点上（16384个槽均分到每个节点上）
> + 数据先写入主节点，再同步到从节点（支持配置为阻塞同步）
> + 同一分片多个节点间的数据不保证强一致性
> + 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点
> + 扩容时需要把旧节点的数据迁移一部分到新节点
> + 在redis cluster架构下，每个redis要放开两个端口，例如：一个6379，另外一个就是加上1W的端口16379。另外一个端口是用来进行节点间通信的，也就是cluster bus的通信。用来进行故障检测，配置更新，故障转移授权。
> + cluster bus用了另外一种二进制的协议，gossip协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间

### cluster集群如果发生槽迁移，那这个时候槽迁移没有迁移完，去访问这个key会发生什么

https://blog.csdn.net/keep_learn/article/details/106834425

迁移过程中，两个节点对应的槽位都存在部分key数据，客户端首先尝试访问旧的节点，如果对应的数据还在旧节点里，旧节点正常处理。
如果不在旧节点，分两种情况 1,在新节点 2，不存在

旧节点不清楚，所以向客户端返回 -ASK targetNodeAddr重定向指令
客户单去目标节点执行一个ASKING 指令，然后再在新节点执行原先的操作指令

执行ASKING 避免形成重定向循环。
ASKING 告诉新节点，不能不理，当做自己的槽位来处理。

### redis的持久化机制

redis提供了两种持久化机制：RDB和AOF

RDB：保存某一时间点之前的快照数据。恢复数据时直接将快照数据解析到内存

AOF：指所有命令行记录以redis命令请求协议的格式完全持久保存在aof文件中。恢复数据时，则根据redis命令依次执行。

### 原生socket编程中，服务端的整个流程（调用什么函数，分别什么作用）

1. socket()：创建socket
2. bind()：绑定服务器地址结构
3. listen()：设置监听上限
4. accpet()：阻塞监听客户端连接
5. read()：读取客户端数据
6. write()：发送数据给客户端
7. close()：关闭连接

### epoll能用来监听文件读写吗

https://zhuanlan.zhihu.com/p/483313542

epoll 是不能监听普通文件的，返回Operation not allow错误码。

原因：当被监听的文件没有提供 `poll` 接口时，就会返回 `EPERM` 的错误，这个错误就是 `Operation not allow 的错误`号。由于我们的文件系统是 `ext4`，所以来看看 `ext4` 文件系统中的文件没有提供了 `poll` 接口（位于文件 **/fs/ext4/file.c** 中）

### select和epoll的区别

|            | epoll            | select                                                       | poll                                                         |
| ---------- | ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 时间复杂度 | O(1)             | 当有 I/O 时间发生时，不能知道是哪个 fd 触发了，只能无差别的轮询所有 fd。 O(N) | 当有 I/O 时间发生时，不能知道是哪个 fd 触发了，只能无差别的轮询所有 fd。 O(N) |
| 底层实现   | 红黑树+就绪链表  | 数组（poll 与 select 没有本质上的区别， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。） | 链表（poll 与 select 没有本质上的区别， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。） |
| 缺点       | 消耗的资源比较多 | 最大连接数有上限<br>需要对fd集合进行轮询扫描<br>需要将fd集合从内核和用户空间来回拷贝 | 需要对fd集合进行轮询扫描<br/>需要将fd集合从内核和用户空间来回拷贝 |

### select的底层原理

数组（poll 与 select 没有本质上的区别， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。）

select：是最初解决IO阻塞问题的方法。用结构体fd_set来告诉内核监听多个文件描述符，该结构体被称为描述符集。由数组来维持哪些描述符被置位了。对结构体的操作封装在三个宏定义中。通过轮寻来查找是否有描述符要被处理。

存在的问题：

1. 内置数组的形式使得select的最大文件数受限与FD_SIZE；

2. **每次调用select前都要重新初始化描述符集，将fd从用户态拷贝到内核态，每次调用select后，都需要将fd从内核态拷贝到用户态；**

3. 轮寻排查当文件描述符个数很多时，效率很低；

### epoll的底层原理

+ 底层实现原理：
  + 当内核初始化epoll时，会开辟一块内核高速cache区，用于安置我们监听的socket，这些socket会以红黑树的形式保存在内核的cache里，以支持快速的查找，插入，删除．同时，建立了一个list链表，用于存储准备就绪的事件．所以调用epoll_wait时，在timeout时间内，只是简单的观察这个list链表是否有数据，如果没有，则睡眠至超时时间到返回；如果有数据，则在超时时间到，拷贝至用户态events数组中．
  + 那么，这个准备就绪list链表是怎么维护的呢？当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。
+ epoll_create：创建一个 epoll 文件描述符，底层同时创建一棵红黑树 and 一个就绪链表 rdlist。红黑树存储了所有监控的文件描述符；就绪链表存储就绪文件描述符
+ epoll_clt：
  + 删除：将文件描述符从红黑树上摘除
  + 插入：先查看红黑树是否有该 fd：如果有，不再插入；如果没有，插入。（epoll 使用“事件”的就绪通知方式，通过 epoll_ctl 注册 fd，一旦该 fd 就绪，内核就会采用类似callback 的回调机制来激活该 fd，epoll_wait 便可以收到通知）
+ epoll_wait：只是从就绪链表中取出元素，将该元素上的事件复制到用户态区间（使用 mmap 提高效
  率）

### 两个线程同时用epoll_wait监听同个fd，那这个时候fd有读写事件，两个线程都会被唤醒吗

https://www.zhihu.com/question/49741301

https://simpleyyt.com/2017/06/25/how-ngnix-solve-thundering-herd/

Epoll_wait的挂起采用 pthread_cond_wait

`EPOLLEXCLUSIVE`是4.5+内核新添加的一个 epoll 的标识，Ngnix 在 1.11.3 之后添加了`NGX_EXCLUSIVE_EVENT`。

`EPOLLEXCLUSIVE`标识会保证一个事件发生时候只有一个线程会被唤醒，以避免多侦听下的“惊群”问题。不过任一时候只能有一个工作线程调用 accept，限制了真正并行的吞吐量。

### 服务端调用listen后，不调用accept，那客户端能发送数据吗

客户端可以发送数据。因为调用listen之后服务端就可以接受客户端的tcp连接。而accept只是将全连接队列中的fd取出来，进行读写操作。accept之前tcp的三次握手已经建立完成

### 全连接队列和半连接队列的区别

客户端发送SYN报文，服务端接收到SYN报文，并且发送SYN+ACK报文，这个时候就会将fd插入到半连接队列

客户端接收到服务端的SYN+ACK报文后，回ACK报文。服务端收到ACK报文后，将半连接队列的fd迁移到全连接队列

### 什么情况下半连接队列会满，什么情况下全连接队列会满

SYN泛洪攻击会导致半连接队列满

不调用accept的情况，或者accept处理过慢也会导致全连接队列满

### 我们调用read的整个过程发生了什么

1. read 调用导致**用户态到内核态的一次变化**，同时，第一次复制开始：DMA（Direct Memory Access，直接内存存取，即不使用 CPU 拷贝数据到内存，而是 DMA 引擎传输数据到内存，用于解放 CPU） 引擎**从磁盘读取文件，并将数据放入到内核缓冲区。**
2. 发生第二次数据拷贝，即：**将内核缓冲区的数据拷贝到用户缓冲区**，同时，**发生了一次用内核态到用户态的上下文切换。**
3. 两次数据拷贝，2次上下文切换

### 数据返回之前这个read是一直阻塞的是吧

read()函数如果阻塞地读，很容易就会被信号打断
如果被信号打断，返回的错误码errno则是`EINTR`，然而无所谓，我们被信号打断并不影响什么，`continue`并且`取消关闭fd`，进入下一次循环即可

### 有没有什么情况可以打断这个read阻塞（对应的fd是阻塞模式）

软终端和信号都会打断read操作

### 信号是怎么触发的吗（信号触发原理）

https://blog.csdn.net/dingqinghui/article/details/115211098

所有信号都需要通过内核发送，内核在收到信号后会对其参数进行检测(这个进程能不能发送这个信号…)。校验通过后，将信号数据(信号值,产生原因，发送者进程ID)拷贝到内核空间.然后再发送给对应的进程。

进程会注册信号和对应的cbk函数到进程的pcb中，触发信号后会调用该cbk函数

### 信号的cbk是在用户态执行的是吧

是的

### 信号的cbk函数执行完，会回复到哪里。回复的流程是什么

进程从内核态切换到用户态前，检测是否有信号需要处理，如果有且没有被阻塞就会调用相应的信号处理程序去处理。
首先，内核在用户栈上创建一个frame，frame中将返回地址设置成信号处理函数的地址，这样，从内核返回用户态时，就会执行这个信号处理函数。
当信号处理函数执行完，会再次进入内核，检测有没有没处理完的信号，和恢复用户栈。

### gdb的实现原理

https://blog.csdn.net/Z_Stand/article/details/108395906

### gdb查看所有线程堆栈

info threads 显示当前可调试的所有线程

thread ID 切换当前调试的线程为指定ID的线程

attach process-id 在gdb状态下，开始调试一个正在运行的进程

thread apply all command 所有线程执行command

### 查看一个文件被哪些进程占有的linux命令

http://c.biancheng.net/view/1088.html

lsof filename 显示打开指定文件的所有进程

### 查看一个进程打开了哪些文件的linux命令

http://c.biancheng.net/view/1088.html

lsof -p ${pid}：显示进程打开了什么文件

### buffer和cache有什么区别

1. buffer：缓冲区，buffer时为了提高内存和硬盘(或其他I/O设备)之间数据交换速度而设计的。buffer是根据硬盘的读写设计的，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。
2. cache：缓存区，cache是为了提高CPU和内存之间的数据交换速度而设计的。即将经常用到的数据放到缓存区内，方便CPU的读取，从而提高性能。

简单理解下：

buffer是缓冲(缓和冲击)，主要通过减少不必要的状态切换和设备I/O来提高性能；

cache是缓存(缓存数据)，主要通过将部分数据放到读写速度快的地方，加快取用速度，从而提高性能。

共性：都属于内存，数据都是临时的，一旦关机数据都会丢失。

差异：

1. buffer是写入数据，cache是读取数据

2. buffer数据丢失会影响数据完整性，源数据不受影响；cache数据丢失不影响数据完整性，但影响性能

3. buffer大小够用就行；cache越大，性能越好

### 什么东西会放到cache里面

将硬盘中的数据读取出来放在内存的缓存区中，这样以后再次访问同一个资源，速度会快很多。

### 如果内存不够用，cache占太多，那linux会自己去回收cache吗

Linux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是被使用更多的cache的空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。

+  算法题1：给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。（[只出现一次的数字](https://leetcode-cn.com/problems/single-number/)）
+  算法题2：假设你正在爬楼梯。需要 n 阶你才能到达楼顶。每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？（[爬楼梯](https://leetcode-cn.com/problems/climbing-stairs/)）