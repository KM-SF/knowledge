### 10亿的整数，找到前100个

hash分流+堆排序

1. 对一个整数用hash函数获得一个hash值，再进行100取模，保存到某一个文件中，然后再对单个小文件进行处理
2. 使用大根堆的方式保存单个小文件的所有整数，所以单个小文件，就形成了大根堆的top是最大的数据
3. 然后再用整合大根堆对这个100个小文件进行整合。
4. 每个小文件的大根堆的堆顶元素，放进整合大根堆（100个小文件就放进了100个元素）
5. 然后对整合大根堆，弹出堆顶元素，则这个元素则是最多出现的次数。
6. 弹出的堆顶元素知道他是属于那个小文件的，再将这个小文件的大根堆堆顶再放到整合大根堆中。
7. 依次类推6，7步骤。直到整合大根堆弹出100个元素就知道TOP100。

### 10亿的整数，有20%的元素是重复的，找到前100个

### 双向链表的的查找时间复杂度

O(N)

### 二分查找的时间复杂度

O(lgN)

### 有没有什么方式使得双向链表的查询时间复杂度为o(logn)

将双向链表改成跳表

### 跳表的应用场景

redis中的zset数据结构

### 有1G的文件用zset的方式去存储，大概暂用多少内存，实际扩大了多少内存

应该是2G，因为跳表是用时间换空间。空间复杂度是O(N)

### 跳表的原理说下

是一个**多层次**的链表，每个节点都有一个next指针（指向下个元素）和一个down指针（指向下一层）

每层节点的**next跨度**大小都不同，从上到下依次减小，最底层为原始链表，是有序的链表。

### 了不了解布隆过滤器

了解

### 说下布隆过滤器的原理

布隆过滤器是一个bitmap，每一位的数值只有0和1。分别表示存在或者不在。有一组hash函数，每次查询key时，会算出每个hash函数的对应hash值，然后判断该hash值所对应的bitmap是否1。都为1则可能存在，有为0则一定不存在

### 布隆过滤器如果不存在的话，那就是真的不存在吗

是的，一定不存在。但是会误判存在的情况，因为多个key可能存在哈希碰撞，那这个时候就会出现误判情况。

### 解决误判的的方式有什么

1. 将bitmap的大小扩大，降低误判情况

1. 发现误判就将该key，保存到set中，下次再判断key是否在误判集合

### 有了解布谷鸟过滤器吗

简单了解过，因为要删除某个key，需要将bitmap上的位设置成0，但是你并不知道这个位上是否还有其他key再使用，所以不能删除

布隆过滤器还有个缺点就是某个key插入之后就不支持删除了。如果需要支持操作可以通过布谷鸟过滤器

### 你负责的系统最大的请求量有多少

tgtd的改造项目，读性能提高40%，写性能提高10%

### tgtd的性能瓶颈在哪里

因为之前tgtd是单epoll反应堆，所以必须该fd的事件处理完才能处理下一个fd。那如果这个时间的处理函数要等待很长时间，那就会阻塞后续的请求

### 你有没有发现机器负载比较高的情况

### 你们是怎么发现压不上去的性能瓶颈在哪里

### 你们分析性能问题的整个链路过程是怎么样的

1. 资源瓶颈。CPU、内存、磁盘和文件系统I/O、网络以及内核资源等各类软硬件资源出现瓶颈。可从使用率、饱和度以及错误数这三个方面来分析。

2. 依赖服务的瓶颈。如数据库、分布式缓存、中间件等应用程序，直接或间接调用的服务出现了性能问题，从而导致应用成效的响应变慢，或者错误率升高。

3. 应用程序自身的性能问题。包括多线程处理不当、死锁、业务算法的复杂度过高等。

应用程序的核心指标：请求数、错误率、响应时间。这些指标不仅直接关系用户的使用体验，还反映应用整体的可用性和整体性。

性能监控的 USE（Utilization Saturation and Errors）法

USE 法把系统资源的性能指标，简化成了三个类别，即使用率、饱和度以及错误数。

- 使用率，表示资源用于服务的时间或容量百分比。100% 的使用率，表示容量已经用尽或者全部时间都用于服务。
- 饱和度，表示资源的繁忙程度，通常与等待队列的长度相关。100% 的饱和度，表示资源无法接受更多的请求。
- 错误数表示发生错误的事件个数。错误数越多，表明系统的问题越严重。

### 进程间的通信方式有什么

通信方式：无名管道（PIPE），有名管道（FIFO），共享内存（mmap），信号，本地套接字，消息队列

### 调用send或者write函数成功，一定能保证数据发送到对端吗

不一定。因为send和write的底层实现原理是：将用户态的数据拷贝到内核缓冲区中。内核缓冲区的数据再拷贝到网卡驱动缓冲区。那这个时候可能会发生硬件故障之类的，这个时候就没法保证一定能发送到对端

### send和write出现阻塞的话会出现在哪个环节

io的读写操作一般会有两个地方会发生阻塞：内核缓存区可读可写，内核缓冲区和用户缓冲区之间数据拷贝

### 网络会有拥塞的情况吗

网络会出现拥塞的情况，不过tcp会有拥塞控制尽量避免网络拥塞

### 那tcp是怎么解决网络拥塞的情况

拥塞控制一般就有：慢启动，拥塞避免和慢启动

+ 目的：通过拥塞窗口cwnd来防止过多的数据注入到网络中，导致网络拥堵。和滑动窗口不同，解决的问题也不同
+ 原理：通过“发送方”的拥塞窗口cwnd与门限值ssthresh大小比较，根据比较结果，调用响应的拥塞控制算法

慢启动：一开始建立连接后，将cwnd设为1，cwnd是指数增长的，直到cwnd增大到门限值ssthresh，就会进入拥塞避免阶段

拥塞避免：cwnd是线性增长的（“加法增大”），直到发生【网络超时】，就会重新开启慢启动。此时门限值ssthresh设置窗口的1/2，cwnd设置为1，继续执行慢启动

快重传：当发送方收到同一个包的连续3次重复确定时（说明网络丢包），此时不用等待网络超时，直接重传数据给接收方

### 粘包的问题有什么解决方案

粘包的解决方案一般有3种方式：

+ 消息定长：发送端将每个数据包封装为固定长度的数据块（长度不够补0填充）
+ 设置消息边界：包尾部添加\n\r，如：FTP协议
+ 消息封装：将消息数据封装为struct{int len; void *data}; 指定数据的长度

### 页面输入一个url后，整个http的链路调用过程

1. 浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址；
2. 解析出 IP 地址后，根据该 IP 地址和默认端口80，和服务器建立TCP连接；
3. 浏览器发出读取文件（URL中域名后面部分对应的文件）的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器；
4. 服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器；
5. 释放 TCP连接；
6. 浏览器将该 html 文本并显示内容；

### http协议的第一行是什么（tpcdump后协议解析）

第一行：请求头 包含【**请求方式**】 【**请求路径**】【**协议/版本**】

常见的HTTP请求方式有 GET、POST、DELETE、PUT、OPTION、PATCH

请求的路径是/ 一般webserver 都会配置一个默认的index.比如nginx 会有一个一个index index.html的参数，后面不传任何路径就是访问这个index,html / 等价于/index.html

协议：HTTP协议 后面的 **1.1**表示协议的版本。最新的http协议为http 2.0

### grpc协议的第一行是什么（tpcdump后协议解析）

### tcp三次握手成功后，发送数据对方一定能收到吗

不一定，因为可能网络出现故障，那么这个时候就无法保证对方能收到。

但是在没收到对方ack确认报文之前，会进行一定次数的重发。

第一次发送数据后，设置的超时时间是1.5s，此后每次重传增加1倍，一直到64秒

一共重传12次，大约9分钟才放弃

### tcp的重试包（so_agent的重试确认嘛）

### send或者write的返回值表示什么

send和write返回值表示：用户缓冲区拷贝到内核缓冲区的大小

### http域名解析后，得到ip和port就直接建立tcp连接吗？然后就直接发送数据吗？

### tcp和udp可以绑定同一个端口吗？

可以绑定同一个端口

### 为什么能绑定同一个端口吗？

因为网络底层区分一条连接使用五元组的形式：<协议类型，源IP，源PORT，目标IP，目标PORT>

### 有做过双协议链路保证的应用吗

双链路保证就是：同时建立tcp连接和udp连接。没有做过该应用

### 负载均衡有什么策略

轮询算法，随机算法，加权轮询算法，平滑加权轮询算法，最小活跃数

### 你们网关是用什么做的

我们的微服务都是使用的go-micro这个微服务框架做的

### 你的ip注册在哪里注册的

我们的注册中心是使用zk，将 服务的ip注册到zk

### epoll的ET和LT有什么区别

+ 水平触发（LT模式，默认模式）：当缓冲区数据可读时，就会一直触发epoll_wait函数，直到缓冲区没有可读
+ 边沿触发（ET模式）：当有客户端发送数据时，不管缓冲区的数据有没有读完都只会触发一次epoll_wait函数。只支持非阻塞模式。

### 你们的go-micro是同步的协议还是异步的协议

go-micro默认的同步通信机制是`http传输`。当然还有很多其他的插件：`grpc`,nats,tcp,udp,rabbitmq,都是目前已经实现了的方式。

我们使用的是grpc的同步通信方式

### 从接入层，服务层，缓存层和数据层的容灾的理解

+ 接入层：我们有做限流，降级和容灾
+ 服务层：我们所有pod都是去中心化的，是集群模式
+ 缓存层：我们使用的codis集群方式，codis他是一个代理框架，所以有节点挂了，也不会受到影响
+ 数据层：使用了mysql的主从模式

### 服务层如果瞬时间来了很多请求，你们这边有怎么做处理

我们接入层会有做限流降级处理，会拦住超过拒绝和降级阈值的流量

### 限流的算法有什么

计数器法，滑动窗口，漏桶算法，令牌桶算法

### 降级的话，你们是怎么做

我们会配置一个降级的阈值，当流量超过这个阈值时，我们直接返回降级数据

### 你们有做限流，降级和熔断的监控吗

都有会有监控和告警

### 你们的限流阈值和降级阈值是怎么设置呢

我们每个月进行月度压测就是为了进行阈值确定。我们一般是压测到系统cpu的60%，那个qps就是我们的阈值

### 你们服务的性能瓶颈是在CPU是嘛

是的，因为我们内部实际上没什么io的操作。基本上都是内存操作，最多就是rpc调用其他服务的接口获取数据。

### 你们缓存层是怎么做容灾的

我们缓存层是用codis集群

### 有经常迁移数据吗

不经常，因为我们一开始就会申请比较大的集群

### codis和cluster的优缺点分别是什么

|              | codis            | cluster  |
| ------------ | ---------------- | -------- |
| 数据库数量   | 16               | 1        |
| 不支持命令   | keys             | select   |
| dashboard    | 有               | 没有     |
| 可视化客户端 | 有               | 没有     |
| 集群结构     | 代理             | 去中心化 |
| 哈希槽       | 1024             | 16394    |
| 升级         | 无法保证后续升级 | 官网保证 |
| 部署         | 较为复杂         | 简单     |
| 自动均衡     | 是               | 否       |

### codis和cluster集群的数据迁移底层实现了解吗

codis：发生数据迁移的话，他需要将所有的key重新映射一次。因为他采用的是普通的hash映射方式

cluster：cluster集群的话，他是从每个节点中拿去一部分数据进行重新映射，他采用的是一致性hash算法

### 有接触过2pc和3pc算法吗

> 2PC：是一种**尽量保证强一致性**的分布式事务，因此它是**同步阻塞**的，而同步阻塞就导致长久的资源锁定问题，**总体而言效率低**，并且存在**单点故障**问题，在极端条件下存在**数据不一致**的风险。
>
> 1. 准备阶段（准备事务所需要资源）
> 2. 提交阶段（提交事务处理）

> 3PC：相比于 2PC 它在**参与者中也引入了超时机制**，并且**新增了一个阶段**使得参与者可以利用这一个阶段统一各自的状态。
>
> 3PC 的引入是为了解决提交阶段 2PC 协调者和某参与者都挂了之后新选举的协调者不知道当前应该提交还是回滚的问题。
>
> 1. 准备阶段：准备阶段协调者只是询问参与者的自身状况，比如你现在还好吗？负载重不重？这类的。
> 2. 预提交阶段（准备事务所需要资源）
> 3. 提交阶段（提交事务处理）

### raft协议介绍下

raft共识算法就是三个主要模块：leader选举，数据同步和分区共识

> leader选举
>
> + 所有节点都有一个定时器（每个节点的定时器都是随机值）。该定时器表示收到Leader的心跳包。
> + 如果在定时器内没有收到Leader的心跳包，则自己变成Candidate状态，参与竞选Leader。（选举超时，自己当成候选者）
> + 然后所有任参与选票，候选者的投票只会投给自己，其他人则投给某个候选者（可能出现多个候选者情况）
> + 如果自己的票数过半，则成为新的Leader。
> + 如果此时有人跟自己一样同时竞选Leader，那么这两个人都会在起一个定时器（随机值），进行在一轮的选票

> 数据同步
>
> + 当leader接收到请求后，将该请求写到自己的日志中
> + leader将该请求发送给其他节点，要求其他节点也写到日志中
> + 其他节点将请求写到日志后，回一个ack给leader
> + leader统计有过半节点回复了ack后，将请求数据更新
> + leader发送请求给其他节点，要求其他节点将数据更新

> 分区共识
>
> + 集群5个节点，一开始1个leader和4个Follower
> + 然后网络出现问题，把1个leader和1个Follower划分为一个区A。而其他三个节点为另外一个区B
> + 另外三个节点为一个区A后，进行重新选举leader
> + 有个clientA向分区A发送请求，但是这个时候分区只有两个节点，没有超过半数所以该请求无效
> + 有个clientB向分区B发送器请求，有过半节点同意该请求，所以请求有效，更新数据
> + 当网络恢复后，出现了两个leaderA和leaderB。因为leaderB是新一代的leader，所以leaderA放弃做leader。并且将分区B的数据更新到分区A的每个节点上
> + 问题：一致性并不一定代表完全正确性！三个可能结果：成功，失败，unknown

### raft协议的为什么要解决日志同步问题

因为集群模式下，需要保证其他节点的数据跟主节点一致。保证强一致性

### 我们拆表的话，多大需要拆

1. 表的体积大于2G或行数大于1000w,以单表主键等简单形式访问数据，这个时候需要分表

2. 表的体积大于2G或行数大于500W,以两表jion，小范围查询（结果集小100行）等形式访问数据，这个时候需要分表
3. 表的体积大于2G或行数大于200w,以多表join，范围查询，order by，group by，高频率等复杂形式访问数据，尤其DML，这个时候需要分表
4. 表的字段中含有text等大字段的、varchar(500)以上的、很少使用的字符型字段拆分成父子表,这种分表可以和以上联合使用
5. 数据有时间过期特性的，需要做数据分表归档处理

只要达到上面任何一个标准，都需要做分表处理

### mysql拆表的原因是什么

水平拆表：一般因为数据量多大，导致底层B+树的树高增加。树层越高会多读磁盘io。

垂直拆表：一般是将不同属性的字段进行拆分成多个不同属性表，这样避免IO争抢并减少锁表的几率，也能并行查询提高效率。

### mysql的每次查询都是需要有io操作吗

mysql底层有一个buffer缓存区，每次查询都会判断是否存在buffer中，如果有则直接返回。没有则进行io查询，并写到缓存中

### 常见的存储引擎有什么

innode和myisam

### 存储引擎分别应用场景是啥

|    对比项    |                            InnoDB                            |                         myisam                          |
| :----------: | :----------------------------------------------------------: | :-----------------------------------------------------: |
|     事务     |                     支持（可靠性要求高）                     |                       不支持事务                        |
|    锁级别    |                  行锁（适用于表更新较频繁）                  |           表锁（适用于查询多，插入和删除少）            |
| 是否支持外键 |                             支持                             |                                                         |
|     查询     |                                                              |                          更快                           |
|   全文索引   |                                                              |                          支持                           |
|   适用场景   | (1)可靠性要求比较高，或者要求事务<br/>(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况 | (1) 做很多count 的计算<br/>(2) 查询非常频繁，插入不频繁 |

### 说下你对索引的一些理解吧（他的匹配原则呀，索引的原理呀，三星索引？）

+ 匹配原则：最左匹配原则

+ 索引的原理：加快SQL查询速度的数据结构，引来的缺点（降低<u>更新表的速度</u>，保存<u>索引占用空间</u>），底层是B+树数据结构

+ 索引分为：聚簇索引和非聚簇索引

+ 三星索引其实是衡量一个索引是否达到最佳表现的三个维度：

  第一星：where后面的等值谓词，可以匹配索引列的顺序：意义在于谓索匹配的越多，索引片越窄，最终扫描的数据行也是越小。

  第二星：order by的排序是否和索引的顺序一致：意义在于避免进行额外的排序，增加消耗。

  第三星：select的字段是否都为索引列：意义在于避免每一个索引行查询，都需要去聚簇索引进行一次随机IO查询。

### 有一个用户表（自增id，userid和name），自增id是主键，userid是普通索引，那这两个索引有什么区别

自增id：他是主键索引，主键索引就是聚餐索引，有唯一性

userid：他是普通索引，所以他是非聚簇索引，普通索引可以重复

### 有一个用户表（自增id，userid，name和地址），自增id是主键，userid是普通索引，userid和name是复合索引。那这个表结构或者索引结果有什么可以优化的吗

http://t.zoukankan.com/duanxz-p-2800004.html

有冗余索引的问题。冗余索引：指多个索引的前缀列相同，或者在联合索引中包含了其他的索引 。

### mysql有什么隔离级别

+ **读未提交**：所有事务都能够读取其他事务未提交的数据，会导致賍读、不可重复读、幻读
+ **读已提交**：所有事务只能读取其他事务已经提交的数据，可以解决賍读！但是会出现在一个事务中前后读取内容不一致的问题，即不可重复读、幻读
+ **可重复读**：在一个事务中，不允许Update操作，允许Add操作，因此能保证在一个事务中读取数据内容是一致的(能解决不可重复读，即对同一个数据多次读取的val都是一样的)，但是不能保证读取到数据条目数一致(会发生幻读)
+ **可串行化**：所有的事务都顺序串行执行，不存在冲突

### mysql的默认隔离级别

innodb默认隔离级别不是最高的，而是倒数第二高的，即<u>可重复读级别</u>

### 脏读和幻读分别出现在哪个隔离级别

脏读出现在：读未提交隔离级别。

幻读出现在：读未提交，读已提交，可重复读

### 有没有情况会出现脏读和幻读呢

在第一个隔离级别就会出现。其他隔离级别不会出现

### redis的优点是什么

1. 纯内存操作，且操作复杂度不高
2. 核心是基于非阻塞的IO多路复用机制
3. 单线程避免了多线程的频繁切换上下文所带来的的性能消耗
4. `完美`的数据结构的设计，键值对按照一定的数据结构促织，操作键值对最终都是对数据结构进行增删改查操作，所以高效的数据结构是redis快速处理数据的基础

### redis他的单线程指的是什么，还有其他的线程吗

+  单线程指的是网络请求模块使用了一个线程（所以不需考虑线程安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。
+  主线程：Redis在<u>处理客户端请求时（获取命令、解析命令、执行、返回内容）</u>等操作都是由一个顺序串行的主线程处理的，这就是所谓的“单线程”。
+  后台线程：清理脏数据、无用连接释放、大key的删除

### redis的淘汰策略是什么？默认策略是什么？

noeviction：不淘汰任何数据，当内存不足时，执行新增操作会报错，**默认策略**

allkeys-lru：淘汰整个键值中最久未使用的键值

allkeys-lfu：淘汰整个键值中最少0.使用的键值

allkeys-random：随机淘汰任意键值

volatile-lru：淘汰所有设置了过期的键值中最久未使用的键值

volatile-lfu：淘汰所有设置了过期的键值中最少使用的键 值

volatile-random：随机淘汰所有设置了过期的键值

volatile-ttl：优先淘汰更短过期时间的键值

### redis和mysql的数据一致性怎么保证

延迟双删策略：先删缓存，再更新mysql，再删缓存

### 延迟双删是强一致性吗？为什么？

不是强一致性的，是最终一致性。

因为有个线程A删除缓存后，更新mysql。再这期间线程B去读缓存，发现没有数据则读到mysql的旧数据并且更新到缓存中。这个时候就出现了不一致。需要线程A最后去删除缓存

### mysql的主从是强一致性的吗？

mysql的主从是最终一致性的，因为主从节点数据同步是异步同步或者半同步同步。这两个方式都无法达到强一致性

### redis集群是cap的哪一种

ap，也是保证可用性，不保证强一致性

### 主从的mysql是cap的哪一种

ap，也是保证可用性，不保证强一致性

### 有没有符合cp的组件

zk

### zk的底层算法是用什么保证的

zab共识算法

### redis中有10亿个key，有1W的key配置了缓存过期，那redis是每次都遍历这所有key判断是否淘汰吗

不会拿所有key，而是会轮询数据库并且只拿一部分key进行扫描，这样做是为了避免cpu的突增。