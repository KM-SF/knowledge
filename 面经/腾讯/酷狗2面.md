### 你们redis是用什么模式

用的是客户端codis分片集群。codis集群是个代理集群，在Codis里面，它把所有的key分为1024个槽，每一个槽位都对应了一个分组，具体槽位的分配，可以进行自定义，现在如果有一个key进来，首先要根据CRC32算法，针对key算出32位的哈希值，然后除以1024取余，然后就能算出这个KEY属于哪个槽，然后根据槽与分组的映射关系，就能去对应的分组当中处理数据了。

### redis底层rehash的过程

```c
// 字典
struct dict {
	dictht ht[2];   // 2个哈希表: ht[0]正常情况下使用, ht[1]在rehash时使用
    int rehashidx;  // rehash索引 (没进行rehash时，该值为-1)
}
```

1. ht[1]分配空间，新建一个空的哈希表
2. rehash索引计数器（**rehash_index**），由-1变为0，表示rehash正式开始
3. 将ht[0]中的元素，rehash重新散列到ht[1]上，每次一个(key,value)键值对rehash成功后，rehash索引计数器都+1。每次增删改查都处理一次index。
4. 当所有的ht[0]都rehash到ht[1]中后，ht[0]被清空，此时将ht[0],ht[1]**交换**，rehash结束，最后将rehash索引设为-1

### redis的zset为什么可以实现点查和范围查

因为zset底层的数据结构是用跳表形式实现的。跳表的话，它是一个有序的双向链表，多层链表结构。通过模拟二分查找的方式达到O(logN)的时间复杂度

### redis和db的数据一致性怎么做

我们采用的是延迟双删的策略

### 延迟双删的话，在高并发的读场景会读到脏数据吗

会有可能读到脏数据。有一个线程正在写mysql，另外个线程发现redis没有数据就去mysql读并且同步到redis。只能达到最终一致性

### 如果有场景对数据的一致性有比较高的延迟要求，那有什么办法来保证尽量的强一致性吗

可以用mysql的canal技术。canal服务可以监听mysql某个表的binlog是否发生变化，如果发生变化则可以触发cbk，在cbk中更新redis数据

### redis高可用的方案

https://blog.csdn.net/liuyueyi25/article/details/126115873

- 持久化：RDB数据落盘加载方式 + AOF记录操作命令用于回放策略
- 主从，主从从：全量数据冗余、读写请求分离，负载均衡的思想；核心问题在于主节点挂掉之后需要人工参与手动指定主库
- 集群：数据分片，每个实例提供部分服务能力
- 主从同步：采用了增量复制和全量复制两种方式保证数据一致性

### mysql的数据同步模式

+ **异步复制**：主服务器写完Binlog，不等同步给从服务器，就返回

  + <u>主库执行操作后，写入Binlog日志后，就返回客户端</u>，这一动作就结束了，并不会验证从库有没有收到，所以，**这样可能会造成主从数据不一致**。
  + 在SQL中，有sync_binlog=n参数，表示每进行n次事务提交，SQL就将Binlog刷新到磁盘。如果该值设为1，就算数据库宕机了，最多只损失一次失误提交。但是sync_binlog=1有以下缺点：①每次事务提交都要刷盘，影响数据库性能 ②SQL只能按照顺序来处理这些请求
  + 缺陷：主库提交事务写入Binlog后，当从库没有从主库得到Binlog时，由于主库宕机或磁盘损坏可能导致该事务的Binlog丢失了，那么从库就不会得到这个事务，也就造成了主从数据的不一致。

+ **半同步复制**：主服务器写完Binlog，等待（同步）给任意一台从服务器，再返回。MySQL5.5之后引入了半同步复制，解决异步复制的主从数据不一致的问题

  + 当主库每次提交一个事务后，不会立即返回，而是：<u>等待其中一个从库接收到Binlog并成功写入RelayLog</u>，才返回客户端。==> 这样，保证了一个事务至少有2份日志（一份保存在主库的Binlog，另一份保存在其中的一个从库的Relay-Log中，从而保证了数据的安全性和一致性）。

  + 在半同步复制时，如果主库的一个事务提交成功了，在推送到从库的过程当中，

    > 【Q1】从库宕机了或网络故障，导致从库并没有接收到这个事务的Binlog 
    >
    > ==> 此时主库会等待一段时间（这个时间由rpl_semi_sync_master_timeout的毫秒数决定），

    > 【Q2】如果这个时间过后还无法推送到从库
    >
    > ==> 那MySQL会自动**从半同步复制切换为异步复制**；当从库恢复正常连接到主库后，主库**又会自动切换回半同步复制**

### 半同步一定能保证主从一定是一致的吗

半同步复制的 **“半”** 体现在：

1. 虽然主从库的Binlog是同步的，但主库不会等待从库执行完Relay-log重放后才返回
2. 而是确认从库接收到Binlog，达到主从Binlog同步的目的后就返回了
3. 所以从库的数据重放对于主库来说还是有延时的，这个延时就是从库执行Relay-log的时间，<u>所以只能称为半同步</u>。

### mysql的事务隔离级别

+ **读未提交**：所有事务都能够读取其他事务未提交的数据，会导致賍读、不可重复读、幻读
+ **读已提交**：所有事务只能读取其他事务已经提交的数据，可以解决賍读！但是会出现在一个事务中前后读取内容不一致的问题，即不可重复读、幻读
+ **可重复读**：在一个事务中，不允许Update操作，允许Add操作，因此能保证在一个事务中读取数据内容是一致的(能解决不可重复读，即对同一个数据多次读取的val都是一样的)，但是不能保证读取到数据条目数一致(会发生幻读)
+ **可串行化**：所有的事务都顺序串行执行，不存在冲突
+ innodb默认隔离级别不是最高的，而是倒数第二高的，即<u>可重复读级别</u>

### 可重复读是怎么实现的

可重复读是由：MVCC实现的。

mvcc：叫多版本控制。是为了解决并发场景下，读写性能问题。通过快照读的方式提高读性能。

mvcc是由：版本链和读视图所组成。每一行数据的多次事务记录组成版本链，读视图就是你能看到这行数据的事务id列表。

当前读就是：读到的最新数据（需要加锁）。快照读就是读到旧数据（不需要加锁）

如果事务隔离级别是 ReadCommit ，一个事务的每一次 Select 都会去查一次ReadView ，每次查询的Read View 不同，就可能会造成不可重复读或者幻读的情况。

如果事务的隔离级别是可重读，为了避免不可重读读，一个事务只在第一次 Select 的时候会获取一次Read View ，然后后面索引的Select 会复用这个 ReadView.

### redolog在断电的情况下，重启后能保证数据不丢失吗

并不一定。因为你一次写操作，是先写到redolog的buffer缓存区，等待后续落盘到日志中。如果你是配置了双1提交的话，那每次都会直接落盘，这种就不会丢数据。如果不是双1提交的话，那有可能没落盘的时候掉电，这个时候缓存区数据就都丢失了。

### kafka高性能的原因

#### **1. 顺序IO**

kafka写消息到分区采用追加的方式，也就是顺序写入磁盘，不是随机写入，这个速度比普通的随机IO快非常多，几乎可以和网络IO的速度相媲美。因为不用老是寻址，随机写每次都需要寻址，这操作很消耗时间。

#### **2. Page Cache和零拷贝**

kafka在写入消息数据的时候通过mmap内存映射的方式，不是真正立刻写入磁盘，而是利用操作系统的文件缓存PageCache异步写入，提高了写入消息的性能，另外在消费消息的时候又通过`sendfile`实现了零拷贝。

#### **3. 批量处理和压缩**

Kafka在发送消息的时候不是一条条的发送的，而是会把多条消息合并成一个批次进行处理发送，消费消息也是一个道理，一次拉取一批次的消息进行消费。

并且Producer、Broker、Consumer都使用了优化后的压缩算法，发送和消息消息使用压缩节省了网络传输的开销，Broker存储使用压缩则降低了磁盘存储的空间。

#### 4.分区分段+索引

kafka的message消息实际上时分布式存储在一个格小的segment中的。每次文件的操作也是直接操作segment。

为了进一步查询优化，kafka又默认为分段后的数据文件提供索引文件

这种分区分段（partition+segment）+索引文件（index）的设计，不仅提升了数据读取的效率，同时提高了数据操作的并行度

### 场景题：如果要求顺序消息和高性能，那有没有什么方案

### kafka有没有可能丢数据呀

有可能丢数据，因为你及时把发送者的ack配置成all。那也是将消息写入到kafka的缓存区中，并没有真正落盘。需要等待系统自己去落盘，如果期间掉电那就丢数据。

### mysql有什么高可用的方案

1. 数据持久化策略：操作内存(buffer)，异步刷盘，两阶段提交保障一致性（WAL机制）
2. 通过冗余来实现高可用：如主备
3. 读写分离，实现负载均衡：主从、主从从模式

### 了解LSM-Tree吗

1. LSM树是一个横跨内存和磁盘的，包含多颗"子树"的一个森林。
2. LSM树分为Level 0，Level 1，Level 2 ... Level n 多颗子树，其中只有Level 0在内存中，其余Level 1-n在磁盘中。
3. 内存中的Level 0子树一般采用排序树（红黑树/AVL树）、跳表或者TreeMap等这类有序的数据结构，方便后续顺序写磁盘。
4. 磁盘中的Level 1-n子树，本质是数据排好序后顺序写到磁盘上的文件，只是叫做树而已。
5. 每一层的子树都有一个阈值大小，达到阈值后会进行合并，合并结果写入下一层。
6. 只有内存中数据允许原地更新，磁盘上数据的变更只允许追加写，不做原地更新。

### LSM-Tree的查询过程是怎么样

LSM树的查询操作会按顺序查找Level 0、Level 1、Level 2 ... Level n 每一颗树，一旦匹配便返回目标数据，不再继续查询。该策略保证了查到的一定是目标key最新版本的数据

### 了解http2.0吗？解决什么问题

- **多路复用**：允许在同一个时刻，对同一URL发起多次请求，同时对多次请求予以相应

  - HTTP/1.x，浏览器在同一个时间，请求同一URL具有一定数量的限制，超过该数量上限的请求都会被阻塞。
  - HTTP/2.0虽然只有一条TCP连接，但是在裸机上分成了很多stream

- 二进制分帧

  - 在不改动HTTP/1.x的语义/方法/状态码/URI等的情况下，HTTP/2.0是如何做到（突破HTTP/1.x的性能限制，改善传输性能，实现低延迟和高吞吐量）的呢？

  - 答：在应用层、传输层之间增加一个二进制分帧层！

    在二进制分帧层中，HTTP/2.0会将所有传输的信息分割成更小的消息和帧，并对它们采用二进制格式的编码

- 请求优先级

- 流量控制：类似于TCP滑动窗口来控制流量，数据接收方通过告诉发送方它能接收的窗口大小

- 服务器推送：客户端请求资源X，而服务器知道它很可能也需要资源Z的情况下，服务器会将资源Z一起推送给客户端

- **首部压缩**

- TLS：更安全的SSL

### 场景题：设计下秒杀场景

1. 用令牌桶进行限流
2. 用乐观锁进行防止超卖
3. 消息队列异步处理订单

### 如果只用mysql的话，那同一时间都有1W的请求打到mysql，那会导致mysql崩溃，那有什么解决方案吗

可以增加redis作为一级缓存，可以用布隆过滤器过滤掉已经卖完的商品

### 那你还要保证mysql和redis的一致性？

是的，这里做最终一致性就好。然后mysql和redis做double check

### 讲下布隆过滤器的原理

布隆过滤器是一个bitmap，每一位的数值只有0和1。分别表示存在或者不在。有一组hash函数，每次查询key时，会算出每个hash函数的对应hash值，然后判断该hash值所对应的bitmap是否1。都为1则可能存在，有为0则一定不存在

### 怎么降低布隆过滤器的的误判率

1. 将bitmap的大小扩大，降低误判情况
1. 发现误判就将该key，保存到set中，下次再判断key是否在误判集合
1. 增加hash函数的个数

### 介绍下有哪些推荐的算法

https://www.zhihu.com/question/20326697

推荐算法大致可以分为三类：基于内容的推荐算法、协同过滤推荐算法和基于知识的推荐算法。

### 推荐怎么做不重复的推荐

我们会对已经推荐过的数据保存到redis，然后是以userid+sessionid作为redis的key。下次相同用户相同会话，那么就会拿到已推荐数据进行过滤

### 场景题：如果redis挂了你们就会重复推送数据，已推数据不落地是吧。先要将已推数据落地，并且要支持高并发的读写场景。

### 如果你的异步落地性能不足，你会怎么改进。

