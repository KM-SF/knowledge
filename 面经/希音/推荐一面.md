### 介绍下你们推荐系统架构

我们推荐系统由两大部分组成：在线部分和离线部分。在线部分主要功能是：提供在线实时推荐。离线部分主要功能是：将推荐数据离线生成并保存。

> 在线部分由：网关服务（gateway），推荐服务（recommend-server），索引服务（index-proxy），数据服务（data-server），geo服务（geo-server）组成
>
> + 网关服务：对外提供推荐接口，限流降级和拒绝处理
> + 推荐服务：是核心服务。推荐业务都在该服务处理。主要处理有多路召回，融合，过滤，排序和重排
> + 索引服务：对外提供查询门店和优惠券的正排信息，并且做了本地缓存。防止频繁访问redis
> + 数据服务：对外提供查询召回数据和降级数据，并且做了本地缓存。
> + geo服务：根据用户的经纬度查询geo召回数据

> 离线部分：数据同步服务（data-sync），索引同步服务（index-sync）
>
> 数据同步服务：该服务将算法生成的hive表数据（召回和降级）定时灌库到redis中，提供给在线的数据服务查询
>
> 索引同步服务：业务侧将门店和优惠券正排数据定时写到kafka，再由该服务从kafka获取消息并消费写入到redis，提供给在线服务的索引服务查询

### 介绍下你的性能优化和缓存改造

> 性能调优
>
> + 背景：推荐服务每个月都需要进行月度压测，但是发现压测数据并不理想，需要分析下性能瓶颈
> + 工作职责：
>   1. CPU分析：pprof性能工具抓取profile文件，用火焰图分析得出日志库debug占用10%CPU，存在性能问题。原因是：先格式化字符串再判断是否要输出。Sprintf 是比较消耗性能的，这样会导致无用的代码消耗 CPU。解决方案是：先判断再格式化字符串。
>   2. Trace 分析：pprof 性能工具抓取 trace 文件，用 Goroutine analysis 发现上报监控数据使用
>      了大量协程，每个协程正在执行时间才不到 10%，而调度等待时间等待调度的时间高达 90%。
>      频繁创建销毁协程也会带来频繁的 gc 和 cpu 消耗 。 解决方案是：引入了协程池，将所有上报
>      监控和一些耗时较短的处理都提交到协程池中执行。
> + 项目结果：通过以上两点的性能优化，推荐服务 cpu 整体下降 15%，内存也下降了 10%

> 缓存改造
>
> + 背景：索引服务是提供查询正排数据的服务，该服务需要将数据缓存到本地进而提升服务性能。
> + 工作职责：旧的缓存方案是 groupCache 的 LRU 算法。该算法锁粒度过大，会造成 CPU 竞争降低并发能力。GC 会触发 STW，频繁 GC 严重影响性能。算法没有对内存做好限制，是根据 item数量进行保存，当存在大量 item 的 value 过大时，会撑爆内存，导致服务异常。解决方案：使用了 BigCache 第三方库，该库使用了分片机制和 map 不存指针的方式提升性。
> + 项目结果：cpu 下降了 40%，内存下降 50%，接口 p99 从 20ms 下降到了 5ms

### 推荐服务什么情况下会用到索引服务

我们推荐服务在多路召回数据后，融合过滤阶段会用到索引服务。去索引服务拿对应的正排数据，过滤掉异常状态的数据

### 你们推荐的item数量有多少

我们推荐的item数量都是支持配置的。有一个ab实验平台，上面可以对每路召回的item数量进行配置

### 你们跟算法怎么交互的

算法每天会生成T+1的召回数据到hive表。然后我们通过离线的数据同步服务，将hive表的数据定时灌库到redis中。提供给在线服务实时查询

### 你们qps有多少

高峰值会有2w的qps

### 高并发服务怎么保证高可用性

目前系统架构设计方面常用的高可用设计方案主要有以下几种：解耦，隔离，异步，备份，重试，熔断，补偿，降级，限流，多活

### 你们服务有用到容灾和降级吗

我们服务有用到降级，没有容灾。我们gateway服务会有限流和降级。会对请求recommend-server的每个接口设置限流值。如果超过该限流值，则后续请求都直接走降级，直接返回降级数据。

我们没有用到容灾。

### 你们用了哪些中间件

redis和kafka

### 你们做了什么监控，能及时发现问题

1. 对推荐请求失败率的监控
2. 对首页推荐数量为0有监控
3. 微服务之间rpc调用有失败率监控
4. 请求掉零也有监控

### 消息队列有用过吗

有用kafka

### kafka中的zk作用是什么

 ZooKeeper 是 Kafka 用来负责集群元数据的管理、控制器的选举等操作的。

比如集群都有哪些 Broker 在运行、创建了哪些 Topic，每个 Topic 都有多少分区以及这些分区的 Leader 副本都在哪些机器上等信息

控制器组件（Controller），是 Apache Kafka 的核心组件。它的主要作用是在 ApacheZookeeper 的帮助下管理和协调整个 Kafka 集群。集群中任意一台 Broker 都能充当控制器的角色，但在运行过程中，只能有一个 Broker 成为控制器，行使其管理和协调的职责。

Broker 在启动时，会尝试去 Zookeeper 中创建/controller 节点。Kafka 当前选举控制器的规则是：第一个成功创建/controller 节点的 Broker 会被指定为控制器。

### kafka怎么保证他是高可用的呢 

Kafka 基本的架构：由多个 broker 组成，每个 broker 是一个机器节点；你创建一个 topic，这个 topic可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition就放一部分数据。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。

所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader上的数据即可。一般情况只能读写 leader，follower在leader不宕机的情况下只负责同步数据。

如果某个 broker 宕机了，那个 broker 上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了
