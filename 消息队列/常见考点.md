!!!https://www.cnblogs.com/crazymakercircle/p/14367425.html!!!

------

## 1. MQ的优点

1. **”削峰填谷”**，相信大家对这四个字也非常熟悉了，可以联想一下现实生活的三峡大坝，本质起到的作用是一样的。扩展解释一下，**所谓的“削峰填谷”就是指缓冲上下游瞬时突发的流量，使其更平滑。**对于发送能力很强的上游系统，如果没有消息引擎的保护，下游系统可能会直接被压垮导致全链路服务雪崩，消息引擎可以在很大程度上避免流量的震荡。平缓的应对突发的流量冲击
2. **解耦：**在于发送方和接收方的松耦合，减少系统间不必要的交互。减少系统之间的影响，提高系统的稳定性和可扩展性
3. **异步**：异步能提高系统的响应速度和吞吐量

## 2. MQ的缺点

1. 系统可用性降低：一旦MQ宕机，整个业务就会产生影响，对高可用较高
2. 系统的复杂度提高：引入MQ后，业务的数据链路变得很复杂，需要保证消息不丢失，不重复消费，顺序消费等等
3. 数据一致性：A系统发消息，需要由B,C两个系统一同处理。如果B系统处理成功，C系统处理失败，会造成数据一致性问题

## 3. 如何设计一个MQ

答题思路：MQ作用，项目大概的样子

1. 实现一个单机的队列数据结构。高效，可扩展
2. 将单机队列扩展成为分布式队列。分布式集群管理
3. 基于topic定制消息路由策略。发送者路由策略，消费者与队列对应关系，消费者路由策略
4. 实现高效的网络通信。Netty HTTP
5. 规划日志文件，实现文件高效读写。零拷贝，顺序写。服务重启后，快速恢复
6. 定制高级功能：死信队列，延时队列，事务消息

## 4.各大MQ的对比 

#### 1）kafka

优点：吞吐量非常大，性能非常好，集群高可用

缺点：会丢数据，功能比较单一

使用场景：日志分析，大数据菜鸡

#### 2）RabbitMQ

优点：消息可靠性高，功能全面

缺点：吞吐量比较低，消息积累会严重影响性能，erlang语言不好定制化

使用场景：小规模场景

#### 3）RocketMQ

优点：高吞吐，高性能，高可靠，功能非常全面

缺点：开源版功能不如商业版。官方文档和周边生态不够成熟。客户端只支持java

使用场景：几乎是全场景

## 5. 如何保证消息的顺序

消息有序指：可以按照消息发送顺序进行顺序消费

全局有序和局部有序：MQ只需要保证局部有序，不需要保证全局有序

生产者把一组有序消息放到同一个队列当中，而消费组一次消费整个队列当中的消息

局部顺序消费通用方案：

1. 生产者讲同一组消息发送到同一个队列
2. 多个消费者并行对消息进行处理。想拿到消费的消费者对队列进行加锁（保证同一时刻只有一个消费者处理队列），处理完再释放锁
3. queue通过分段锁保证消息消费的顺序行

RocketMQ：有整体的设计。生产者指定发送的的队列，消费组监听顺序消息

RabbitMQ：要保证目标exchange只有对应一个队列，并且一个队列只对应一个消费组（降低性能）

kafka：生产者通过定制partition分配规则，将消息分配到同一个partition。topic下只有一个消费者。（降低性能）

## 6. 如何保证消息的高效读写

1. 零拷贝：kafka和RocketMQ都是通过零拷贝技术优化文件读写
2. 数据是顺序存放的，减少了磁道寻址时间
3. PageCache的预读取机制：将数据提前整块读到内存中。

## 7. 如何保证消息不丢失

![](/消息队列/images/消息丢失的场景.png)

#### 1）生产者发送消息丢失

kafka：同步发送。异步发送+回调

RocketMQ：同步发送。异步发送+回调。事务消息。

#### 2）MQ主从消息同步丢失

RocketMQ：

1. 普通集群：同步复制，异步复制。异步复制效率更高，但是有丢失消息的风险。同步复制不会丢消息。
2. Dledger集群-两阶段提交

kafka：acks参数配置成all

#### 3）MQ消息落盘丢失

RocketMQ：同步刷盘，异步刷盘。异步刷盘，性能高，有可能丢消息。同步刷盘安全性更高，效率低

kafka：kafka落盘采用异步落盘，减小落盘时间间隔，但是还是会丢消息

#### 4）MQ消费者消费消息丢失

RocketMQ：使用默认消费就行，不要采用异步方式。同步提交offset

kafka：手动提交offset

## 8. 如何保证消息消费的幂等性

其实就是如何解决消息重复消费问题。

所有MQ没有提供主动解决幂等性的机制，需要消费者自己控制，根本原因是网络不可达

场景：

1. 发送时消息重复：当生产者成功发送一条消息到broker，当出现网络问题，导致broker没有回应ACK，生产者认为失败了，就再次发送消息。这个情况就出现了两条相同消息
2. 消费时消息重复：当消费者已经完成业务处理，需要给MQ回应ACK。此时网络抖动，导致broker没收到ACK，不更新offset。为了保证消息至少消费一次，broker会将消息再次投递给消费者，这种情况就处理了两次相同消息。

解决方案：

1. 给消息带一个全局唯一ID
2. 消费者消费该消息之前先判断该全局ID是否已经保存过（保存过则代表已经消费）
3. 没有则消费消息，有则跳过

## 9. MQ如何保证分布式事务的最终一致性

分布式事务：业务相关的多个操作，保证多个操作都成功或者都失败

最终一致性：处理业务过程中，允许多个操作中有部分操作有其他状态，但是最终只要多个操作最终都成功或者都失败

MQ中要保证事务的最终一致性，需要做到两点：

1. 生产者要保证100%消息投递，事务消息机制
2. 消费者需要保证幂等消费。唯一ID+业务自己实现幂等性

## 10. 数据传输的事务定义有哪三种

所谓的消息交付可靠性保障，是指Producer和Consumer要处理的消息提供什么样的承诺。常见的承诺有以下三种：

- 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。

- 至少一次（at least once）：消息不会丢失，但有可能被重复发送。

- 精确一次（exactly once）：消息不会丢失，也不会被重复发送。（幂等性和事务可以实现）

## 11. 消息积压

### 大量消息在 mq 里积压了几个小时了还没解决

几千万条数据在 MQ 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。

一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。

一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：

- 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
- 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
- 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
- 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。