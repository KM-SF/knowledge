## 1. 持久化机制

+ commitLog：commitlog目录中存放着很多的mappedFile文件，**当前Broker中的所有消息都是落盘到这些mappedFile文件中的**。mappedFile文件大小为1G（小于等于1G）一个Broker中仅包含一个commitlog目录，无论当前Broker中存放着多少Topic的消息，这些消息都是被**顺序写入**到了mappedFile文件中的。**这些消息在Broker中存放时并没有被按照Topic进行分类存放。**![](/消息队列/\RocketMQ/images/消息单元.png)

+ consumequeue：每个Topic在~/store/consumequeue中创建一个目录，目录名为Topic名称。**在该Topic目录下，会再为每个该Topic的Queue建立一个目录，目录名为queueId**。每个目录中存放着若干consumequeue文件，**consumequeue文件是commitlog的索引文件，可以根据consumequeue定位到具体的消息。**![](/消息队列/\RocketMQ/images/consumequeue索引条目.png)

+ indexFile：根据**key或者时间区间**进行消息查询的功能。indexFile文件以创建时的时间戳命名

一个brocker的是所有队列公用一个日志数据文件（commitlog），避免了kafka的分区数过多导致日志数据文件过多，从而导致磁盘IO读写压力较大造成性能瓶颈。RocketMQ影响性能的是对commitlog文件的读取，读取消息时会产生大量的随机访问，而随机访问会严重影响性能

#### 消息写入

一条消息进入到Broker后经历了以下几个过程才最终被持久化。

+ Broker根据queueId，获取到该消息对应索引条目要在consumequeue目录中的写入偏移量，即QueueOffset
+ 将queueId. queueOffset等数据，与消息一起封装为消息单元
+ 将消息单元写入到commitlog
+ 同时，形成消息索引条目
+ 将消息索引条目分发到相应的consumequeue

#### 消息拉取

当Consumer来拉取消息时会经历以下几个步骤：

+ Consumer获取到其要消费消息所在Queue的**消费偏移量offset**，计算出其要消费消息的**消息offset**。

> 消费offset即消费进度，consumer对某个Queue的消费offset，即消费到了该Queue的第几条消息
> 消息offset = 消费offset + 1

+ Consumer向Broker发送拉取请求，其中会包含其要拉取消息的Queue. 消息offset及消息Tag。
+ Broker计算在该consumequeue中的queueOffset。queueOffset = 消息offset * 20字节（一个索引单元20字节）
+ 从该queueOffset处开始向后查找第一个指定Tag的索引条目。
+ 解析该索引条目的前8个字节，即可定位到该消息在commitlog中的commitlog offset
+ 从对应commitlog offset中读取消息单元，并发送给Consumer

## 2. 怎么实现顺序消息

默认情况下MQ不能保证顺序消费，需要程序保证发送和消费的是同一个queue，单线程才能实现，多线程消费也无法保证

发送顺序：发送端自己业务逻辑保证先后顺序，发往一个固定的queue

mq：queue本身就是顺序追加写，RocketMQ保证了一个queue统一时间只有一个consumer消费。通过加锁实现（超时会释放锁，需要续约），consumer上的消费有一个定时任务，每隔一段时间向broker发送延迟加锁时间

消费端：

+ pull模式：消费者需要自己维护需要拉取的queue，一次性拉取的消息时顺序的，需要自己保证消费顺序（不能用多线程消费）
+ push模式：消费端得到消息时broker自己主动推送，需要我们自己去实现监听方式消费消息（串行消费）。

## 3. 如何保证不丢消息

#### 生产者

+ 同步阻塞的方式发送消息，加上失败重试机制，可能broker存储失败，可以通过查询确认
+ 异步发送需要重写回调方法，检查发送结果，失败了也要重试
+ ack机制：可能存储commitlog，consumequeue失败，此时对消费组不可见。（依赖broker的刷盘机制）

#### broker

+ 同步刷盘，集群模式下采用同步复制，会等待slave复制完成才返回确认

#### 消费者

+ offset手动提交，消息消费保证幂等性

## 4. 事务消息原理

依赖TransactionListener接口

+ executeLocalTransaction方法会再发送消息后调用，用于执行本地事务，如果本地事务执行成功，rocketmq再提交消息
+ checkLocalTransaction用于对本地事务做检查，rocketmq依赖此方法做补偿

通过两个内部的topic来实现对消息的两阶段提交

1. prepare：将消息（消息上带有事务标记） 投递刚到一个名为RMS_SYS_TRANS_HALF_TOPIC的topic中，而不是投递到真正的topic中

2. commit/rollback：producer再通过TransactionListener的executeLocalTransaction方法执行本地事务，当producer的executeLocalTransaction处理成功或者失败后，producer会向broker发送commit或者rollback命令

   + 如果是commit：broker会将投递到RMS_SYS_TRANS_HALF_TOPIC中的消息投递到真实的topic中，然后再投递一个表示删除消息到RMS_SYS_TRANS_HALF_TOPIC中，表达当前事务已经完成

   + 如果是rollback：则没有投递到真实topic的过程，只需要投递表达要删除的消息到RMS_SYS_TRANS_HALF_TOPIC

3. 消费组和消费普通消息一样，消费事务消息

## 5. 什么是死信队列？什么是延时队列？

#### 1）死信队列

死信队列也是一个消息队列，它是用来存放没有消费成功的消息（重试失败一定次数），通常可以用来作为消息重试

#### 2）延时队列

延时队列就是用来存放需要指定时间被处理的消息队列，通常可以用拉力处理一些具有过期性操作的业务，比如十分钟内未支付则取消

## 6. RocketMQ 由哪些角色组成

生产者（Producer）：负责产生消息，生产者向消息服务器发送由业务应用程序系统生成的消息。

消费者（Consumer）：负责消费消息，消费者从消息服务器拉取信息并将其输入用户应用程序。

消息服务器（Broker）：是消息存储中心，主要作用是接收来自 Producer 的消息并存储， Consumer 从这里取得消息。

名称服务器（NameServer）：用来保存 Broker 相关 Topic 等元信息并给 Producer ，提供 Consumer 查找 Broker 信息。

## 7. RocketMQ消费模式有几种

#### 1）集群消费

- 一条消息只会被同Group中的一个Consumer消费
- 多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据

#### 2）广播消费

- 消息将对一个Consumer Group 下的各个 Consumer 实例都消费一遍。即即使这些 Consumer 属于同一个Consumer Group ，消息也会被 Consumer Group 中的每个 Consumer 都消费一次。

## 8. RocketMQ如何实现分布式事务

1. 生产者向MQ服务器发送half消息。
2. half消息发送成功后，MQ服务器返回确认消息给生产者。
3. 生产者开始执行本地事务。
4. 根据本地事务执行的结果（`UNKNOW`. `commit`. `rollback`）向MQ Server发送提交或回滚消息。
5. 如果错过了（可能因为网络异常. 生产者突然宕机等导致的异常情况）提交/回滚消息，则MQ服务器将向同一组中的每个生产者发送回查消息以获取事务状态。
6. 回查生产者本地事物状态。
7. 生产者根据本地事务状态发送提交/回滚消息。
8. MQ服务器将丢弃回滚的消息，但已提交（进行过二次确认的half消息）的消息将投递给消费者进行消费。

`half Message`：预处理消息，当broker收到此类消息后，会存储到`RMQ_SYS_TRANS_HALF_TOPIC`的消息消费队列中

`检查事务状态`：Broker会开启一个定时任务，消费`RMQ_SYS_TRANS_HALF_TOPIC`队列中的消息，每次执行任务会向消息发送者确认事务执行状态（提交、回滚、未知），如果是未知，Broker会定时去回调在重新检查。

超时：如果超过回查次数，默认回滚消息。

也就是他并未真正进入Topic的queue，而是用了临时queue来放所谓的`half message`，等提交事务后才会真正的将half message转移到topic下的queue。
