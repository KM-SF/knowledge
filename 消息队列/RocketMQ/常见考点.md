## 1. 持久化机制

+ commitLog：commitlog目录中存放着很多的mappedFile文件，**当前Broker中的所有消息都是落盘到这些mappedFile文件中的**。mappedFile文件大小为1G（小于等于1G）一个Broker中仅包含一个commitlog目录，无论当前Broker中存放着多少Topic的消息，这些消息都是被**顺序写入**到了mappedFile文件中的。**这些消息在Broker中存放时并没有被按照Topic进行分类存放。**![](/消息队列/\RocketMQ/images/消息单元.png)

+ consumequeue：每个Topic在~/store/consumequeue中创建一个目录，目录名为Topic名称。**在该Topic目录下，会再为每个该Topic的Queue建立一个目录，目录名为queueId**。每个目录中存放着若干consumequeue文件，**consumequeue文件是commitlog的索引文件，可以根据consumequeue定位到具体的消息。**![](/消息队列/\RocketMQ/images/consumequeue索引条目.png)

+ indexFile：根据**key或者时间区间**进行消息查询的功能。indexFile文件以创建时的时间戳命名

一个brocker的是所有队列公用一个日志数据文件（commitlog），避免了kafka的分区数过多导致日志数据文件过多，从而导致磁盘IO读写压力较大造成性能瓶颈。RocketMQ影响性能的是对commitlog文件的读取，读取消息时会产生大量的随机访问，而随机访问会严重影响性能

#### 消息写入

一条消息进入到Broker后经历了以下几个过程才最终被持久化。

+ Broker根据queueId，获取到该消息对应索引条目要在consumequeue目录中的写入偏移量，即QueueOffset
+ 将queueId、queueOffset等数据，与消息一起封装为消息单元
+ 将消息单元写入到commitlog
+ 同时，形成消息索引条目
+ 将消息索引条目分发到相应的consumequeue

#### 消息拉取

当Consumer来拉取消息时会经历以下几个步骤：

+ Consumer获取到其要消费消息所在Queue的**消费偏移量offset**，计算出其要消费消息的**消息offset**。

> 消费offset即消费进度，consumer对某个Queue的消费offset，即消费到了该Queue的第几条消息
> 消息offset = 消费offset + 1

+ Consumer向Broker发送拉取请求，其中会包含其要拉取消息的Queue、消息offset及消息Tag。
+ Broker计算在该consumequeue中的queueOffset。queueOffset = 消息offset * 20字节（一个索引单元20字节）
+ 从该queueOffset处开始向后查找第一个指定Tag的索引条目。
+ 解析该索引条目的前8个字节，即可定位到该消息在commitlog中的commitlog offset
+ 从对应commitlog offset中读取消息单元，并发送给Consumer

## 2. 怎么实现顺序消息

默认情况下MQ不能保证顺序消费，需要程序保证发送和消费的是同一个queue，单线程才能实现，多线程消费也无法保证

发送顺序：发送端自己业务逻辑保证先后顺序，发往一个固定的queue

mq：queue本身就是顺序追加写，RocketMQ保证了一个queue统一时间只有一个consumer消费。通过加锁实现（超时会释放锁，需要续约），consumer上的消费有一个定时任务，每隔一段时间向broker发送延迟加锁时间

消费端：

+ pull模式：消费者需要自己维护需要拉取的queue，一次性拉取的消息时顺序的，需要自己保证消费顺序（不能用多线程消费）
+ push模式：消费端得到消息时broker自己主动推送，需要我们自己去实现监听方式消费消息（串行消费）。