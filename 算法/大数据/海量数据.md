# 海量数据处理的技巧

注意：需要跟面试官问清楚场景：内存消耗，数据量，是否允许误差

1. **hash分流**：hash函数可以将数据按照种类均匀分流（一般是key哈希->val->取模分流）
2. 布隆过滤器：用于集合的建立和查询，并可以节省大量的空间，存在误差
3. 一致性hash解决数据服务器负载管理问题
4. 利用并查集进行并行计算
5. **位图**：位图解决某一范围的数字出现的情况，并且可以节省大量空间
6. **范围统计**：利用分段统计思想，并进一步节省大量空间
7. **大小根堆**：利用堆，外排序做多个处理单元的结果整合

# 如何在40亿数据中找到最多出现的一个数

### 问题：

在1G的内存中，查找40亿的无符号整数中如何找到出现次数最多的一个数

### 常规思想：

用一个hashmap保存每个数出现的情况<key,cnt>。这样就知道每个数出现的次数。

但是上面的思路是有问题的：因为hashmap保存的key和value，分别是4个字节。那一对数据就要8个字节。在40亿数据中，最坏的情况没有重复的情况，那么需要的内存就是：40亿*8字节=32G。

**32G已经超过我们限定的最大内存，所以这个思路不行**

### 解法思路：哈希分流

通过上面的思路，我们可以得知hashmap占用内存大小：只跟不同元素个数有关，跟相同元素出现多少次无关。

所以我们通过以下方法解决：

1. 对每个数都进行hash函数，会得到对应的hash值。（相同数通过相同hash函数得到的hash值一定一样）
2. 然后对上面的hash值对100取模，得到这个hash值取模后的范围在0~99之间。
3. 上面得到取模后的结果0~99，然后将这个数放到对应的0~99文件中（会存在不同hash值取模后数值一样）
4. 那么40亿的数据就会均分在0~99的文件内。最坏情况一个文件里面的数字都不一样，然后全部加载到内存后大概需要的内存是：40亿/100*8字节=0.32G。最坏情况需要的内存大小没超过1G
5. 将1个文件的数据全部加载到内存，然后存到hashmap中。这样就知道这个文件每个数出现次数的情况。从而得到这个文件出现最大的数值MaxVal1
6. 0~99个文件依次执行步骤5，可以得到这个100个文件的最多次数的数值（MaxVal1~MaxVal100）。然后再对这100个数值做比较就知道最多出现的次数了。

# 如何在40亿数据中找到所有未出现的数字

### 问题：

32位无符号整数的范围是0~2^32-1，现在有一个正好包含40亿个无符号整数的文件，所以整个范围中必然存在没有出现过的数。可以使用最多`1G`的内存，怎么找到所有未出现的过

### 思路：bitmap

我们可以用一个bit类型表示某个数出现或者没出现。

因为无符号整数范围是 0~2^32-1，即2^32个元素，所以可以用2^32个bit类型的数组（bit b[2^32]）来表示每一位上的数是否出现过。数字就是对应bit的下标，然后设置成1

内存消耗：2^32/8 约等于 500M

### 进阶：内存只有3KB大小，如何找到随意一个未出现的数字（范围统计）

1. 一个int类型占用4字节，3KB的内存大小可以申请：3000/4大于700多个int类型。
2. 700最接近512（2^9）大小，所以申请一个int[512]大小的数组。
3. 将2^32个数字全部切割成512份，分别保存在int[512]的数组里。
4. 那么2^32/512 = 8388608，则一个数组中的每一个元素表示出现在该范围的数字有多少个。（例如：0~8388608的数字保存再第一个元素，8388609~8388608*2保存再第二远。。。）
5. 如果出现在这个范围内的数，则对应的数组元素加一（x/8388608结果就是对应的下标）（例如：100，则下标num[0]++。10000则num[0]++。8388609则num[1]++）
6. 40亿数字遍历完以后，正常情况num[idx]的大小应该是8388608，但是因为只有40亿个数字，所以会有某一个num[idx]的大小不等于8388608。
7. 在继续对num[idx]的范围进行切割，继续划分。再重复步骤3~6，直到出现结果。

# 100亿个URL大文件，找到重复URL

### 问题：

有一个100亿个URL的大文件，假设每个URL占用64B，请找到其中所有重复的URL

### 思路：hash分流

1. 一个URL占64B，即8字节，那么100亿个URL，则需要100亿*8字节=80G内存。所以一台机器基本不可能保存的下，所以用hash分流
2. 将一个URL用一个hash函数获得一个hash值，然后取模100，保存到对应的一个文件中。即可以的到100个文件
3. 那么一个文件平均情况需要处理1亿个URL，0.8G内存，然后再对每个小文件单独处理
4. 使用hasset保存已经存在的URL，出现一个URL就判断是否在hashset中，如果存在则重复，不存在则不重复
5. 然后再汇总100个文件得到结果

# 100亿词汇量找到TOP100的词汇

### 问题：

某公司一天的用户搜索词汇是海量（百亿的词汇），请设计一种求出每天热门TOP100的词汇可行方法

### 思路：hash分流+大根堆

1. 100亿的词汇量，一个词汇量算4字节，也需要100亿*4字节=32内存，所以一台机器放不下，进行hash分流
2. 对一个词汇用hash函数获得一个hash值，再进行100取模，保存到某一个文件中，然后再对单个小文件进行处理
3. 使用大根堆的方式保存单个小文件的所有词汇，所以单个小文件，就形成了大根堆的top是最热门数据
4. 然后再用整合大根堆对这个100个小文件进行整合。
5. 每个小文件的大根堆的堆顶元素，放进整合大根堆（100个小文件就放进了100个元素）
6. 然后对整合大根堆，弹出堆顶元素，则这个元素则是最多出现的次数。
7. 弹出的堆顶元素知道他是属于那个小文件的，再将这个小文件的大根堆堆顶再放到整合大根堆中。
8. 依次类推6，7步骤。直到整合大根堆弹出100个元素就知道TOP100。

# 40亿个无符号整数，找到所有出现2次的数

### 问题：

32位无符号整数的范围是0~2^32-1，现在有40亿个无符号整数，最多使用1G内存，找到所有出现两次的数

### 思路：

#### 1. 哈希分流+hash统计

使用hash函数进行分流，再对每个小文件中的数字进行hash统计就可以得到结果

#### 2. 使用bitmap

1. 可以使用两个bit数组（A,B），两个bit数组大小都为2^32，bit A[2^32]。
2. 然后用A和B两个bit位表示出现情况，即A0B0=0次，A1B0=1次，A0B1=2次，A1B1=2次以上
3. 然后要计算这个数字的作为A,B的下标，进行设置0和1操作，就知道这个数字出现了几次

## 找到40亿个整数的中位数

### 问题：

只能使用10KB的大小，找到40亿个整数的中位数

### 思路：范围统计

1. 使用10KB去申请int类型的数组，10000/4=2500。然后申请的数组大小需要是2的次方，即2048离2500最近，所以申请Int[2048]数组
2. 2^32/2048=2097152。所以数组每个元素表示2097152\*idx~2097152\*(idx+1)的范围。（例如num[0]的范围为0~2097152）
3. 遍历40亿个数，判断每个数落在哪个范围，即可以得到对应的下标（x/2097152），对应数组下标值++
4. 遍历完可以得到数组每个元素的值，num0=1亿，num1=20亿，那么中位数就落在num1中，因为num0+num1=21亿>20亿
5. 然后再对num1进行切割，重复步骤2，3，4。直到求出结果

# 10G的无序文件转换成10G有序文件

### 问题：

10G的无序文件，里面保存的是int数值。通过一些方法输出一个新文件，新文件需要保留原来旧文件数值，并且要有序。

### 思路：hash分流+堆

1. 是用hash分流将数值分流到100个小文件中，然后再单独小文件处理
2. 对小文件先用hashmap进行统计，统计每个数值出现的次数
3. 然后再对上面hashmap<val,cnt>保存到大根堆中，以数值大小进行排序
4. 然后再对着100个小文件进行合并，取出100个小文件中的最大保存到整合大根堆
5. 然后整合大根堆的堆顶输出到新文件（val和cnt）
6. 然后再对val所在的小文件，弹出堆顶到整合大根堆
