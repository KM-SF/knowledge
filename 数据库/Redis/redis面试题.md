##  一. 底层数据结构

### 1. 简单动态字符串SDS

所有的key类型都是sds类型

```C++
struct sds{
	int len;     // buf数组已经使用字符串的长度
	int free;    // buf数组未使用的长度
	char buf[];  // 保存字符串
};
```

#### 1.1 为什么要使用SDS，而不使用C字符串

##### 1.1.1 背景：

Redis作为缓存数据库，`数据经常会被修改`，造成`内存重分配`，影响性能。

##### 1.1.2 原因详述

1. SDS有len成员变量，可以在**O(1)**的时间复杂度**获取长度信息**。即使反复执行strlen命令，也不会对系统性能造成任何影响
2. 更安全：杜绝**缓冲区溢出**。当SDS执行strcat/strcpy等函数时，会先检查free是否够用，不够用时，就扩增
3. 减少**重分配次数**
   - **扩增**：SDS会多分配free的空间，当需要扩容时，若free空间足够，直接改变len/free的值就可以
   - **缩短**：缩短时，直接修改free的值，不需要释放旧空间，申请小的新空间存放新字符串

### 2. 哈希表

所有的kv数据都保存到这个哈希数组中。

dictEntry变量保存每个kv数据

#### 2.1. 数据结构

```cc
// 字典
struct dict {
	dictht ht[2];   // 2个哈希表: ht[0]正常情况下使用, ht[1]在rehash时使用
    int rehashidx;  // rehash索引 (没进行rehash时，该值为-1)
}
```

```c
// 哈希表元素
typedef struct dictEntry {
	void* key;  // 键（实际就是sds类型）
	union {     // 值
		void* val;		// redisObject
		uint64_t u64;
		int64_t  s64;
	} v;
	struct dictEntry* next; // 指向下一个哈希节点，形成链表
}dictEntry_t;

// 哈希表
struct dictht {
	dictEntry_t **table;  // 数组，每个元素都是dictEntry_t*，它是一个链表头，所有冲突的key挂在相同链表上
	unsigned long size;   // 哈希表容量大小
	unsigned long used;   // 当前已经使用大小
}
```

```c
// 保存value
typedef struct redisObject {
	unsigned type:4;			// value对应的类型：string，list,set,zset,hash。。。	
	unsigned encoding:4;		// 数据的存储格式。因为一个类型可能有多种存储格式。例如下面ptr取值
	unsigned lru:24;
	int refcount;
	void *ptr;					// 数据
}// 一个变量需要的空间：4字节（type，enconding，lru）+4字节（refcount）+4字节（void*）

/*
ptr取值类型：
1.string:
	1.1 int	value的值是数字
	1.2 row	大于44个字符
	1.3 embstr	44个字符以内（跟cpu缓存有关）
2.list:
	2.1 quicklist
	2.2 ziplist
3.hash:
	3.1 hashtable
	3.2 ziplist
4.set
	4.1 hashtable
	4.2 intset
5.zset
	5.1 ziplist
	5.2 skiplist
*/
```

#### 2.2 数据操作流程

1. 先用key通过hash函数计算hash值
2. 然后将hash值取模数组大小得到对应的hash数组的哪个元素
3. 然后将dictEntry变量（保存kv数据）使用头插法插入到这个数组元素的链表中**【插入】**
4. 得到hash数组元素后，遍历链表每个元素的key**【查询/删除】**

#### 2.3 rehash（重新散列）

- 背景：哈希表中键值对的增加/减少，都可能导致rehash（为了使哈希表的 `负载因子` 维持在合理的范围内）：一般进行2倍扩充（算法导论中的平摊分析）

- rehash过程（渐进式rehash）

  - ht[1]分配空间，新建一个空的哈希表
  - rehash索引计数器（**rehash_index**），由-1变为0，表示rehash正式开始
  - 将ht[0]中的元素，rehash重新散列到ht[1]上
    - 每次一个(key,value)键值对rehash成功后，rehash索引计数器都+1
  - 当所有的ht[0]都rehash到ht[1]中后，ht[0]被清空，此时将ht[0],ht[1]**交换**，rehash结束，最后将rehash索引设为-1

+ 在rehash过程中，**新增加的(key,value)键值对**，怎么处理？
    - 答：会直接rehash到ht[1]上，这样做，会保证ht[0]只减不增


### 3. 压缩列表ziplist

#### 3.1 使用场景

列表键、哈希键: 含有少数的键，且键是“短整型”、“短字符串”

#### 3.2 优点

节省内存，实现简单，是连续内存块的顺序存储（有点像变长数组，它通过长度划分每个节点）

#### 3.3 每个 `压缩列表节点` 构成

- 前一个节点的长度pre_len 当前节点的长度、类型 
- 当前节点的数据内容

#### 3.4 连锁更新

当插入和删除元素时，可能会导致连锁更新：

1. （全small）原ziplist节点都是长度小于256：当在idx插入大于256的节点时，idx+1后面的节点e1的成员pre_len无法保存前一个节点的长度，因此，要重分配内存。这样e1内存就扩增了，因为是顺序存储，所以e2、e3后面的元素都要向后移动（更新） 

2. （big1、small、big2）：当删除small时，将会引起big2后面的节点连锁更新

### 4. 跳跃表skipList

https://blog.csdn.net/qq_34412579/article/details/101731935

#### 4.1 结构

是一个**多层次**的链表，每层节点的**next跨度**大小都不同，从上到下依次减小

#### 4.2 时间复杂度

- 性能可以和AVL树媲美，且实现简单
- 最好O（lgN）
- 最差O（N） 

#### 4.3 空间复杂度

跳表通过建立索引，来提高查找元素的效率，就是典型的“空间换时间”的思想，所以在空间上做了一些牺牲，假如原始链表包含 n 个元素，则一级索引元素个数为 n/2、二级索引元素个数为 n/4、三级索引元素个数为 n/8 以此类推。所以，索引节点的总和是：n/2 n/4 n/8 … 8 4 2 = n-2，**空间复杂度是 O(n)**。

#### 4.4 使用场景

zset有序集合键

#### 4.5 Redis为什么使用skiplist，不使用红黑树

1. **范围查找**的时候，平衡树比skiplist操作要复杂。

   > 在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。
   >
   > 而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。

2. 平衡树的插入和删除操作可能**引发子树的调整**，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。

3. 从**内存占用**上来说，skiplist比平衡树更灵活一些。

   一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。

4. 查找单个key，skiplist和平衡树的时间复杂度都为O(logn)，大体相当

5. 从**算法实现难度**上来比较，skiplist比平衡树要简单得多。

##  二. Redis五种数据结构

#### 1. 字符串键string

可以存储最简单的数据，缓存简单的字符串。字符串类型的value最大能容纳**512M** 

- int
- embstr
- raw

#### 2. 列表list

存储多个数据，可以当做栈或者队列，有点像双端队列。quicklist有个头结点和尾节点，分别是指向链表的头和尾。链表中每个元素则是ziplist

- ziplist
- quicklist               

#### 3. 哈希hash

key-value形式。底层实现为一个字典（dict），也是redisdb用来存储kv的数据结构。

当数据量比较小，或者单个元素比较小时，底层是用ziplist。

数据量和数据大小超过阈值时则改用hash-table

- ziplist
- hash-table            

#### 4. 集合set

类似列表，存储多个元素，但是不能重复。可以进行交集，并集，差集等操作。

无序的，自动去重的集合数据类型。底层数据结构为一个value为null的字典。

当数据可以用整型表示时，set集合将编码为intset数据结构。

如果元素个数少于阈值或者元素无法用整数表示时，则改用hash-table

- intset
- hash-table

#### 5. 有序集合zset

有序（优先score排序，score相同则用元素字典序），自动去重的集合数据类型。底层实现是用：字典+跳表。

当数据比较少时，用ziplist结构

数据量超过一个阈值时，则用跳表

- ziplist
- 跳跃表 

## 三. Redis的过期键的删除策略

https://www.cnblogs.com/bruceChan0018/p/15768823.html

Redis是key-value的数据库，我们可以设置Redis中缓存的key过期时间。Redis的过期策略就是指当Reids中缓存中Key过期了，Redis如何处理

+ 惰性过期：只有当访问一个key时，才会判断key是否过期，过期则清理。该策略可以最大化的节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被删除，占用大量内存。
+ 定时过期：对每个key开启一个定时器，定时器到时间时，删除过期数据 。对内存相当的友好，不会浪费多余的内存。但是需要消耗CPU资源
+ 定期过期：每隔一定的时间，会扫描**一定数量**的数据库的expire字典中一定数量的key，并且清除其中过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使用CPU和内存资源达到最优的平衡效果

expire字典会保存所有设置了过期时间的key的过期时间数据。其中key是指向键空间中的某个键的指针，value是该键的毫秒精度的时时间戳表示过期时间。键空间是指该redis中保存的所有键

**Redis同时使用了惰性过期和定期过期两种策略**

## 四. Redis的淘汰机制

当redis的内存超过最大允许的内存之后，redis会触发内存淘汰策略，删掉一些不常用的key

> noeviction：不淘汰任何数据，当内存不足时，执行新增操作会报错，默认策略
>
> allkeys-lru：淘汰整个键值中最久未使用的键值
>
> allkeys-lfu：淘汰整个键值中最少使用的键值
>
> allkeys-random：随机淘汰任意键值
>
> volatile-lru：淘汰所有设置了过期的键值中最久未使用的键值
>
> volatile-lfu：淘汰所有设置了过期的键值中最少使用的键值
>
> volatile-random：随机淘汰所有设置了过期的键值
>
> volatile-ttl：优先淘汰更短过期时间的键值

## 五. 持久化机制RDB/AOF

### 1. redis有哪些持久化机制

redis提供了两种持久化机制：RDB和AOF

RDB：保存某一时间点之前的快照数据。恢复数据时直接将快照数据解析到内存

AOF：指所有命令行记录以redis命令请求协议的格式完全持久保存在aof文件中。恢复数据时，则根据redis命令依次执行。

混合持久化：可以通过aof-use-rdb-preamble yes开启。rdb和aof混合的方式，aof文件的头部添加了rdb的数据

### 2. RDB

#### 2.1 RDB快照有哪些触发方式

1. 为通过配置参数：通过一定时间周期内，命令执行个数，超过阈值则执行快照生成。（实际快照生成原理跟下面bgsave原理一样）

> save 900 1
> save 300 10
> save 60 10000

2. 通过手动执行bgsave/save。触发生成快照。bgsave会fork子进程，在子进程中完成快照生成。save则是阻塞主进程进行生成。

#### 2.2 RDB持久化流程

1. 主进程通过fork创建一个子进程
2. 子进程跟主进程共享同一片内存区域。（**读时共享，写时拷贝**）
3. 主进程仍然能进行业务处理。因为写入操作时，为另外一片新内存空间。

#### 2.3 RDB优缺点

##### 2.3.1 优点

1. 性能最大化，fork子进程来完成写操作，让主进程继续处理命令。使用单独子进程完成持久化，保证redis的高性能
2. 当重启恢复数据的时候，数据量比较大时，redis直接解析rbd二进制文件，生成对应的数据存在内存，比AOF的启动效率更高

##### 2.3.2 缺点

1. 数据安全性低，会丢数据。RDB周期性的进行持久化，如果持久化期间redis故障了，则会发生丢数据情况。所以不适合对数据要求严谨的时候
2. fork是读时共享，写时拷贝。所以如果发生写请求时，会触发页异常中断，kernel会触发内存复制。于是父子进程各自维护一份内存空间。在大量写请求时，会发生大量的页异常中断，这样消耗大量性能在复制上面

### 3. AOF

#### 3.1 AOF持久化流程

1. 需要开启appendonly yes开启
2. 命令写入时，会将命令写入到AOF缓存区
3. 根据同步策略，将AOF缓存区的数据刷到AOF文件中 
4. 刷到AOF文件时，可能会触发重写机制

> AOF同步策略
>
> 1. no 表示操作系统进行数据缓存同步到磁盘，不主动刷盘
> 2. always：表示每次写请求都会刷到磁盘
> 3. everysec：每一秒刷盘一次

#### 3.2 AOF重写机制

随着命令不断写入到AOF，文件会越来越大。为了解决这个问题，redis引入了AOF写入机制压缩文件大小。

AOF文件重写是把**redis进程内存的数据**转化为写命令同步到新AOF文件的过程。

AOF重写机制可以通过**手动触发（bgrewriteaof）**和**自动触发**

#### 3.3 优缺点

优点：数据安全，aof持久化可以配置appendfsync属性，有always，每次进行写操作都写到aof文件中

缺点：数据集大的时候，比rdb启动效率低

## 六. 高可用

高可用方案：主从复制，哨兵模式，cluster模式，sharding模式

### 1. 主从复制

#### 1.1 概述

+ 通过执行slaveof命令或者设置slaveof选项，让一个服务器去复制另外一个服务器的数据。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。**而从数据库一般是只读的，并接受主数据库同步过来的数据。**一个数据库可以拥有多个从数据库，而一个从数据库只能有一个主数据库
+ 正常情况下，主机提供服务，并将数据同步到备份机器；当主机宕机后，备机立即开始服务 。master宕机后，通过<u>选举投票</u>方式选择出新的master，继续提供服务。
+ 实现读写分离，提高并发性
+ 复制的方式有两种：**全量复制**和**增量复制**

#### 1.2 全量复制：

  + 主节点通过bgsave命令fork子进程进行RDB持 久化，RDB持久化过程是非常消耗CPU，内存（页表复制），硬盘IO
  + 主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来非常大的消耗
  + 从节点清空老数据，载入新RDB文件（载入过程是阻塞的，无法响应客户端命令）。
  + 如果从节点执行了bgrewriteaof，也会带来额外的消耗（aof复制也需要消耗资源）

#### 1.3 增量复制：

  + 复制偏移量：执行复制的双方，主从节点分别会维护一个复制偏移量offset
  + 复制积压缓存区：主节点内部维护一个固定长度的，先进先出队列作为复制积压缓冲区，**当主从节点offset的差距超过换缓存区长度时，将无法进行增量复制，只能执行全量复制**
  + 服务器运行ID（runid）：每个节点都有其运行ID，运行ID由节点在启动时自动生成，主节点会将自己的运行ID发送给从节点。从节点会将主节点的runid保存起来。从节点断开重连的时候，就是根据运行ID来判断同步的进度：
    + 如果从节点保存的runid与主节点现在的runid相同，说明主从节点还保持联通，主节点会继续尝试使用增量复制的方式（到底能不能使用增量复制还要看offset和复制积压缓存区的情况）
    + 如果从节点保存的runid与住节点现在的runid不同，说明从节点在断线前同步的redis节点并不是当前的主节点，只能进行权力复制

  > 过程原理图：![过程原理图](/数据库/Redis/image/主从复制原理图.png)

### 2. 哨兵模式

sentinel，哨兵是redis集群中非常重要的一个组件，主要有以下功能：

+ 集群监控：负责监控redis master和slave进程是否正常工作
+ 消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员
+ 故障转移：如果master node挂掉了会自动转移到slave node上
+ 配置中心：如果故障转移发生了，通知client客户端新的master地址

哨兵用于实现redis集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协作工作。

+ 故障转移时，判断一个master node是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举
+ 即使部分哨兵节点挂了，哨兵集群还是能正常工作
+ 哨兵通常需要3个实例来保证自己的健壮性
+ 哨兵+redis主从的部署架构，不能保证数据零丢失，只能保证redis集群的高可用性

### 3. Redis Cluster

Redis Cluster是一种服务端sharding技术，3.0版本开始正式提供了。采用了slot（槽）的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询的请求发送到正确节点上执行

#### 3.1 方案说明

+ 通过哈希的方式，将数据分片，每个节点均分存储一定的哈希槽（哈希值）区间的数据，默认分配了16384个槽位
+ 数据分片存储在多个互为主从的多个节点上（16384个槽均分到每个节点上）
+ 数据先写入主节点，再同步到从节点（支持配置为阻塞同步）
+ 同一分片多个节点间的数据不保证强一致性
+ 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点
+ 扩容时需要把旧节点的数据迁移一部分到新节点
+ 在redis cluster架构下，每个redis要放开两个端口，例如：一个6379，另外一个就是加上1W的端口16379。另外一个端口是用来进行节点间通信的，也就是cluster bus的通信。用来进行故障检测，配置更新，故障转移授权。
+ cluster bus用了另外一种二进制的协议，gossip协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间

#### 3.3 Redis cluster 的高可用与主备切换原理

Redis cluster 的高可用的原理，几乎跟哨兵是类似的。

##### 3.3.1 判断节点宕机

如果一个节点认为另外一个节点宕机，那么就是 `pfail` ，**主观宕机**。如果多个节点都认为另外一个节点宕机了，那么就是 `fail` ，**客观宕机**，跟哨兵的原理几乎一样，sdown，odown。

在 `cluster-node-timeout` 内，某个节点一直没有返回 `pong` ，那么就被认为 `pfail` 。

如果一个节点认为某个节点 `pfail` 了，那么会在 `gossip ping` 消息中， `ping` 给其他节点，如果**超过半数**的节点都认为 `pfail` 了，那么就会变成 `fail` 。

##### 3.3.2 从节点过滤

对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。

检查每个 slave node 与 master node 断开连接的时间，如果超过了 `cluster-node-timeout * cluster-slave-validity-factor` ，那么就**没有资格**切换成 `master` 。

##### 3.3.3 从节点选举

每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。

所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node `（N/2 + 1）` 都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。

从节点执行主备切换，从节点切换为主节点。

#### 3.4 优缺点

+ 优点：
  + 无中心架构，支持动态扩容，对业务透明
  + 具备sentinel监控和自动failover（故障转移）能力
  + 客户端不需要连接集群所有节点，连接节点中任何一个可用节点即可
  + 高可用，客户端直连redis服务，免去了proxy代理的消耗
+ 缺点：
  + 运维也很复杂，数据迁移需要人工干预
  + 只能使用0号数据库
  + 不支持批量操作（pipeline管道操作）
  + 分布式逻辑和存储模块耦合等

#### 3.5 扩容和缩容

https://blog.csdn.net/weixin_43871678/article/details/116902679

扩容和缩容：key和hash槽之间的映射关系不变，hash槽和节点之间的映射关系会改变。导致key和节点之间的映射关系发生变化。

> 扩容原理：
>
> 1. redis cluster可以实现对节点的灵活上下线控制
> 2. 3个主节点分别维护自己负责的槽和对应的数据，如果希望加入一个节点实现扩容，就需要把一部分槽和数据迁移和新节点
> 3. 每个master把一部分槽和数据迁移到新的节点node04
>
> 新节点刚开始都是master节点，但是由于没有负责的槽，所以不能接收任何读写操作，对新节点的后续操作，一般有两种选择：
>
> 1. 从其他的节点迁移槽和数据给新节点
> 2. 作为其他节点的slave负责故障转移
>
> slot迁移说明：
>
> 1. 迁移过程是同步的，在目标节点执行restore指令到原节点删除key之间，原节点的主线程处于阻塞状态，直到key被删除成功
> 2. 如果迁移过程突然出现网路故障，整个slot迁移只进行了一半，这时两个节点仍然会被标记为中间过滤状态，即"migrating"和"importing"，下次迁移工具连接上之后，会继续进行迁移
> 3. 在迁移过程中，如果每个key的内容都很小，那么迁移过程很快，不会影响到客户端的正常访问
> 4. 如果key的内容很大，由于迁移一个key的迁移过程是阻塞的，就会同时导致原节点和目标节点的卡顿，影响集群的稳定性，所以，集群环境下，业务逻辑要尽可能的避免大key的产生

> 缩容原理： 
>
> 1. 如果下线的是slave，那么通知其他节点忘记下线的节点
> 2. 如果下线的是master，那么将此master的slot迁移到其他master之后，通知其他节点忘记此master节点
> 3. 其他节点都忘记了下线的节点之后，此节点就可以正常停止服务了

### 4. Redis Sharding

+ redis sharding是一种客户端端sharding技术，redis cluster出来之前，业界普遍使用多redis实例集群方式。其主要思想采用哈希算法将redis数据的key进行三列，通过hash函数，特定的key会映射到特定的redis节点上。
+ 优点：优势在于非常简单，服务端的redis实例彼此独立，互相无关联，每个redis实例就像单个服务器一样运行，非常容易线性扩展，系统的灵活去也很强
+ 缺点：
  + 由于sharding处理放在客户端，规模进一步扩大时给运维带来的挑战
  + 客户端sharding不支持动态增删。服务端redis实例群拓扑结构有变化时，每个客户端都需要更新调整。连接不能共享，当应用规模增大时，资源浪费制约优化
+ codis集群的原理就是客户端sharding：https://article.itxueyuan.com/7ed6KG

## 七. Redis拓展特性

### 1. 发布订阅模式

- 客户端订阅服务端的频道

- 当服务端向该频道中发送消息时，频道中所有的客户端都会收到该消息，执行相应的动作 

### 2. 事务

#### 2.1. SQL/Redis事务对比

SQL和Redis的事务有本质的区别，<u>Redis不支持事务回滚</u>，即使事务在执行过程中出错，也不会回滚，将会一直执行下去，直到事务结束。 因为，开发者认为，事务执行失败，很少会在实际生产环境中出现。

#### 2.2 SQL事务原理

innodb引擎支持的事务，采用**Redo log + Undo log**来实现

#### 2.3 Redis事务原理

使用 **乐观锁**，只负责<u>监听key</u>有没有被改动。

- 采用watch监听某个key
- 在执行命令时，检查该被监视的key是否已经被修改
- 如果该key时被改动，那么事务将会被打断

### 3 分布式锁

https://www.cnblogs.com/crazymakercircle/p/14731826.html

分布式锁使用: setnx（如果一个key不存在则插入成功）

#### 3.1 加超时时间

使用setnx+expire：对一个key加上超时时间，保证key不会永远占着，导致死锁

但是还是存在死锁问题，setex存在设置超时时间失败的情况，导致死锁

#### 3.2 解决死锁

set(key,value,nx,px)：将setnx+setex变成原子操作

#### 3.3 释放锁

需要先判断加锁者是谁，如果是持锁人才能释放锁（先判断，在释放）。需要原子操作，所以用lua脚本进行解锁

#### 3.4 其他问题

1. 任务超时，锁自动释放，导致并发问题。使用redisson（看门狗监听，自动续期）
2. 加锁和释放锁不在同一个线程问题。在value中存入uuid（线程唯一标记），删除锁时判断该标记（使用lua保证原子操作）
3. 不可重入，使用redisson解决（实现机制类似AQS，计数）
4. 异步复制可能造成锁丢失，使用redLock解锁

## 八. Redis线程模型

### 1. Redis单线程？多线程？

+  单线程指的是网络请求模块使用了一个线程（所以不需考虑线程安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。
+ 主线程：Redis在<u>处理客户端请求时（获取命令、解析命令、执行、返回内容）</u>等操作都是由一个顺序串行的主线程处理的，这就是所谓的“单线程”。
+ 后台线程：清理脏数据、无用连接释放、大key的删除

### 2. Redis单线程为什么快

1. 纯内存操作，且操作复杂度不高
2. 核心是基于非阻塞的IO多路复用机制
3. 单线程避免了多线程的频繁切换上下文所带来的的性能消耗
3. `完美`的数据结构的设计，键值对按照一定的数据结构促织，操作键值对最终都是对数据结构进行增删改查操作，所以高效的数据结构是redis快速处理数据的基础

### 3. Redis6.0之前为什么之前一直不使用多线程？

+ **官方回应**：Redis几乎不存在CPU称为瓶颈的情况，主要受限于**内存/网络**。单机QPS可以达到**100万**。

- 多线程难以维护性
  - 增加系统复杂度：单线程的惰性删除、Rehash等操作都可以<u>无锁实现</u>
  - 存在线程切换，<u>加锁解锁</u>带来的性能消耗
- 集群：单机如果实在不行，还可以使用多个Redis服务器组成<u>集群</u>，也能在一定程度上解决性能上的压力

### 4. Redis超过内存限制，会出现什么问题

+ 会根据Redis配置文件，释放内存（内存淘汰策略LRU/LFU/random）。可能 <u>释放内存的速度 < 内存增大的速度</u>，此时就会导致Redis客户端写入错误

### 5. Redis6.0多线程

1. 默认多线程模式是关闭的

   ```python
   # io-threads 4
   ```

2. 官方建议

   - 4核机器建议设置为2或3，8核建议设置为6.<u>（线程数一定要小于机器核数）</u>
   - 还需要注意的是，<u>线程数并不是越大越好</u>，官方认为超过了8个基本就没什么意义了


3. **开启多线程后，是否会存在线程并发安全问题？**

   **不存在线程安全问题**，不需要去考虑控制 key、lua、事务，LPUSH/LPOP 等等的并发及线程安全问题。
   
   1. 只是用来<u>处理网络数据的读写和协议解析</u>
   2. <u>执行命令仍然是主线程顺序执行</u>。

## 九. 大key+热key

### 1. 大key

#### 1.1 大key介绍

Redis使用过程中经常会有各种大key的情况， 比如：

1. 单个简单的key存储的value很大
2. hash， set，zset，list 中存储过多的元素（以万为单位）

由于redis是单线程运行的，如果一次操作的value很大会对整个redis的响应时间造成负面影响，所以，业务上能拆则拆

#### 1.2 大key的风险

1. 读写大key会导致超时严重，甚至阻塞服务。
2. 如果删除大key，DEL命令可能阻塞Redis进程数十秒，使得其他请求阻塞，对应用程序和Redis集群可用性造成严重的影响。
3. 建议每个key不要超过M级别。

#### 1.3 数据量分配倾斜

redis实例上的数据分布不均匀，某个实例上的数据特别多

解决方案：

1. 在业务侧保证生成数据时，避免过多的数据保存在一个key中
2. 一个key，拆分成多个key，分散存在不同的redis实例上

#### 1.4 如何优雅的删除大key

DEL命令在删除单个集合类型的Key时，命令的时间复杂度是O(M)，其中M是集合类型Key包含的元素个数。阻塞删除key，导致Redis阻塞，出现故障切换和应用程序雪崩的故障。

从Redis2.8版本开始支持SCAN命令，通过m次时间复杂度为O(1)的方式，遍历包含n个元素的大key.这样避免单个O(n)的大命令，导致Redis阻塞。 这里删除大key操作的思想也是如此。

##### 1.4.1 版本4之前

以前 string，list，set，hash  不同数据类型的大 key，删除方式有所不同。一般有两种情况：del 命令删除单个很大的 key  和  del 批量删除 大 key。**直接 del 命令粗暴的删大 key 容易造成 redis 线程阻塞**。4.0 以前要优雅的删除就是针对不同的类型 写脚本，拆分链表，hash 表，**分批删除**。

> Hash类型的大key
>
> 通过[hscan命令](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2Fredis.io%2Fcommands%2Fhscan)，每次获取500个字段，再用[hdel命令](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2Fredis.io%2Fcommands%2Fhdel)，每次删除1个字段。

> Set类型的大key
>
> 删除大set键，使用[sscan命令](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2Fredis.io%2Fcommands%2Fsscan)，每次扫描集合中500个元素，再用[srem命令](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2Fredis.io%2Fcommands%2Fsrem)每次删除一个键

> list类型的大key
>
> 删除大的List键，未使用scan命令； 通过[ltrim命令](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2Fredis.io%2Fcommands%2Fltrim)每次删除少量元素。

> zset类型的大key
>
> 删除大的有序集合键，和List类似，使用sortedset自带的[zremrangebyrank命令](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Flink.juejin.im%2F%3Ftarget%3Dhttp%3A%2F%2Fredis.io%2Fcommands%2Fzremrangebyrank),每次删除top 100个元素。

##### 1.4.2 版本4之后

4.0 版本以后官方对 删 大key 有了特别优化，支持了 lazy free 功能， 通常不需要开发脚本就可以删。

> **主动删除大 key**
>
> **unlink** 命令是  del 的异步版本，由 Lazyfree 机制实现。Lazyfree 机制的原理是在删除的时候只进行逻辑删除，把 key 释放操作放在 bio (Background I/O)单独的子线程中惰性处理，减少删除大 key 对 redis 主线程的阻塞，有效地避免因删除大key带来的性能问题。unlink 即使在批量删除 大 key 时，也不会对阻塞造成阻塞。

> **被动删除大 key**
>
> 被动删除是指 Redis 自身的 key 清除策略，一个 大 key 过期或者被淘汰时，如何被清除，会不会导致阻塞?
>
> 4.0 以前自动清除是有可能阻塞主线程的。
>
> 4.0 以后的版本，被动删除策略是可选的配置参数，允许 以 Lazyfree 的方式清除。但是参数默认是关闭的，可配置如下参数开启。
>
> lazyfree-lazy-expire on  *# 过期惰性删除*
> lazyfree-lazy-eviction on  *# 超过最大内存惰性删除*
> lazyfree-lazy-server-del on  *# 服务端被动惰性删除*

### 2. 热key

#### 2.1 热key介绍

所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机。
那接下来这个key的请求，就会直接怼到你的数据库上，导致你的服务不可用。

#### 2.2 数据访问倾斜

某个redis实例上的数据是热点数据，访问十分频繁

解决方案：

1. 利用二级缓存：将热key直接存入到本地内存，不走redis
2. 备份热key：不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。

## 十. 缓存穿透，缓存击穿，缓存雪崩

### 1. 缓存穿透

+ 缓存穿透是指**缓存和数据库中没有数据**，导致所有请求都落到数据库上，造成数据库短时间承受大量请求而崩溃
+ 出现场景：
  + 被别人恶意攻击（比如，发起ID=-1的请求）
+ 解决方案：
  + 接口层增加入参校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截
  + 从缓存取不到的数据库，在数据库中也没取到，这个时候可以将key-value写成key-null，缓存有效时间可以设置短点（设置太长会导致正常情况也无法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
  + 采用布隆过滤器，将所有可能存在的数据haxi到一个足够大的bitmap中，一个一定不存在的数据会被bitmap拦截掉，从而避免对底层存储系统查询增加压力。
    + 布隆过滤器算法的特点：① 不在布隆过滤器中的元素，一定不存在。② 在布隆过滤器中的元素，大概率存在（但是不是“一定存在”）

### 2. 缓存击穿

+ 缓存穿透是指**缓存中没有数据但是数据库中有数据（一般是缓存时间到期）**，这个时候由于并发用户特别多，同时读缓存没有的数据，然后去数据库中拉去数据，引起数据库压力瞬间增大，造成崩溃。和缓存雪崩不同的是，缓存击穿是指并发查询同一个数据，缓存雪崩是指大量缓存数据过期。
+ 出现场景：
  + 刚好缓存过期期间，有大量的请求访问该过期数据
+ 解决方案：
  + 设置热点数据永远不过期
  + 加互斥锁（重新将数据缓存到redis的时候加一把锁）

### 3. 缓存雪崩

+ 缓存雪崩是指**缓存同一时间大面积失效，所以后面的请求都会落到数据库上**，造成数据库短时间承受大量请求崩溃

+ 出现场景：

  + 缓存宕机，缓存数据大面积同时失效
  + 缓存同时到期，缓存数据大面积同时失效

+ 解决方案：

  > **避免出现缓存雪崩**
  >
  > 1. 一般采用“搭建高可用集群”，：防止“Redis服务器宕机”导致缓存雪崩
  > 2.  采用“设置不同的过期时间”：防止同一时间大量数据过期现象发生
  > 3. 给每个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存
  > 4. 设置热点数据永远不过期
  > 5. 互斥锁

  > **已经出现缓存雪崩**
  >
  > 假设已经出现缓存雪崩，那么，没有其他解决办法！只能进行“熔断”、“降级”、“限流”
  >
  > 1. “熔断”，（拒绝请求）一旦发现当前服务的请求失败率达到预设的值，就拒绝随后该服务的所有请求。
  >
  > 2. “限流”，（限制请求数量）当经过一段时间后，会放行该服务的一部分请求，再次统计它的请求失败率。如果此时请求失败率符合预设值，则完全打开限流开关；如果请求失败率仍然很高，那么继续拒绝该服务的所有请求，这就是所谓的“限流”。
  >
  > 3. “降级”，（服务降级）而向那些被拒绝的请求直接返回一个预设结果，被称为“降级”

## 十一. 缓存一致性问题

缓存一致性问题是指：数据库的数据和redis中的数据不一致。缓存一致性问题一定会发生，最终只能达到最终一致性，无法做到强一致性。比较有效的方案是：**延迟双删**

### 1. 先更新缓存，再更新数据库

显然是不行呀，缓存更新成功了，但是更新数据库却失败了，那么，每次访问数据都先访问缓存中错误的数据！

### 2. 先更新数据库，再更新缓存

该方案也不行

#### 2.1 case1

更新完数据库（更新成功），再更新缓存（更新失败，导致缓存中的数据是旧值）

#### 2.2 case2

多线程的顺序问题。

原因分析：线程A、B都更新同一个字段ID

1. 线程A先更新数据库ID=1，然后发了一个更新缓存ID=1的操作，但是由于网络原因，更新缓存的操作卡住了。
2. 之后线程B更新数据库ID=2，且更新成功，然后线程B更新缓存成功ID=2。
3. 此后，之前卡住的线程A的更新缓存ID=1操作执行成功。

结束时，数据库/缓存中ID的值分别是ID=2、ID=1，出现不一致！

### 3. 先删除缓存，再更新数据库

先删除缓存，再更新数据库。在多线程中也会有问题，出现了缓存是旧数据，数据库是新数据问题

#### 3.1 多线程问题

1. 数据发生了变更，先删除缓存，然后去修改数据库（该操作卡了），此时，还没修改数据库。
2. 但是一个读请求过来：将先去读缓存，发现缓存空了，就去查询数据库。会查到了未修改的数据库旧值，*将旧数据放到了缓存中。*
3. 随后，修改数据库操作完成，*数据库中的内容被更新为新值了。*
4. 显然，数据库值是新的，缓存值是旧的，发生了不一致。

### 4. 解决方案：延时双删

先删除缓存，再更新数据库，再删除缓存。这样保证及时出现了3.1中的多线程问题，那么后续缓存也会被删除，只有短暂的数据不一致问题。后续再读到缓存为空时，则会再从数据库获取到新值更新到缓存

## 十二. 应用场景

### 1 总结

#### 1.1 计数器

可以对string进行自增自减运算，从而实现计数器的功能。redis这种内存※数据库的读写性能非常高，很适合存储频繁读写的计算量

#### 1.2 分布式ID生成器

利用自增特性，一次请求一个大点的步长如incr2000，缓存在本地使用，用完再请求

#### 1.3 海量数据统计

位图（bitmap）：存储是否参与某次活动，是否已读谋篇文章，用户是否是会员，日活统计

#### 1.4 会话缓存

可以使用redis来统一存储多台应用服务器的会话信息。当应用服务器不在存储用户的会话信息，也就不在具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可靠性以及可伸缩性

#### 1.5 分布式队列/阻塞队列

List是一个双向链表，可以通过lpush/rpush和lpop/rpop写入和读取消息，可以通过brpop/blpop来实现阻塞队列

#### 1.6 分布式锁实现

在分布式场景下，无法使用基于进程的锁来对多个节点上进程进行同步。可以使用redis自导的setnx命令实现分布式锁

#### 1.7 热点数据存储

最新评论，最新文章列表，使用list存储，ltrim取出热点数据，删除老数据

#### 1.8 社交类需求

set可以实现交集，从而实现共同好友等功能。

set通过求差集，可以进行好友推荐，文章推荐

#### 1.9 排行榜

zset可以实现有序性操作，从而实现排行榜功能

#### 1.10 延时队列

使用sorted_set，使用【当前时间戳+需要延时的时长】做score。消息内容作为元素，调用zadd来生产消费。消费者使用zrangbyscore获取当前时间之前的数据做轮训处理。消费完再删除任务rem key member

### 2. Hash之淘宝商城购物车

### 3. List之微博公众号消息流

订阅了某个公众号，当该公众号发文章后，会推送给你！ 特点：消息的发送是有一个时间线的 

（微信朋友圈）

```python
LPAUSH msg:{小明微信号ID} 10018    # 发消息
LPAUSH msg:{小明微信号ID} 10011    # 发消息  
LRANGE msg:{小明微信号ID} 0 -1     # 查看最新的消息流列表
```

### 4.Bit位之日活量

场景：统计2020/10/03，登录用户数。现在系统有千万级活跃用户，如何实现日活统计，为了增强用户粘性，要上线一个连续打卡发放积分的功能，怎么实现连续打卡用户统计？

```python
将20201003Login作为key，offset作为每个用户，value 0/1表示都否登录，即：

Data    1  0  0  0  1  1  0 
Offset  0  1  2  3  4  5  ... ... 

Setbit 20201003Login 0 1 
Setbit 20201003Login 4 5 

bitcount 20201003Login 0 -1  # 统计日活

将20201003Login, 20201004Login,..., 20201007Login相与，之后再统计1的总个数 # 统计连续几日登录量
```

### 5. Set之微信抽奖小程序、微博点赞列表、微博关注模型	

无序不重复，放相同的元素，将会被去重（每个人点击多次抽奖，将会被去重，只视为一次抽奖）

#### 5.1 场景1：微信抽奖小程序 

```python
SADD activity:10086 {用户ID}   # 用户点击抽奖按钮后，将加入set
SMEMBERS activity:10086       # 查看参与抽奖的所有用户
SRANDMEMBER activity:10086 2 SPOP activity:10086 2  # 随机抽取count名中奖者
```

#### 5.2 场景2：微博点赞

```python
SADD like:{消息ID} {用户ID}      # 点赞
SREM like:{消息ID} {用户ID}      # 取消点赞
SISMEMBER like:{消息ID} {用户ID} # 检查用户是否点过赞
SMEMBERS like:{消息ID} {用户ID}  # 获取点赞的用户列表
SCARD like:{消息ID}             # 获取点赞用户总数
```

#### 5.3 场景3：微博关注模型

James --\> {A,B,C} Kobe--\>{A,C,D,R} 

James、Kobe是两个集合Set 

```python
SINTER James Kobe      # 取出James和Kobe共同关注的人（交集） 
SISMEMBER James Jordan # 判断James集合中是否有Jordan 
SDIFF James Kobe       # James可能认识的人
```

#### 5.4 场景4：Set实现电商商品类型的筛选 

```python
SADD brand:huawei P30 
SADD brand:xiaomi 6X 
SADD os:android P30 6X
SADD cpu:brand:intel P30 6X 
SADD ram:8G P30 6X
SINTER os:android cpu:brand:intel ram:8G  # -->{P30, 6X}
```

### 6. ZSet有序集合之微博热点排行榜

```python
ZINCRBY hotNews:20190722 1   # 点击新闻 
ZREVRANGE hotNews:20190722 0 10 WITH SCORES  # 展示当日排行前十
```

### 7. String字符串对象

场景：统计网页/贴吧/文章阅读/浏览次数

```
Incr article:readcnt:1001  # 对文章1001的读次数+1
```

### 8. Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？

使用keys指令可以扫出指定模式的key列表。

对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？

这个时候你要回答redis关键的一个特性：

redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。

这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

### 9. 异步队列

一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。
如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。
如果对方追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。
如果对方追问pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。

### 10. 延时队列

使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。

------

- [整理了2019年40道Redis高频面试题，答案详细解析](https://www.bilibili.com/read/cv4042105/)
- [redis原理总结(很全面)](https://blog.csdn.net/wuyangyang555/article/details/82152005)
- [Redis双写一致性、并发竞争、线程模型](https://www.imooc.com/article/297496)
- https://www.cnblogs.com/crazymakercircle/p/13900198.html

+ https://www.cnblogs.com/crazymakercircle/p/14731826.html
