
## 一. 索引

+ 加快SQL查询速度的数据结构，引来的缺点（降低<u>更新表的速度</u>，保存<u>索引占用空间</u>）

### 1. 索引采用哪些数据结构

1. HASH索引：底层是哈希表，存储KV，在进行查找时，O(1)就可以找到相应的键值
2. B+Tree索引：B+树，多路平衡查找树，每次查询都是从根节点出发，查找到叶子节点就可以获得所查的值
   - MySQL中的数据一般是放在磁盘中的，读取数据的时候肯定会有访问磁盘的操作， <u>B+Tree是专门为磁盘IO设计的一种多路平衡查找树</u>，它的**高度**远远小于其他数据结构，因此访问磁盘的数量极小，磁盘IO所花的时间少。
   - B+树为什么比B树更适合？
     - 1）B+树的<u>内部节点不存放数据</u>，只有叶子节点存放数据 ==> 其内部节点相对B树更小
     - 2）B+树的叶子节点形成<u>链表</u>，便于范围查询
     - 3）B+树的查询效率更加稳定：B+树的数据都存储在叶子结点中，所以任何关键字的查找必须走一条从根结点到叶子结点的路，所有关键字查询的路径长度相同，导致每一个数据的查询效率相当

### 2. HASH索引和B+Tree索引对比

1. HASH索引等值查询更快O(1)，但是不支持采用key排序/范围查询/最左匹配原则/模糊查询

2. HASH函数选择不好时，会发生HASH碰撞，导致查询效率降低

3. HASH索引任何时候都<u>避免不了回表查询</u>，B+索引在覆盖查询时，可以避免回表查询

4. HASH索引是存放在<u>内存中</u>的，占用内存资源太大

### 3. 为什么底层使用B+Tree，不使用二叉树、BST、AVL、RBT

这是由数据结构的时间复杂度决定的，二叉树/BST会退化成链表、AVL树旋转代价太高、RBT树太高

### 4. 索引种类

1. 普通索引：最基本的索引，没有任何限制

2. 唯一索引：不允许具有索引值相同的行，从而禁止重复索引或键值，“唯一”：假如在name上建立唯一索引，那么，整个表就不能有两个行name相同的情况

   - 问题：唯一索引允许为NULL么？出现NULL会造成什么影响？
     - 答：<u>允许为NULL</u>。NULL表示的是未知，因此两个NULL比较的结果既不相等，也不不等，所以结果仍然是未知

3. 组合索引：又叫联合索引，一个索引包含多个列。:slightly_smiling_face:<u>（最左匹配原则）</u>

4. 全文索引：FULLTEXT，它是通过关键字<u>语义匹配</u>分析方式来进行过滤查询，仅适用于MYISAM引擎的数据表

### 5. 聚簇/主键索引、非聚簇/非主键索引

+ 聚集索引/非聚簇索引：并不是一种索引类型，而是一种数据存储方式。
  + 聚簇索引：将数据存储与索引放到一块，索引结构的叶子节点保持行数据。1个表只能有1个聚簇索引
  + 非聚簇索引：将数据与索引分开存储，索引结构的叶子节点指向了数据对应的位置。又称为辅助索引或者二级索引

### 6. 聚簇索引和非聚簇索引区别

+ 区别：
  + 索引的位置存放的是真实数据？还是主键值？（① 主键索引的叶子节点存放的是要查找的真实数据，主键索引也被称为聚簇索引。② 非聚簇索引的叶子节点存放的不是真实的数据，而是**主键值**，它也被称为二级索引）
  + 聚簇索引：索引B+Tree的叶子节点上存放了数据行的物理地址

  + 非聚簇索引：非聚簇索引B+Tree树的叶子节点存储的不再是行的物理位置，而是主键值；索引数据时，需要两次查询（通过非聚簇索引查找到主键值，再通过主键值在主键索引中查找到该主键对应的真实数据）

### 7. 回表

+ 如果查询语句是select \* from table where ID=100，即主键查询方式，则只需要搜索ID=100的B+树的叶子节点
+ 如果查询语句是select \* from table where score=30，即非主键查询方式，则先通过非聚簇索引查找score=30的主键索引（即ID索引），再经过主键索引搜索一次才查找到数据行。这个操作也被称之为**回表查询**。
+ **聚簇索引查询速度一般更快，因为它不需要二级/多级查询**

### 8. 可以存在多个聚簇索引？

聚簇索引的顺序就是数据的物理存储顺序，正式因为如此，所以<u>一个表最多只能有一个聚簇索引</u>。

### 9. InnoDB主键选择

+ 为什么主键通常建议使用自增id
  + 聚簇索引的数据的物理存放顺序与索引顺序是一致的。即：只要索引是相邻的，那么对应的数据一定也是相邻的存放在磁盘上。如果主键不是自增id，那么可以想象，它会干些什么，不断地调整数据的物理地址，分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但如果自增，那就简单了，它只需要一页一页的写，索引结构相对紧凑，磁盘碎片少，效率高
+ 在分布式场景中，自增id还适用吗
  + 不适用。用雪花算法(snowflake)（它给每台机器分配一个唯一标识，然后通过时间戳+标识+自增实现全局唯一ID），自定义id生成器
+ InnoDB没有主键会发生什么
  + 在innodb中，聚簇索引默认是主键，如果表中没有定义主键，则会选择一个唯一且非空索引替代。如果没有这样的索引，会隐式定义1个主键(row_id)作为聚集索引，这个隐藏的主键是一个6字节的列，该列的值会随着数据的插入自增

### 10. 覆盖索引

#### 10.1 所有的非聚簇索引都一定会经过回表查询么？

答：不是，覆盖索引解决了该问题。

覆盖索引：当sql语句的所求查询字段<u>（select列）</u>和查询条件字段<u>（where子句属性列）</u>全都包含在一个索引中，就可以直接使用索引查询而不需要回表！

#### 10.2 怎么通过覆盖索引优化回表查询？

答：建立联合索引，使要查找的列都在索引中，避免回表查询。

即：select （查找项） from where （条件项），查找项 in 条件项 && 查找项 == 索引

### 11. 全文索引

:cry: 区别：全文索引、模糊匹配like%

- 二者有本质的区别
- 全文索引是以语法分析的方式来分词的，而like是带通配符的匹配
- 使用场景：全文索引（如，可以对特定词的同义词形式来进行查询，一般用于电子商务网站），like模糊匹配（由常规字符串和通配符组成，要符合匹配准则）

### 12. 索引下推

+ 英文：Index Condition PushDown
+ 当存在索引的列做为判断条件时，**MySQL服务器将这一部分判断条件传递给存储引擎，然后存储引擎通过判断索引是否符合MySQL服务器传递的条件**，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器。
+ select \* from where name like 'zhang%' and age\>18
+ 因为是select \* ，所以一定会触发回表查询，以下有2种查法
  + 查找zhang开头的主键，然后回表查询所有的记录，再过滤age\>18的行
  + 查找zhang开头的数据，再筛选出age\>18的记录，再回表查询所有数据
  + 优化器会选择第2中，因为2先通过两个条件过滤会得到更少的信息，再回表查询

### 13. 索引场景案例

1. 建立联合索引（a,b,c），然后在where条件是：a=xxx and b>xxx and c=xxx，这个时候联合索引是否被用到？

   答：索引会在>后面停止

2. 建立联合索引（a,b,c），where条件是：c=xxx and b>xxx and a=xxx，索引是否被用到？

   答：这个where条件跟第一个是一致的，数据库会进行优化。

3. 表并不存在索引，查询条件是where a=xxx order by b，这个时候应该如何建立索引？

   答：建立一个ab的联合索引，会先过滤a索引，在排序b索引 v 

### 14. 存储引擎InnoDB和MyISAM的区别

+  innodb/myisam最主要的差别：Innodb **支持事务处理与外键和行级锁**，而MyISAM不支持

+ innodb支持<u>事务、外键、行锁(默认)/表锁</u>，不支持全文索引

+ innodb必须有主键，没有显示指定主键，mysql会默认创建主键_rowid；而myisam可以没有主键

+ innodb是主键索引/聚集索引，myisam是非主键索引/非聚集索引。

+ 存储文件

  innodb：frm表结构文件、ibd数据文件(包括索引/数据)

  Myisam：frm表结构文件、MYD数据文件、MYI索引文件

|    对比项    |                                             InnoDB                                              |                         myisam                          |
| :----------: | :---------------------------------------------------------------------------------------------: | :-----------------------------------------------------: |
|     事务     |                                      支持（可靠性要求高）                                       |                       不支持事务                        |
|    锁级别    |                                   行锁（适用于表更新较频繁）                                    |           表锁（适用于查询多，插入和删除少）            |
| 是否支持外键 |                                              支持                                               |                                                         |
|     查询     |                                                                                                 |                          更快                           |
|   全文索引   |                                                                                                 |                          支持                           |
|   适用场景   | (1)可靠性要求比较高，或者要求事务<br/>(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况 | (1) 做很多count 的计算<br/>(2) 查询非常频繁，插入不频繁 |

### 15. InnoDB为什么推荐使用自增ID作为主键，不用UUID？

+ B+Tree底层结构：在插入的时候
  + 自增ID可以保证每次插入时B+索引是从右边扩展的
  + UUID是随机生成的，不一定key值就比之前的数大，会导致B+树和频繁合并和分裂。 另外，UUID占用16个字节，占用内存较大 

### 17. Memory存储引擎

memory存储引擎使用的哈希索引。InnoDB是使用的自适应哈希

## 二. 事务

+ 引出事务的原因：多用户/多程序/多线程，存在同时对表中一个元组进行DML操作，如果不进行控制，就会造成数据不一致性

### 1. 特性：ACID

+ 原子性：最小单元，整个事务的所有操作要么做，要么都不做 （undo log）
+ 一致性：从一种一致性状态转换为另一种一致性状态，事务开始/结束都保证完整性 
+ 隔离性：并发执行的各个事务之间不相互干扰
+ 持久性：事务一旦提交，结果将永久保存在数据库中（redo log）

### 2. 事务并发问题

+ **賍读(读取未提交数据)**：事务B修改某个数据后，未提交，被事务A读到；之后事务B回滚修改数据操作，事务A之前读到的数据就是脏数据
+ **不可重复读(在一个事务中前后读取的数据不一致)**：事务A读取同一个数据经历的时间很长，第一次读时，该数据为Val1，之后，该数据被事务B修改，之后事务A再去读该数据，结果为Val2，这就叫做不可重复读
+ **幻读(前后多次读取，数据总量不一致)**：与不可重复读类似，都是在一个事务中，两次读取结果不一样。区别在于幻读是在一个事务中读取到数据的条数不一致，如：事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，称为幻读

### 3. 四种隔离级别

+ **读未提交**：所有事务都能够读取其他事务未提交的数据，会导致賍读、不可重复读、幻读
+ **读已提交**：所有事务只能读取其他事务已经提交的数据，可以解决賍读！但是会出现在一个事务中前后读取内容不一致的问题，即不可重复读、幻读
+ **可重复读**：在一个事务中，不允许Update操作，允许Add操作，因此能保证在一个事务中读取数据内容是一致的(能解决不可重复读，即对同一个数据多次读取的val都是一样的)，但是不能保证读取到数据条目数一致(会发生幻读)
+ **可串行化**：所有的事务都顺序串行执行，不存在冲突
+ innodb默认隔离级别不是最高的，而是倒数第二高的，即<u>可重复读级别</u>

### 4. 事务原理

+ **原子性：undo log实现**

+ **持久性：redo log实现**

+ **隔离性：加锁（解决幻读）和MVCC**

+ **一致性：基于原子性，隔离性和持久性完成**

### 5. 事务日志redo/undo

之前已经说过，innodb支持事务，它具有事务日志redo/undo，而myisam不支持事务，它没有这两种事务日志。

#### 5.1 redo log 重做日志，保证事务持久性

- **保证：所有已经提交的事务的数据仍然存在**
- redo_log作用：用于记录事务的变化，记录的是数据修改之后的值，<u>不管事务是否提交都会记录</u>。如果某时刻系统宕机，重启后，可以通过redo log恢复之前的数据
- 数据库宕机恢复过程：先从redo log中把未落盘的脏页数据恢复回来，重新写入磁盘，保证用户数据不丢失
- redo_log写入磁盘过程：先<u>写入redo log buffer（redo log缓存）</u> 之后调用<u>fsync</u>，刷新写入redo log物理磁盘（它的写入是可进行参数配置的）

#### 5.2 undo log 回滚日志，保证事务原子性

- **保证：所有没有提交的事务的数据自动回滚**
- 数据更新时，会写入undo log（该操作和数据更新执行操作相反，即如果是插入数据，则undo log是删除数据）
- 回滚：当事务失败或回滚时，根据undo log，把未提交的事务回滚到更新前的状态

### 6. SQL引入二阶段提交，保证主从数据的一致性！

+ 因为存在的binlog（mysql自身）和redolog（innodb存储引擎），要保证两个日志的数据一致性，所有引入了两阶段提交
+ SQL会为每一个事务，分配一个事务ID（XID）
+ 事务被分为2个阶段：papare/commit
+ Binlog会被当作事务协调者

>  准备阶段（papare）
>
> - 此时SQL已经成功执行，生成XID信息以及Redo/Undo的内存日志
> - 然后调用papare方法，将事务状态设置为TRX_PREPARED，并<u>将Redo log刷入磁盘</u>

> 提交阶段（commit）
>
> （1）提交 or 回滚
>
> - 如果事务涉及的所有存储引擎的papare都执行成功，则将SQL语句写入Binlog，调用fsync写入磁盘
> - 如果事务涉及的所有存储引擎的papare都执行失败，则SQL语句不会写入Binlog，此时事务回滚
>
> （2）告诉引擎进行commit
>
> - （假设papare成功，完成事务提交）会清除undo信息，调用fsync刷redo日志到磁盘，将事务设置为TRX_NOT_STARTED状态

> 一旦步骤提交阶段中的操作完成，就确保了事务的提交。此外需要注意的是，每个步骤都需要进行一次fsync操作才能保证上下两层数据的一致性。提交阶段的fsync参数由sync_binlog=1控制，步骤3的fsync由参数innodb_flush_log_at_trx_commit=1控制，俗称“双1”，是保证CrashSafe的根本。

![两阶段提交](/数据库/MySQL/images/两阶段提交.png)

### 7. 为什么要有Binlog

+ 不管SQL使用那种存储引擎，都有Binlog，它是Server层的（而redo log是innodb层的）

###  8. 二进制日志Binlog

+ binlog与redo log类似，它记录了对数据库执行更新的所有操作，但是二者还是有本质的区别

+ binlog - 主要用作主从复制和即时点恢复

|          |                         redo log                          |                                 binlog                                  |
| :------: | :-------------------------------------------------------: | :---------------------------------------------------------------------: |
|   场景   | crash-recovery<u>宕机恢复</u>（保证事务持久性），事务安全 | point-time-recovery恢复某个时间点（即使<u>点恢复</u>）；<u>主从复制</u> |
|   层次   |        只有innodb支持事务的存储引擎有（innodb层）         |                        所有SQL都支持（Server层）                        |
| 写入时机 | 在事务进行中不断地写入，并日志不是随事务提交而顺序写入的  |                      只在事务完成后，进行一次写入                       |
|   功能   |                      保证事务一致性                       |                   记录数据库DML操作，能够实现主从复制                   |

### 9. 双1设置

innodb_flush_log_at_trx_commit和sync_binlog 两个参数是控制MySQL磁盘写入策略以及数据安全性的关键参数。

innodb_flush_log_at_trx_commit：保证事务的log的落盘时机

sync_binlog ：保证了数据操作的落盘时机

#### 9.1 innodb_flush_log_at_trx_commit

如果innodb_flush_log_at_trx_commit设置为0，log buffer将每秒一次地写入log file中，并且log file的flush(刷到磁盘)操作同时进行.该模式下，在事务提交的时候，不会主动触发写入磁盘的操作。

如果innodb_flush_log_at_trx_commit设置为1，每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去.

如果innodb_flush_log_at_trx_commit设置为2，每次事务提交时MySQL都会把log buffer的数据写入log file.但是flush(刷到磁盘)操作并不会同时进行。该模式下,MySQL会每秒执行一次 flush(刷到磁盘)操作。

#### 9.2 sync_binlog

sync_binlog 的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。

当sync_binlog =N (N>0) ，MySQL 在每写N次二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。

### 10. 组提交

为了保证Redo log和binlog的数据一致性，MySQL使用了二阶段提交，由binlog作为事务的协调者。而 引入二阶段提交 使得binlog又成为了性能瓶颈，先前的Redo log 组提交 也成了摆设。为了再次缓解这一问题，MySQL增加了binlog的组提交，目的同样是将binlog的多个刷盘操作合并成一个，结合Redo log本身已经实现的 组提交，分为三个阶段(Flush 阶段、Sync 阶段、Commit 阶段)完成binlog 组提交，最大化每次刷盘的收益，弱化磁盘瓶颈，提高性能。

## 三. 锁

当数据库有并发事务时，可能会产生数据不一致，锁可以保证访问次序。

### 1. 共享锁（读锁）/ 独占锁（写锁）

+ 共享锁(读锁)：可以被多个事务同时读，但是加了读锁，不允许加写锁
+ 独占锁(写锁)：加了写锁，不允许加读锁or写锁

### 2. 乐观锁 / 悲观锁

+ 悲观锁：只允许一个锁进入
+ 乐观锁：MySql最经常使用的乐观锁是进行**version版本控制**（在分布式锁中，讲到过SQL的乐观锁/幂等），也就是在数据库表中增加一列，记为version。
  + 当将数据读出时，将版本号一并读出；当数据进行更新时，会对这个版本号进行加1；
  + <u>当提交数据时</u>，会判断数据库表中<u>当前的version列值</u>和当时读出的version是否相同；
  + 若相同，说明没有进行更新的操作，不然，则取消这次的操作。

### 3. 按照对数据的粒度

+ 表锁（偏读）：对整张表进行加锁
  + 特点：偏向MyISAM存储引擎，开销小，枷锁快，无死锁。粒度大，发生锁冲突概率高，并发度小
+ 行锁（偏写）：对表中的某一行或者多行进行加锁
  + 特点：偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁。粒度小，发生锁冲突概率小，并发度大。
+ 页锁：开销和加锁时间介于表锁和行锁之间。会出现死锁。锁粒度介于表锁和行锁之家你，并发度一般
+ 记录锁：事务在加锁的只是表中的某条记录。精准条件命中，并且命中的条件字段是唯一索引。
  + 特点：可以避免数据在查询的时候被修改的重复读温恩替，也避免了在修改的事务未提交前被其他事务读到的脏读问题

+ 间隙锁：属于行锁的一种。锁住的是表中的某一区间范围。可以锁住记录不存在的范围
  + 特点：防止幻读问题

+ 临建锁

### 4. 按照对锁的状态分类

如果当事务A加锁成功之后就设置一个状态告诉后面的人，已经有人对表的行加了一个排他锁，你们就不能对整个表加共享锁和排他锁了。那么后面需要对整个表加锁的人只需要获取这个状态就知道自己是不是可以对整个表加锁，避免了对整个索引树的每个节点扫描是否加锁，而这个状态就是意向锁

+ 意向共享锁：当一个事务试图对整个表进行加共享锁之前，首先需要获得这个表的意向共享锁
+ 意向排他锁：当一个事务试图对整个表进行加排他锁之前，首先需要获得这个表的意向排他锁

### 5. innodb无索引or索引失效时，行锁会升级为表锁

## 四. SQL优化

使用explain关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈

### 1. 慢查询

+ 慢查询配置：slow_query_log、slow_query_log_file、long_query_time
+ 慢查询日志分析工具mysqldumpslow：捕获前10条查询较慢的 mysqldumpslow -s at -t 5 xxx.log

### 2. SQL语句编优化

+ 使用<u>join</u>来代替子查询
+ 拆分大的delete或insert语句
+ 可通过开启<u>慢查询</u>日志来找出较慢的SQL
+ OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内
+ 没建立索引，就建立索引

### 3. 对于已经建立的索引，可能存在索引失效

+ explain查看SQL语句的执行计划：possibe_key, key, key_len，分别表示可能使用的索引，实际使用的索引，使用索引的总字节数，using
+ index(覆盖索引)/where(回表)/filesort(order by)/temporary(group by 临时表)

| Using字段 |                                                                                                                                                                                                                                                         |
| :-------: | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|   where   | 回表查询                                                                                                                                                                                                                                                |
|   index   | 覆盖索引，直接通过索引就可以获取到所有要查询的数据，无需回表查询                                                                                                                                                                                        |
| filesort  | 并不是说通过磁盘文件进行排序，而只是告诉我们进行了一个排序操作而已(只有在order by 数据列的时候才可能会出现using filesort)  (1)修改逻辑，不在mysql中使用order by而是在应用中自己进行排序  (2)使用mysql索引，将待排序的内容放到索引中，直接利用索引的排序 |
| temporary | group by 临时表                                                                                                                                                                                                                                         |

### 4. 数据插入优化

- 插入前，<u>禁用索引</u>

- 修改事务的提交方式（变多次提交为一次提交）

  ```sql
  插入前，禁用索引
  
  insert into test values(1,2); 
  insert into test values(1,3); 
  insert into test values(1,4); 
  
  insert into test values(1,2),(1,3),(1,4)  // 合并多条为一条，批量插入
  ```

- 插入后，<u>不禁用索引</u>

### 5. 优化索引口诀 

- 全值匹配我最爱，<u>最左前缀</u>要遵守 

- 带头大哥不能丢，中间兄弟不能断

- 索引列上<u>少计算</u>，<u>范围</u>之后全失效 

- <u>like百分写最右</u>， 覆盖索引<u>不写\*</u>

- 不空值还有or，索引失效要少用 

- var引号不能丢，SQL高级也不难


- 下面，列出的几条，就是上面口诀的具体展现
  1. 查询频率高的列、经常需要排序、分组、联合的字段建立索引
  2. 创建索引的数目不宜过多，过多会占用空间，且影响表的更新速度
  3. 选择唯一性索引(如学生的学号)
  4. 不在索引上做运算符操作
  5. 范围条件放最后: 因为范围条件后的索引都会失效
  6. 字符类型要加双引号: 隐式转换，索引会失效
  7. 条件字段函数操作，导致索引失效
  8. 隐式字符编码转换，索引会失效
  9. or替换为union: A or B，如果A建立了索引，B没有建立索引，则索引通通不走
  10. like查询要当心: like %keyword索引失效，like keyword%索引有效
  11. 不等于!=要慎用: 索引失效
  12. 考虑在where或order by 或 group by涉及的列建立索引

- innodb无索引or索引失效时，行锁会升级为表锁d
- 之前听分享课，mysql加锁其实是对索引进行加锁，如果没有索引，锁会退化成表锁

## 五. 集群优化

### 1. 主从复制

+ **定义**：将一台主服务器的数据，同步复制到从服务器（数据的复制是单向的，只能由主节点到从节点）
+ **作用**：
  +  数据冗余：从节点保存了和主节点一样的数据。 
  +  故障恢复：主节点出现问题时，从节点可以提供服务，实现故障恢复。
  + 负载均衡：在主从复制的基础上，配合读写分离，主节点提供写服务，从节点提供读服务 
  + 高可用基石：哨兵、集群实现高可用

### 2. 如何将主节点的binlog同步到各个从节点上

1. master将改变记录写到二进制日志（binary log）：这些记录过程叫做二进制日志事件，binary log events。master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中。
2. slave将master的binary log events拷贝到他的中继日志（relay log）：slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件
3. slave重做中继日志事件，将改变应用到自己数据库中：同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。

### 3. 主从复制中延迟问题

+ **延迟问题产生原因**：从服务器的两个线程执行速度不一致，可能会造成延迟问题。 
  +  IO线程从主服务器读取日志速度很快（顺序读），而SQL线程重放SQL速度慢（随机写），这就会造成从服务器同步数据远远落后于主服务器，导致从服务器数据远远落后于主服务器，（主从数据库长期处于不一致的状态），这种现象就是延迟更新。
  + 主库经常会开多个线程去写，从库只有一个线程在工作，导致从库效率 \<\< 主库效率

+ **解决方案**：（MTS） 从服务器的数据重放过程采用多线程
+ MTS：要遵循两个规则
  + <u>同一个事务</u>中的MDL，必须分发到同一个worker线程
  +  MDL<u>同一行的多个事务</u>，必须分发到同一个worker

### 6. 读写分离

+ 核心原则：主库只进行更新写操作，从库进行查询读操作

+ 主库：增删改更新操作，即：更新操作，一直在主服务器

+ 从库：查询操作，即：查询操作，一直在从服务器

+ 问题：会有时间窗口导致主库和从库的数据不一致。主库插入后，马上去查询结果（会去从库查询）。有可能会出现从库查不到的情况

+ 解决方案：强制路由在SQL语句前面加上:`/*master*/`。强制去主读数据

  ```sql
  /*master*/select * from tb where id = 1
  ```

### 7. 分库分表（水平/垂直）

+ 随着公司业务的发展，数据库中的数据量猛增，访问性能也变慢了，优化迫在眉睫。当数据达到100W或100G后，由于查询的维度较多，即使添加从库、优化索引，很多操作仍然性能下降很大。 分库分表是为了解决数据量过大导致数据库性能降低的问题！将原来独立的数据库、表，拆分成多个数据库、表，使得单个数据库、表的数据量变小，从而达到性能优化的目的。

- 垂直分表：将表按照属性列划分成多个表
- 水平分表：数据量行数过大时，按照行分成多个表
- 垂直分库：按照业务将表分不到不同的数据库，每个库可以放在不同的服务器
- 水平分库

### 8. 缓存redis

+ 防止每次请求都发到数据库上，使用缓存，降低连接数据库操作、数据库处理操作次数，提高数据库性能 

## 六. 分页查询 limit

### 1. 原理

limit语法支持两个参数，offset/limit

- offset：从偏移量开始查找
- limit：返回limit条元组

```SQL
### 返回符合条件的第11-20条数据
select * from user limit 10,20
```

本质：limit 10000,10的语法，实际上是<u>mysql查找到前10010条数据，之后丢弃前面的10000行</u>，返回10行数据。（可以看到，查找的前10000行数据是十分消耗资源且没有必要的）

### 2. 优化

+ 用ID优化：
  + 先找到上次分页的最大id
  + 然后利用id上的索引来查询
  + 类似于：select \* from user where id >1000000 limit 100.

+ 这样的效率非常快，因为主键上是有索引的；但是这样有个缺点，就是ID必须是连续的，并且查询不能有where语句，因为where语句会造成过滤数据。

### 3. 用覆盖索引杜绝回表查询

```sql
select * from (select id from job limit 1000000,100) a left join job b on a.id = b.id;
```

+ 先查出索引id，然后根据id查询数据

##  七. 存储过程

+ 定义：多个SQL语句的集合，就像是函数，但是它没返回值

+ 优点：
  + 一次连接，执行存储过程中所有的SQL语句，效率高
  + 只在创建时编译一次，之后不编译；可以重复使用，提高开发效率
  + 安全性高：可以设定某个用户是否具有某个存储过程的使用权限

```sql
create procedure insert_student_process(name varchar(50),age int,out_id ing) //创建存储过程
begin:
insert into student value(null,name,age)
select max(stuId) into id from studentend;
call insert_student_process('Jamed',26,\@id); //调用存储过程select \@id;
```

## 八. 高级

### 1. “脏页”导致查询速度变慢

#### 1.1 为什么mysql突然变慢了？

1. 类比

   掌柜记忆(内存)、记账粉板(redolog)、账本(数据文件)

   掌柜要把账本更新一下，即: 内存中的数据写入到磁盘中，flush操作

2. 脏页

   当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

3. 你的SQL语句为什么变慢了？

   当出现大量脏页，数据要从内存中刷入磁盘(内存==>redolog==>磁盘)

4. 什么情况下会出现flush操作？

   1. 掌柜记忆满了(系统内存满了)
      1. 对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
   2. <u>粉板满了(redolog满了)</u>
   3. 空闲时，掌柜闲着更新账本
   4. 店铺打样后，更新账本(即: sql关闭后)

   以上4种，

   ① 3-4是正常情况。

   ② 1也是常态，内存满了，要先将脏页刷入磁盘(因为innodb的策略是尽可能的使用内存，避免频繁刷写磁盘)

   ③ 2不是常态，应该尽可能避免 ==> 引出，innodb刷写脏页的控制策略

####  1.2 innodb刷写脏页的控制策略

1. 需要正确的告诉innodb所在主机的IO能力==>决定需刷脏页的速度
   1. 主机IO能力(主机IOPS):  fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 
   2. 参数innodb_io_capacity: innodb刷脏页的速度，建议设置为主机IOPS
2. 平时要多关注脏页比例，不要让它经常接近 75%
   1. 参数innodb_max_dirty_pages_pct: 脏页比例上线，默认值是75%
3. 参数innodb_flush_neighbors: 控制邻居的行为
   1. 值1: 刷写自己页面的时候，邻居的页面也会刷写(减少随机IO)
   2. 值0: 只刷写自己的页面


### 2. 为什么我只查一行的语句，也执行这么慢？

1. 全表扫描导致查询慢
2. 表级别锁
   1. 等MDL锁(waiting for table metadata lock): 对表执行DDL操作，导致表被锁死
3. 等flush
   1. 脏页过多，此时正在刷新内存中的脏页到磁盘
4. 等行锁
   1. sessionA: 开启了事务，在事务中更新某行，则该行被加上写锁
   2. sessionB: 查询该行(将会被阻塞)

### 3. 问题: 重建索引

#### 3.1 问题描述

最后，我给你留下一个问题吧。对于上面例子中的 InnoDB 表 T，如果你要重建索引 k，你的两个 SQL 语句可以这么写: 

```sql
alter table T drop index k;
alter table T add index(k);
```

如果你要重建主键索引，也可以这么写: 

```sql
alter table T drop primary key;
alter table T add primary key(id);
```

我的问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？

答案: 重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 :  alter table T engine=InnoDB。

#### 3.2 为什么要重建索引？

1. 我们文章里面有提到，索引可能因为删除，或者页分裂等原因，导致数据页有空洞
2. 重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。


### 4. 普通索引、唯一索引应该怎么选择？ 

谁的性能更高呢？先说结论

1. 读，唯一索引略高一点点，但是基本差不多
2. 写，insert场景下，唯一索引的change buffer会失效 ==> 普通索引 >> 唯一索引


#### 4.1 查询过程: 二者差别很小

假设，执行查询的语句是 select id from T where k=5。

- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

#### 4.2 insert过程

1. 当要被更新的数据在内存时，直接更新
2. 当数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了
   - 虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上

#### 4.3 插入过程

如果使用的是唯一索引，那么所有insert操作都会判断这个操作是否违反唯一性约束，即: 在插入数据时，唯一索引必须要先从磁盘读取数据，判断数据是否存在，然后再根据是否唯一性，返回结果

- 比如，要插入(4，400)这个记录，就要先判断现在的表中是否存在k=4记录，而这必须要将数据从磁盘读入到内存中才能判断。(如果此时都已经将数据读入到内存了，那么直接更新内存更快，就没必要使用change buffer了==>因此，在更新时，只有普通索引才会使用到change buffer)==> 因此，更新时，普通索引更快

#### 4.4 实际举例

- 实际例子: 有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。

#### 4.5 change buffer的使用场景

change buffer适用于写多读少的业务。(页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统)

反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

### 5. 为什么表数据delete删掉一半，表文件大小不变？

结论: 索引占据大量的空间

1. 在索引树上删除数据，是标记删除，看起来是”空洞“(标记删除的好处是为了复用)==> 要想完全释放表的数据，应该(重建表)
2. 重建表命令: alter table A engine=InnoDB

## 九. 思考

### 1. 怎么优化

1. 加索引
2. 看执行计划
3. 优化sql语句
4. 分库分表
5. 分结构设计

+ 具体：工作中做过很多sql优化，一般的优化我们并不是出现了问题才进行优化，在进行数据库建模和数据库设计的时候会预先考虑到一些优化问题。例如表字段的类型，长度等等，包括创建合适的索引等方式，但是这种方式只是提前的预防，并不一定能解决所有问题，所以当我们生产环境中出现了sql问题之后，我会从数据库的性能监控，索引的创建和维护，sql语句的跳转，参数的设置，架构的调整等多方面进行综合考虑调整。

### 2. select \* 与 select全部字段

|                             |  **select \***   | **select 全部字段** |
| :-------------------------: | :--------------: | :-----------------: |
|    是否需要解析数据字典     |        是        |         否          |
|        结果输出顺序         | 与建表列顺序相同 |   按指定字段顺序    |
|         表字段改名          |     无需修改     |      需要修改       |
|           可读性            |        低        |         高          |
| <u>是否可以建立索引优化</u> |        否        |         是          |

### 3. varchar/char区别

+  定长/变长：是否由实际存储内容决定
  + char是<u>定长</u>字段，假如申请了char(10)的空间,那么无论实际存储多少内容，该字段都占用10 个字符
  + varchar是<u>变长</u>的，也就是说<u>申请的只是最大长度</u>，占用的空间为实际字符长度+1，最后一个字符存储使用了多长的空间.

+ char查询效率更快

### 4. count(*）count(1) count(字段)

+ count(*) 包括了所有的列，相当于行数，在统计结果的时候，不会忽略字段值为NULL的列

+ count(1) 包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略字段值为NULL的列 

+ count(列名) 只包括列名那一列，在统计结果的时候，会忽略字段值为值为NULL的列（这里的空不是指 空字符串“” 或者 0，而是表示null）的计数，即某个字段值为NULL时，不统计
+ 执行效率上看

  1. 列名为**主键**，count(列名)会比count(1)快  且 select count（主键）的执行效率是最优的；
  2. 列名不为主键，count(1)会比count(列名)快  ；
  3. 如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（*） ；
  4. 如果表**只有一个字段**，则 select count（*）最优。

### 5. drop、truncate、delete

#### 5.1 drop

+ 将表所占用的空间全释放掉（会删除整个表的结构）
+ 将删除表的结构被依赖的约束（constrain)，触发器（trigger)，索引（index)，即：依赖于该表的存储过程/函数将的状态会变为：invalid（无效）

#### 5.2 truncate

+ 一次性地从表中删除所有的数据，并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且，在删除的过程中不会激活与表有关的删除触发器。执行速度快。
+ 删除后，（表结构及其列、约束、索引等保持不变），这个表和索引所占用的空间会恢复到初始大小
+ 应用范围：只能对TABLE

#### 5.3 delete

+ 执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。DELETE语句为DML，该操作会被放到 rollback segment中，事务提交后才生效。如果有相应的tigger，执行的时候将被触发。
+ 不会减少表或索引所占用的空间
+ 应用范围：TABLE、VIEW
