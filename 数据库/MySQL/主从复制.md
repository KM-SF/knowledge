### 为什么需要主从复制

1. 在业务复杂的系统中，有这么一个情景，有一句sql语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。
2. 做数据的热备
3. 架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。

## 什么是mysql的主从复制

+ MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。
+ MySQL 默认采用**异步复制方式**，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。
+ **MySQL复制是异步且串行化**

## 主从复制的两种方式

+ **异步复制**：主服务器写完Binlog，不等同步给从服务器，就返回
  + <u>主库执行操作后，写入Binlog日志后，就返回客户端</u>，这一动作就结束了，并不会验证从库有没有收到，所以，**这样可能会造成主从数据不一致**。
  + 在SQL中，有sync_binlog=n参数，表示每进行n次事务提交，SQL就将Binlog刷新到磁盘。如果该值设为1，就算数据库宕机了，最多只损失一次失误提交。但是sync_binlog=1有以下缺点：①每次事务提交都要刷盘，影响数据库性能 ②SQL只能按照顺序来处理这些请求
  + 缺陷：主库提交事务写入Binlog后，当从库没有从主库得到Binlog时，由于主库宕机或磁盘损坏可能导致该事务的Binlog丢失了，那么从库就不会得到这个事务，也就造成了主从数据的不一致。

+ **半同步复制**：主服务器写完Binlog，等待（同步）给任意一台从服务器，再返回。MySQL5.5之后引入了半同步复制，解决异步复制的主从数据不一致的问题

  + 当主库每次提交一个事务后，不会立即返回，而是：<u>等待其中一个从库接收到Binlog并成功写入RelayLog</u>，才返回客户端。==> 这样，保证了一个事务至少有2份日志（一份保存在主库的Binlog，另一份保存在其中的一个从库的Relay-Log中，从而保证了数据的安全性和一致性）。

  + 在半同步复制时，如果主库的一个事务提交成功了，在推送到从库的过程当中，

    > 【Q1】从库宕机了或网络故障，导致从库并没有接收到这个事务的Binlog 
    >
    >    ==> 此时主库会等待一段时间（这个时间由rpl_semi_sync_master_timeout的毫秒数决定），

    > 【Q2】如果这个时间过后还无法推送到从库
    >
    >    ==> 那MySQL会自动**从半同步复制切换为异步复制**；当从库恢复正常连接到主库后，主库**又会自动切换回半同步复制**

+ 半同步复制的 **“半”** 体现在：

  1. 虽然主从库的Binlog是同步的，但主库不会等待从库执行完Relay-log重放后才返回
  2. 而是确认从库接收到Binlog，达到主从Binlog同步的目的后就返回了

+ 所以从库的数据重放对于主库来说还是有延时的，这个延时就是从库执行Relay-log的时间，<u>所以只能称为半同步</u>。

## 原理

+ 原理：slave会从master读取binlog进行数据同步


1. master将改变记录写到二进制日志（binary log）：这些记录过程叫做二进制日志事件，binary log events。master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中。
2. slave将master的binary log events拷贝到他的中继日志（relay log）：slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件
3. slave重做中继日志事件，将改变应用到自己数据库中：同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。

#### 也可以这样说

- 从库会生成两个线程,一个I/O线程,一个SQL线程;
- I/O线程会去请求主库的binlog,并将得到的binlog写到本地的relay-log(中继日志)文件中;
- 主库会生成一个log dump线程,用来给从库I/O线程传binlog;
- SQL线程,会读取relay log文件中的日志,并解析成sql语句逐一执行;

### 注意

1. master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）
2. slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和master数据保持一致了。
3. Mysql复制至少需要两个Mysql的服务，当然Mysql服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。
4. Mysql复制最好确保master和slave服务器上的Mysql版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本）
5. master和slave两节点间时间需同步

## 主从复制步骤

1. 从库通过手工执行change  master to 语句连接主库，提供了连接的用户一切条件（user 、password、port、ip），并且让从库知道，二进制日志的起点位置（file名 position 号）；    start  slave
2. 从库的IO线程和主库的dump线程建立连接。
3. 从库根据change  master  to 语句提供的file名和position号，IO线程向主库发起binlog的请求。
4. 主库dump线程根据从库的请求，将本地binlog以events的方式发给从库IO线程。
5. 从库IO线程接收binlog  events，并存放到本地relay-log中，传送过来的信息，会记录到master.info中
6. 从库SQL线程应用relay-log，并且把应用过的记录到relay-log.info中，默认情况下，已经应用过的relay 会自动被清理purge

## 组成

1. 每个slave只有一个master
2. 每个slave只能有一个唯一的服务器ID
3. 每个master可以有多个slave

## 问题

+ 数据有一定延时
+ **延迟问题产生原因**：从服务器的两个线程执行速度不一致，可能会造成延迟问题。 
  +  IO线程从主服务器读取日志速度很快（顺序读），而SQL线程重放SQL速度慢，这就会造成从服务器同步数据远远落后于主服务器，导致从服务器数据远远落后于主服务器，（主从数据库长期处于不一致的状态），这种现象就是延迟更新。
  +  主库经常会开多个线程去写，从库只有一个线程在工作，导致从库效率 \<\< 主库效率
+ 具体原因可能如下：
  + 在某些部署环境中，从库所在的机器性能要比主库的机器差。此时如果机器的资源不足就会造成从库同步效率低
  + 从库充当读库，一般情况下主要写的压力在主库，一部分读的压力在从库。而当从库查询压力较大时，从库查询会消耗大量的系统资源，那么必不可少的就会影响同步的速度
  + 大事务执行，如果主库的一个事务执行了10分组，而binlog的写入必须要等待事务完成之后，才会传给从库。那么此时的开始执行时间已经延迟了10分钟
  + 主库的写操作是顺序写binlog，从库单线程去主库顺序读binlog，从库取到binlog后再本地执行。mysql的主从复制都是单线程的操作，但是由于主库是顺序写，所以效率很高，而从库也是顺序读取主控日志，此时效率也比较高。但是当数据拉去回来后，会变成随机写数据了（因为不知道数据要落在哪里），此时成本提高
  + 从库在同步数据的同时，可能跟其他的线程发送了锁抢占情况，也会发送延时
  + 当主库的TPS并发非常高的时候，产生的DDL数量超过1个线程能承受的范围，那么可能会带来延时
  + 在进行binlog日志传输的时候，如果网络带宽不好，也会网络延迟导致数据同步延时

+ **解决方案**：（MTS-multi thread slave）并行复制： 从服务器的数据重放过程采用多线程
+ MTS：要遵循两个规则
  + <u>同一个事务</u>中的MDL，必须分发到同一个worker线程
  + MDL<u>同一行的多个事务</u>，必须分发到同一个worker线程
+ 在并行操作的时候，可能会有并发事务问题，我们的从库在执行的时候可以按照轮询的发放给各个work线程吗
  + 不行。因为事务被发放给worker线程后，不同的woker线程是独立执行的，但是由于CPU的调度策略不同。没办法保证哪个worker线程先执行。很有可能第二个事务比第一个事务先执行，如果他们刚好都是修改同一行数据，那么会导致主从数据不一致问题
+ 同一个事务的多个更新语句，能不能分给不同woker线程执行
  + 不行。例如：一个事务更新了表t1和表t2中的各一行，如果这两条更新语句发送到不同woker线程的话，虽然最终的结果是主从数据一致。但是如果如果表t1执行完的瞬间，从库上有一个查询，就会看到这个事务更新了一半，破了事务逻辑的隔离性
+ 我们进行分发的试试要在每一个woker定义一个hash表，用来保存当前这个woker正在执行的事务所涉及的表。hash表的key按照不同粒度需要存储不同的值
  + 按照库分发：key值是数据库名字
  + 按照表分发：key值是库名+表名
  + 按照行分发：key值是库名+表名+唯一键

### SQL引入二阶段提交，保证主从数据的一致性！

+ SQL会为每一个事务，分配一个事务ID（XID）

+ commit被分为2个阶段：papare/commit

+ Binlog会被当作事务协调者

>  准备阶段（papare）
>
>  - 此时SQL已经成功执行，生成XID信息以及Redo/Undo的内存日志
>  - 然后调用papare方法，将事务状态设置为TRX_PREPARED，并<u>将Redo log刷入磁盘</u>

> 提交阶段（commit）
>
> （1）提交 or 回滚
>
> - 如果事务涉及的所有存储引擎的papare都执行成功，则将SQL语句写入Binlog，调用fsync写入磁盘
> - 如果事务涉及的所有存储引擎的papare都执行失败，则SQL语句不会写入Binlog，此时事务回滚
>
> （2）告诉引擎进行commit
>
> - （假设papare成功，完成事务提交）会清除undo信息，调用fsync刷redo日志到磁盘，将事务设置为TRX_NOT_STARTED状态

> 一旦步骤提交阶段中的操作完成，就确保了事务的提交。此外需要注意的是，每个步骤都需要进行一次fsync操作才能保证上下两层数据的一致性。提交阶段的fsync参数由sync_binlog=1控制，步骤3的fsync由参数innodb_flush_log_at_trx_commit=1控制，俗称“双1”，是保证CrashSafe的根本。

### 组提交

​	为了保证Redo log和binlog的数据一致性，MySQL使用了二阶段提交，由binlog作为事务的协调者。而 引入二阶段提交 使得binlog又成为了性能瓶颈，先前的Redo log 组提交 也成了摆设。为了再次缓解这一问题，MySQL增加了binlog的组提交，目的同样是将binlog的多个刷盘操作合并成一个，结合Redo log本身已经实现的 组提交，分为三个阶段(Flush 阶段、Sync 阶段、Commit 阶段)完成binlog 组提交，最大化每次刷盘的收益，弱化磁盘瓶颈，提高性能。

+ 参考：https://www.cnblogs.com/xibuhaohao/p/10907903.html

## GTID

+ GTID（global transaction）是对于一个已提交事务的编号，并且是全局唯一编号。GTID实际上是由UUID+TID组成的，其中UUID是mysql实例的唯一标识。TID标识该实例上已经提交的事务量，并且随着事务提交单调递增。这种方式保证事务在集群中有唯一ID，强化了主备一致及故障恢复能力

## 图解

+ 主从复制架构图：![主从复制架构图](/数据库/MySQL/images/主从复制架构图.png)

