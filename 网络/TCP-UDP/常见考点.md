### 分层模型

OSI七层模型：物，数，网，传，会，表，应

TCP/IP四层模型：网（数据链路层/网络接口层），网，传，应

OSI七层模型中：应用层 + 表示层 + 会话层 = TPC/IP四层协议：应用层

OSI七层模型中：数据链路层 + 物理层 = TPC/IP四层协议：数据链路层

| OIS七层模型 | TCP/IP四层模型 | 协议                       |
| :---------- | :------------- | -------------------------- |
| 应用层      | 应用层         | http,ftp,nfs,ssh,telnet... |
| 表示层      |                |                            |
| 会话层      |                |                            |
| 传输层      | 传输层         | TCP,UDP                    |
| 网络层      | 网络层         | IP,ICMP,IGMP               |
| 数据链路层  | 数据链路层     | 以太网帧协议，ARP          |
| 物理层      |                |                            |

### TCP如何保证可靠性

答：最大报文长度（mss），ACK到达确认，超时重传，seq序列号发送，数据校验，滑动窗口/拥塞控制

1. 序号/应答机制：数据传输的顺序行
2. 超时重传机制：发送数据后，启动计时器，在超时时间内没有收到ack确认序号，会重发数据包
3. 数据头部校验：TCP保证它的头部和数据的校验和，如果数据包有差错，就丢弃数据不进行ACK
4. 滑动窗口：告诉对方，我这里的缓冲区剩余大小是多少。防止对方发送的数据量大于我缓冲区剩下的大小
5. 拥塞控制：在一方面保证了TCP数据传送的可靠性。然而如果网络非常拥堵，此时再发送数据就会加重网络负担，那么发送的数据段很可能超过了最大生存时间也没有到达接收方，就会产生丢包问题。为此TCP引入慢启动机制，先发出少量数据，就像探路一样，先摸清当前的网络拥堵状态后，再决定按照多大的速度传送数据。
6. 最大报文长度：在建立TCP的时候，会约定数据包的最大长度，超过该长度会进行切分

### 确认/重传机制

问题：确认和重传机制下如果1，2，4，5号的ACK收到了，3号丢失，那么发送端仅重发3号还是全部重发3，4，5？

答： 

​	超时重传：就是发送端发送seq3。

​	快速重传：则是接收端连续发送ACK=3的确认序号，发送端收到了三个 Ack = 3 的确认，知道了 Seq3 还没有收到，就会在定时器过期之前，重传丢失的 Seq3。

### 超时重传时间间隔和次数

指数退避方式

第一次发送数据后，设置的超时时间是1.5s，此后每次重传增加1倍，一直到64秒

一共重传12次，大约9分钟才放弃

## TCP粘包/拆包

+ 现象：因为TCP是流式套接字，是没有界限的一串数据。TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区实际情况进行包的划分。所以，在业务层上认为，一个完整的包可能被TCP拆分成多个包进行发送，也可能把多个小包封装成一个大包发送。这就是所谓的粘包和拆包
+ 本质原因：
  + 要发送的数据小于TCP发送缓冲区的大小，多次写入缓冲区的数据一次性发送出去，发生粘包
  + 要发送的数据大于TCP发送缓冲区剩余空间大小，被拆分成多个数据包发送，发生拆包
  + 待发送的数据大于MSS（最大报文长度）,TCP在传输钱进行拆包
+ 解决方案：由于底层TCP无法知道业务层数据传输情况，所以TCP底层无法保证不发生粘包和拆包情况。这个只能业务层的应用协议来控制
  + 消息定长：发送端将每个数据包封装为固定长度的数据块（长度不够补0填充）
  + 设置消息边界：包尾部添加\n\r，如：FTP协议
  + 消息封装：将消息数据封装为struct{int len; void *data}; 指定数据的长度



### 服务器接入抖动如何解决

+ 现象：例如一个服务器正常情况下接入10K个连接，耗时1000ms。突然有那么一次10K个连接耗时5000ms。耗时时间翻倍称为接入抖动
+ 原因：服务器在开启socket监听和连接的时候，底层会有一个半连接队列和一个全连接队列。**全连接队列满了，没有及时取走fd。**accept函数调用不及时，导致fd没有被取出来。
  + 半连接队列：当客户端调用connect函数是，发送了syn请求给服务器。服务器用listen收到该请求，并且将fd加入到一个半连接队列
  + 全连接队列：服务器用listen收到请求后，回一个syn+ack请求。客户端再回一个ack请求，服务器收到ack回复的时候，将半连接队列的fd拷贝到全连接队列。然后调用accept函数将fd从全连接队列中取出来。
  + 类似于生产者和消费者。客户端不断发起接入生产，服务器的队列满了，没被消费
+ 解决办法：
  + 将listen的第二个参数设置大一点，可以延缓出现的概率（不能根治）
  + 用多线程或者多进程的方式，并行调用accept函数。

### ！！！三次握手过程

![3次握手](https://github.com/594301947/knowledge/blob/master/%E7%BD%91%E7%BB%9C/images/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.jpg)

1. 客户端向服务端发送连接请求报文（客户端进入**SYN-SEND**状态）。SYN标志位为1，seq序号为**n**。
2. 服务端收到客户端请求（服务端结束**LISTEN**状态）。发送应答报文（服务端进入**SYN-RCVD**状态）。SYN标记位为1，seq序号为**k**。ACK标记位为1，ack确认序号为**n+1**
3. 客户端收到应答报文，再发送一个应答报文给服务端。（客户端和服务端状态进入**ESTABLISHEN**）。ACK标记位为1，ack确认序号为**k+1**，seq序号为n+1。

### ！！！为什么要进行三次握手？而不是2次或者4次

答：执行完步骤1，2后。C给S发送了连接请求，并且S回复了C可以连接，此时C知道自己和S端没问题了。但是S端不知道C端是否没问题。因为需要步骤3，让C告诉S没问题。这也S和C都互相知道对方没问题，连接建立成功

>  两次握手：**防止已失效的请求报文段突然又传送到了服务端而造成连接的误判**
>
> ​	假如客户端发出连接请求A，由于网络原因，服务端并没有收到A，于是客户端又发送了连接请求B，并建立了连接，完成通信，断开连接。这时候，服务端突然又收到了A，于是看作是一次新的连接请求，进行第二次握手，由于不存在第三次握手，所以这时已经建立了TCP连接。但实际上客户端并没有发起连接，所以不会传递数据，那么这条连接就会变成一条死连接。络延迟，延迟的连接请求后面可能会再次发送给服务端，服务端却不知道这个连接是之前的连接，就会与延迟的连接建立新连接
>

> 四次握手：
>
> ​	3次握手已经能够让双端都确认建立了有效的连接，再多一次造成浪费

### ！！！四次挥手过程

四次挥手时序图：

<img src="https://github.com/594301947/knowledge/blob/master/%E7%BD%91%E7%BB%9C/images/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.jpg" alt="四次挥手时序图" style="zoom:150%;" />

过程：

1. 客户端向服务器发送断开连接报文（客户端进入**FIN-WAIT-1**阶段），FIN标记位为1，seq为X（随机值）
2. 服务器收到客户端发来的断开连接报文后，发送确认报文（服务器结束**ESTABLISHEN**，进去**CLOSE-WAIT**阶段），ACK标记位位1，ack确认序号**X+1**，seq序号为Y随机值。客户端收到服务器回的的确认报文后，客户端进入**半关闭状态**（退出**FIN-WAIT-1**阶段，进入**FIN-WAIT-2**阶段）
3. 服务器发送断开连接报文（服务器退出**CLOSE-WAIT**阶段，进入**LAST-ACK**阶段）。FIN标记为为1，seq序号位为Z随机值。客户端收到服务器发送的断开连接报文后，客户端退出**FIN-WAIT-2**阶段，进入**TIME-WAIT**阶段
4. 客户端进入TIME-WAIT阶段时，会立即发送最后一个确认报文，ACK标记位为1，ack确认序号位**Z+1**。服务器收到客户端发送的确认报文后，退出**LAST-ACK**阶段，进入**CLOSED**阶段
5. 如果这个2MSL时间内服务器没有再一次发送FIN报文的话，那个2MSL时长 后，客户端退出TIME-WAIT阶段，进入**CLOSED**阶段

### ！！！为什么是4次挥手，不是3次

答：TCP建立连接的时候之所以是3次握手，是因为第二次握手的过程中，s端发送给c端的TCP报文（SYN+ACK）一起发送，其中**ACK报文是用来应答的，SYN报文是用来同步的**。而释放连接时，之所以需要4次是因为ACK确认接收报文，FIN释放连接报文是分别由第二次和第三次分开发送。

+ 主动断开方发送FIN时，被动断开方要回复ACK，意思是“我收到你的FIN了”；
+ 主动断开方发送FIN并不意味着立即关闭TCP连接，而是告诉对方自己没有更多的数据要发送了，只有当对方发完自己的数据再发送FIN后，才意味着关闭TCP连接；
+ 被动断开方收到FIN并回复ACK后，此时TCP处于“半关闭”状态，为保证被动断开方可以继续发送数据，所以第二个FIN并不会伴随ACK发送，所以比连接时多一个报文段。

### ！！！为什么建立连接的时候ACK+SYN是一起发送？释放连接时ACK和FIN是分开发送

1. 建立连接时：被动方s端从LISTEN阶段进入SEND_RECV阶段不需要做什么准备，可以直接发送ACK+SYN
2. 断开连接时：被动方s端，突然收到c端断开连接的请求，**此时可能还有数据还要处理，所以不能立即断开**，需要等到数据处理完毕后，再告诉c端可以完全断开。所以先回了ACK确认报文（告诉c端你要断开的请求我收到了），等到数据处理完毕后，再发送FIN释放连接报文，断开了解

### ！！！TIME_WAIT存在原因

+ 2MSL：1MSL，为1段TCP报文再传输过程中最大生命周期
+ 等待2MSL的根本原因，为了实现TCP全双工可靠的释放
  + 在第4次挥手时，C端向S端发送最后的ACK，也可能会丢失，导致S端收不到该确认报文。当S端在1MSL时间内没有接收到C端发送的ACK确认报文时，S端会再次向C端**重新发送FIN报文（重传机制）**。C端收到FIN报文后，会重新发送最后一个ACK报文，直到S端能成功的接收到ACK报文，连接才真正的断开。
+ 为了使就得数据包在网络中因过期而消失（防止被动方收到主动方发送的过期数据）
  + 先假设没有TIME_WAIT状态的限制，如果当前有一个TCP连接（local_ip，local_port，remote_ip，remote_port）在断开的同时，以相同的4元组去建立新的连接。那么TCP协议栈就无法区分前后两条tcp连接是不同的，在它看来就一条连接。导致前一条TCP已经关闭的连接发送出去的数据，，通过之后的新连接，仍然可以发送给s端

### ！！！TIME_WAIT过多

+ 主动调用close的一方，会发送最后一个ACK后，进入TIME_WAIT状态
+ TIME_WAIT过多导致的原因是：**大量的短连接**。许多短连接正在被快速的创建和关闭，由于关闭需要等到2MSL时长，看你导致出现大量的TIME_WAIT
+ 危害：
  + 每个套接字都要消耗一个fd，缓冲区等等。浪费资源（类似僵尸资源）
  + 如果没有设置地址/端口复用，在TIME_WAIT时期内不能用该地址
+ 如果服务端出现大量的time_wait。那么可能是业务逻辑上面判断出现了什么问题导致主动调用close。解决方法：socket设置重用

### ！！！CLOSE_WAIT过多

+ 被动方接受到close请求，然后发送ACK后进入CLOSE_WAIT。
+ 原因：被动方没有及时调用close。代码逻辑有问题，处理异常情况的时候没有调用close函数

### ！！！半关闭

+ 半关闭：一个套接字内部由内核借助两个缓冲区实现（一个读缓存，一个写缓存），当处于半关闭状态的时候：**只关闭了写缓存，但是连接还是存在的，还能接收数据。**
+ 半关闭状态：主动发起关闭的一方不能再发送数据了，只能接受数据

### ！！！TCP状态转换图

TCP状态转换图：![TCP状态转换图](https://github.com/594301947/knowledge/blob/master/%E7%BD%91%E7%BB%9C/images/TCP%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2%E5%9B%BE.jpg)

> **建立连接**：
>
> + 主动发起连接请求端：<u>**CLOSE**</u> --》 发送SYN --》 <u>**SEND_SYN**</u> --》 接收ACK，SYN --》 <u>**SEND_SYN**</u> --》 发送ACK --》<u>**ESTABLISHED**</u>（数据通信状态）
>
> + 被动接收连接请求端：<u>**CLOSE**</u> --》 <u>**LISTEN**</u> --》 接收SYN --》<u>**LISTEN**</u> --》 发送ACK，SYN --》SYN_RCVD --》接收ACK --》 <u>**ESTABLISHED**</u>（数据通信状态）

> **断开连接：**
>
> + 主动关闭连接请求端：<u>**ESTABLISHED**</u>（数据通信状态） --》 发送FIN --》 <u>**FIN_WAIT1**</u> --》 接收ACK --》<u>**FIN_WAIT2**</u>（半关闭）--》接收端发送FIN --》<u>**FIN_WAIT_2**</u>（半关闭）--》回发ACK --》<u>**TIME_WAIT**</u>（只有主动关闭连接方，才会有该状态）--》等待**2MSL**时长 --》<u>**CLOSE**</u>
> + 被动关闭连接请求端：<u>**ESTABLISHED**</u>（数据通信状态）--》接收FIN --》 <u>**ESTABLISHED**</u>（数据通信状态）--》发送ACK --》<u>**CLOSE_WAIT**</u> --》发送FIN --》<u>**LAST_ACK**</u> --》接收ACK --》<u>**CLOSE**</u>

### 产生RST的场景

+ RST表示复位，用来异常的关闭连接。发送RST包关闭连接时，不必等到缓冲区的数据包全部发送（将直接丢弃缓冲区中的数据）。接收端收到RST包，也不必发送ACK包来确认，直接就关闭
+ 客户端去连接一个未打开的端口：会向该客户端发送一个RST
+ 请求超时：才用SO_RCVTIMEO 选项设置套接字选项，超时后，会发送RST
+ 提前关闭：B阻塞接收4096个数据后，调用close。A向B阻塞发送5000个数据，此时B接收到4096个字节后，就会调用close，将返回接收到4096个字节的ACK给A，并再发送RST给A，断开连接
+ 向一个已经关闭的套接字发送数据：A与B建立连接后，此时B调用close关闭fd，A再向B的fd发送数据，A会受到RST

### 长连接和短连接

|      | 短连接                                                       | 长连接                                                       |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 概念 | 客户端和服务器每进行一次操作，就要建立一次连接，任务执行完断开 | 客户端和服务器建立连接，长期保持连接。只有当所有任务执行完才断开 |
| 缺点 | 请求频繁时，频繁的创建和销毁消耗资源，导致产生大量的TIME_WAIT | 占用连接的资源，资源个数优先                                 |
| 优点 |                                                              | 省去较多的TCP建立和关闭带来的浪费                            |
| 场景 | Web网址的HTTP服务                                            | 操作频繁，点对点通信，连接数不能太多                         |

### 保活：心跳包机制

+ 方案一：TCP套接字选项SO_KEEPALIVE。系统每两个小时定时发送探测消息
+ 方案二：应用层，自定义心跳包机制。
  + client每隔一段时间向server发送探测包，并启动定时器。
  + server接收到包后，进行回应
  + client在规定时间内没有收到回应，则认为server挂了。否则认为server正常，删除超时定时器。

### 滑动窗口

+ 目的：控制发送端的发送速度，防止发送数据过快，导致接收方接收不过来
+ 原理：接收方每次收到数据，向发送方返回ACK的时候，会携带一个接收窗口大小的字段

### 为什么需要滑动窗口

答：如果是一发一应的模型，一次发送之后需要等待对方的应答才能发送下一次，那这种模型发送性能极差。使用滑动窗口就可以大大提高发送的性能，在对端窗口大小内都能发送

### 零窗口和坚持定时器

+ 当接收缓冲区满时，B在回复ACK的时候，会告诉A自己的接收窗口rwnd=0了，此时A接收到窗口大小为0后，就会挺尸发送数据。（此时启动坚持定时器）
+ B发送给A窗口为0的确认包后，A就不会再给B发送数据。等待一段时间后，B缓冲区有空间了，就会向A发送一个报文，通知A现在有发送数据了。但是该报文再传输过程中一旦丢失，就会出现下面“双方死等现象”。A等待B通知它发送数据，B发送报文后等待A发送数据。**为此就坚持定时器就是解决该场景**
+ 坚持计时器：在A接收到一个窗口为0的报文后，将每隔一段时间，发送给B探测报文，即探测接收窗口大小的报文，一旦接收窗口大小不为0，就可以继续发送数据

 ### 拥塞控制

+ 目的：通过拥塞窗口cwnd来防止过多的数据注入到网络中，导致网络拥堵。和滑动窗口不同，解决的问题也不同
+ 原理：通过“发送方”的拥塞窗口cwnd与门限值ssthresh大小比较，根据比较结果，调用响应的拥塞控制算法

### 慢启动

+ 一开始建立连接后，将cwnd设为1，cwnd是指数增长的，直到cwnd增大到门限值ssthresh，就会进入拥塞避免阶段

### 拥塞避免

+ cwnd是线性增长的（“加法增大”），直到发生【网络超时】，就会重新开启慢启动。此时门限值ssthresh设置窗口的1/2，cwnd设置为1，继续执行慢启动

### 快重传

+ 当发送方收到同一个包的连续3次重复确定时（说明网络丢包），此时不用等待网络超时，直接重传数据给接收方

### ！！！TCP/UDP的区别

| TCP                                                          | UDP                  |
| ------------------------------------------------------------ | -------------------- |
| 面向连接（可靠）                                             | 面向无连接（不可靠） |
| 流式协议（粘包拆包问题）                                     | 报文（有边界）       |
| 处理和传输速度较慢                                           | 处理/传输速度较快    |
| 具有可靠性（头部校验，滑动窗口，拥塞控制，超时重传机制，应答机制） | 不可靠，需要自己保证 |

### ！！！TCP可靠，为什么很多项目仍选择UDP

答：UDP不考虑数据的可靠性，传输效率更快，尽最大可能传递数据。很多项目不需要太考虑可靠性，但是需要很快的传输速度，例如音视频。如果需要很快的传输速度，又需要数据可靠，那需要应用层自己实现一套可靠的机制

### ！！！TCP是可靠的，为什么通信会丢包

+ TCP协议本身是保证传输的数据完整性不会丢数据的。
+ 如果通信中发现缺少数据或者丢包，那么，最大的可能在于程序发送的过程或者接收的过程出现问题。
+ 例如：A给B以极高的频率调用send发送数据，那么就可能在send时发生错误（原因可能很多：缓冲区溢出，多线程同步等），如果send发生错误却没有重发数据，最终会导致B收到数据小于A发送的数据
+ 这种现象本质上不是丢包，也不是丢数据。而是因为程序处理有错误，导致有些数据没有成功被发送出去

### ！！！UDP可靠性设计方案：KCP/RUDP

**主要思想参考TCP可靠性方案**

1. 数据包切分（MTU）：每次调用sendto，只能发送一个报文，当发送的报文超过MTU时，就会报错或者丢包。对于一个很长的UDP数据报，要进行切分多个端进行传输
2. 序列号seq（保证不失序）：给每个数据包都添加一个应用层header，header中包含一个字段序列号seq，接收端接收到数据后，使用该序列号对数据进行排序，保证数据有序
3. 发送与确认机制（保证不丢失数据）：发送端每次发送一个数据，都要等到接收方回复一个ACK
4. 重传机制（保证不丢失数据）：发送完数据后，要启动一个超时定时器，一旦超时就要重新发送数据
5. 滑动窗口/流量控制（保证尽可能合理的多发数据）：为了加速数据的发送效率，参考TCP的滑动窗口，允许发送端一次可以发送滑动窗口大小的字段给接收方。为了避免发送数据较快，引入流量控制，根据对方的接收窗口大小，调整发送数据的速度



### listen的第二个参数

```
listen(int fd, int backlog)
```

TCP通过三次握手建立连接，采取两个队列：请求队列，已连接队列

第二个参数：请求队列的大小，当请求数超过长度时，将会被丢弃

1. 未连接队列大小设置为100，此时有1000个连接请求，那么只处理前100个，后面900个丢弃
2. 当连接建立成功后，将从请求队列中剔除，加入到已连接队列

### 连接建立是在accept函数吗

答：socket客户端连接上服务器是在listen之后而非accept之时

1. 只要服务器开启listen，客户端调用connect时，就连接成功（三次握手成功）
2. accept只是将fd从连接队列中移除
3. 服务器在listen调用之后sleep，没有调用accept。客户端仍然可以调用send发送数据，也会发送成功

### close/shutdown，引用计数

+ fd引用计数：对于每个打开的套接字fd，它都是有一个引用计数，当有多个继承打开该fd时，引用计数+1

+ close：会关闭套接字，但是调用close时，有其他进程共享该套接字，那么该连接仍是打开的，该连接在其他进程可以进行读写。只是本进程已经关闭。对应的fd引用计数-1。只有当fd引用计数清0时，才会真正关闭fd
+ shutdown：会将fd引用计数清零，其他进程共享的fd也无法使用。
+ shutdown相当于将“主动关闭连接”这件事分成两步：
  + A调用shutdown关闭写方向，保留读方向。B调用read将返回0，然后B手动调用shutdown关闭读方向，保留写方向。（此时A进入半关闭状态）
  + B发送完数据后，调用shutdown关闭写方向。A调用read将返回0，然后A手动调用shutdown关闭读方向。（此时A，B进入关闭状态）

### UDP/TCP的connect区别

1. TCP的connect会引起三次握手，UDP不会
2. 由于UDP是无连接的，在调用connect时其实没有向外发包，只是在协议栈中记录了该状态
3. UDP调用了connect后，也可以用send和write，read和recv。当然也可以调用sendto，recvfrom
4. UDP可以调用多次connect，TCP只能调用一次connect

### UDP多次调用connect目的

1. 指定一个新ip，port连接
2. 断开和之前的ip，port连接：将connect第二个参数中的sin_famliy设置成AF_UNSPEC
3. 提高发送数据的效率
   1. 普通的UDP发送两个报文内核做了：建立连接->发送报文->断开连接->建立连接->发送报文->断开连接
   2. 采用connect方式的UDP发送两个报文内核做了：建立连接->发送报文->发数码管纳帕纹
4. 异步ICMP错误不会反悔给unconnect的udp套接字，调用connect后，可以接收到异步ICMP的错误



### select/poll/epoll的区别

|            | epoll            | select                                                       | poll                                                         |
| ---------- | ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 时间复杂度 | O(1)             | 当有 I/O 时间发生时，不能知道是哪个 fd 触发了，只能无差别的轮询所有 fd。 O(N) | 当有 I/O 时间发生时，不能知道是哪个 fd 触发了，只能无差别的轮询所有 fd。 O(N) |
| 底层实现   | 红黑树+就绪链表  | 数组（poll 与 select 没有本质上的区别， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。） | 链表（poll 与 select 没有本质上的区别， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。） |
| 缺点       | 消耗的资源比较多 | 最大连接数有上限<br>需要对fd集合进行轮询扫描<br>需要将fd集合从内核和用户空间来回拷贝 | 需要对fd集合进行轮询扫描<br/>需要将fd集合从内核和用户空间来回拷贝 |

### select

+ select：是最初解决IO阻塞问题的方法。用结构体fd_set来告诉内核监听多个文件描述符，该结构体被称为描述符集。由数组来维持哪些描述符被置位了。对结构体的操作封装在三个宏定义中。通过轮寻来查找是否有描述符要被处理。

+ 存在的问题：

  1. 内置数组的形式使得select的最大文件数受限与FD_SIZE；

  2. **每次调用select前都要重新初始化描述符集，将fd从用户态拷贝到内核态，每次调用select后，都需要将fd从内核态拷贝到用户态；**

  3. 轮寻排查当文件描述符个数很多时，效率很低；

### poll

+ poll：通过一个可变长度的数组解决了select文件描述符受限的问题。数组中元素是结构体，该结构体保存描述符的信息，每增加一个文件描述符就向数组中加入一个结构体，结构体只需要拷贝一次到内核态。poll解决了select重复初始化的问题。轮寻排查的问题未解决。

### epoll底层实现原理

+ 底层实现原理：
  + 当内核初始化epoll时，会开辟一块内核高速cache区，用于安置我们监听的socket，这些socket会以红黑树的形式保存在内核的cache里，以支持快速的查找，插入，删除．同时，建立了一个list链表，用于存储准备就绪的事件．所以调用epoll_wait时，在timeout时间内，只是简单的观察这个list链表是否有数据，如果没有，则睡眠至超时时间到返回；如果有数据，则在超时时间到，拷贝至用户态events数组中．
  + 那么，这个准备就绪list链表是怎么维护的呢？当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。
+ epoll_create：创建一个 epoll 文件描述符，底层同时创建一棵红黑树 and 一个就绪链表 rdlist。红黑树存储了所有监控的文件描述符；就绪链表存储就绪文件描述符
+ epoll_clt：
  + 删除：将文件描述符从红黑树上摘除
  + 插入：先查看红黑树是否有该 fd：如果有，不再插入；如果没有，插入。（epoll 使用“事件”的就绪通知方式，通过 epoll_ctl 注册 fd，一旦该 fd 就绪，内核就会采用类似callback 的回调机制来激活该 fd，epoll_wait 便可以收到通知）
+ epoll_wait：只是从就绪链表中取出元素，将该元素上的事件复制到用户态区间（使用 mmap 提高效
  率）

### epoll水平触发和边缘触发

+ 水平触发：只要高电平 or 低电平时，才会触发。即：有数据可读时，就会一直触发（事件没处理完，不会从激活链表中摘除，会一直触发，直到事件处理完，才移除激活队列）
+ 边缘触发：只有电平发生变化时，才会触发（事件来到时，只触发一次，就从激活链表中摘除）
+ 举例：一个管道收到了 1kb 的数据，epoll 会立即返回，此时读了 512 字节数据，然后再次调用 epoll。
  + 如果是水平触发的，epoll 会立即返回，因为有数据准备好了
  + 如果是边缘触发的不会立即返回，因为此时虽然有数据可读，但是已经触发了一次通知，在这次通知到现在还没有新的数据到来，直到有新的数据到来时，epoll 才会返回。
+ 水平触发注意：对于读事件，如果用水平触发不用担心数据有没有读完，因为下次 epoll 返回时，没有读完的 socket 依然会被返回。但是要注意这种模式下的写事件，因为是水平触发，每次socket 可写时，epoll 都会返回，当我们写的数据包过大时，一次写不完，要多次才能写完或者每次 socket 写都写一个很小的数据包时，每次写都会被 epoll 检测到，因此长期关注 socket写事件会无故 cpu 消耗过大甚至导致 cpu 跑满，所以在水平触发模式下一般不关注 socket 可写事件而是通过调用 socket write 或者 send api 函数来写 socket
+ 水平触发在效率上是没有边缘触发高的，因为每一次 socket 读或写可能被返回两次甚至多次，所以有时候也会用到边缘触发。但是这种模式下在读数据的时候一定要注意，因为如果一次没有把数据读完，且在 socket 没有新的数据可读时，epoll 就不回返回了，将导致数据没有读取完。、
+ 对于边缘触发，必须：使用非阻塞 IO 和  while 循环一次性读写完全部数据

### EPOLL_ONESHOT 和 边缘触发

+ 解释EPOLL_ONESHOT：由上面我们知道，采用 ET 模式，为了保证数据能够全部读完，采用 while 循环的方式！但是，如果在 while 循环读取过程中，此时有新的事件到达，很可能触发了其他线程来处理这个 socket，这就发生了错乱！
+ 解决方案：一旦事件触发后，就调用 epoll_clt 将事件从红黑树上摘除，直到处理完该事件，再调用 epoll_clt 将该事件添加到红黑树。这样，就可以保证同一个 fd 事件在同一时刻只能触发一次！







### 在浏览器地址栏键入URL，按下回车之后会经历以下流程：

1. 浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址；
2. 解析出 IP 地址后，根据该 IP 地址和默认端口80，和服务器建立TCP连接；
3. 浏览器发出读取文件（URL中域名后面部分对应的文件）的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器；
4. 服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器；
5. 释放 TCP连接；
6. 浏览器将该 html 文本并显示内容；

### GET和POST的区别

1. 概括：
   1. 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；
   2. POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）

2. 区别：get参数通过url传递，post放在request body中。
3. get请求在url中传递的参数是有长度限制的，而post没有。
4. get比post更不安全，因为参数直接暴露在url中，所以不能用来传递敏感信息。
5. get请求只能进行url编码，而post支持多种编码方式。
6. get请求会浏览器主动cache
7. get请求参数会被完整保留在浏览历史记录里，而post中的参数不会被保留。
8. GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。
9. GET产生一个TCP数据包；POST产生两个TCP数据包。