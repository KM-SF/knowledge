## 线程和进程

+ 进程是对运行时程序的封装，**是系统进行资源调度和分配的的基本单位**，实现了操作系统的并发；
+ 线程是进程的子任务，**是CPU调度和分派的基本单位**，用于保证程序的实时性，实现进程内部的并发；**线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。**
+ 区别：

  1. 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。
  2. 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。**（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）**
  3. 进程是资源分配的最小单位，线程是CPU调度的最小单位；
  4. 系统开销： **由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。**
  5. 通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要线程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，**线程的切换、同步和通信都无须操作系统内核的干预**
  6. 进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。
  7. **进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉**
  8. 进程适应于多核、多机分布；线程适用于多核

## 有了进程，为什么还要有线程？

+ 线程产生的原因：进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量；但是其具有一些缺点：**进程在同一时间只能干一件事。进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。**

+ 操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。
+ **线程的优势如下：**
  + 从资源上来讲，线程是一种非常"节俭"的多任务操作方式。在linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种"昂贵"的多任务工作方式。
  + 从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一个线程开销的30倍左右。
  + 从通信机制上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进程下的线程之间贡献数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。

## 多线程和多进程的不同

+ 多线程之间共享同一个进程的地址空间，线程间通信简单，同步复杂，线程创建、销毁和切换简单，速度快，占用内存少，适用于多核分布式系统，但是线程间会相互影响，一个线程意外终止会导致同一个进程的其他线程也终止，程序可靠性弱。
+ 多进程间拥有各自独立的运行地址空间，进程间不会相互影响，程序可靠性强，但是进程创建、销毁和切换复杂，速度慢，占用内存多，进程间通信复杂，但是同步简单，适用于多核、多机分布。

## 进程和线程的区别

1. 进程是cpu资源分配的最小单位，线程是cpu调度的最小单位。
2. 进程有独立的系统资源，而同一进程内的线程共享进程的大部分系统资源,包括堆、代码段、数据段，每个线程只拥有一些在运行中必不可少的私有属性，比如tcb,线程Id,栈、寄存器。
3. 一个进程崩溃，不会对其他进程产生影响；而一个线程崩溃，会让同一进程内的其他线程也死掉。
4. 进程在创建、切换和销毁时开销比较大，而线程比较小。进程创建的时候需要分配系统资源，而销毁的的时候需要释放系统资源。进程切换需要分两步：切换页目录、刷新TLB以使用新的地址空间；切换内核栈和硬件上下文（寄存器）；而同一进程的线程间逻辑地址空间是一样的，不需要切换页目录、刷新TLB。
5. 进程间通信比较复杂，而同一进程的线程由于共享代码段和数据段，所以通信比较容易。

## 游戏服务器应该为每个用户开辟一个线程还是一个进程，为什么？

+ 游戏服务器应该为每个用户开辟一个进程。因为同一进程间的线程会相互影响，一个线程死掉会影响其他线程，从而导致进程崩溃。因此为了保证不同用户之间不会相互影响，应该为每个用户开辟一个进程

## 多进程和多线程的使用场景

+ 多进程模型的优势是CPU

+ 多线程模型主要优势为线程间切换代价较小，因此适用于I/O密集型的工作场景，因此I/O密集型的工作场景经常会由于I/O阻塞导致频繁的切换线程。同时，多线程模型也适用于单机多核分布式场景。

## 死锁发生的条件

+ 死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。死锁发生的四个必要条件如下：
  + 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；
  + 请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源
  + 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放
  + 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链

## 解决死锁

+ 解决死锁的方法即破坏上述四个条件之一，主要方法如下：
  + 资源一次性分配，从而剥夺请求和保持条件
  + 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件
  + 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件

## 协程

+ 协程，又称微线程，纤程，英文名Coroutine。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。

+ 协程和线程区别
  + **那和多线程比，协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制（发生在用户态），因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。**
  + 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

## Linux虚拟地址空间

+ 为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。
+ **虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。**
+ 4G 指的是最大的寻址空间为4G
+ 进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。
+ 请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。
+ **虚拟内存的好处：**

  1. 扩大地址空间；

  2. 内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。

  3. 公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。

  4. 当进程通信时，可采用虚存共享的方式实现。

  5. 当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存

  6. 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高

  7. 在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片
+ 虚拟内存的代价：

  1. 虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存
  
  2. 虚拟地址到物理地址的转换，增加了指令的执行时间。
  
  3. 页面的换入换出需要磁盘I/O，这是很耗时的
  
  4. 如果一页中只有一部分数据，会浪费内存。
## 为么要引入虚拟地址呢？

1. 操作系统是不希望一个普通的进程可以直接对物理地址写数据的。如果一个普通的进程可以随意的向物理地址中写数据。那么一个恶意进程一旦知道别的进程的物理地址，那不是很容易就把别的进程的数据篡改了嘛。
2. 每个进程在创建之初，它所需要的内存大小都是不确定的。如果按照您的说法直接给进程分配固定的物理内存，假如两个进程在创建之初都直接各自分配了 1G 的物理空间。但实际运行起来，A 进程只用了 100M，而 B 进程需要 1.9 G。那么给 A 进程分配的空间就浪费了，而给 B 进程分配的空间又不够。都采用虚拟地址，表面看上去每个进程都可以独占内存的所有空间。在进程运行的途中再对虚拟地址和物理地址进行转换，可以有效的利用空间。甚至在内存不足的情况下，还可以把进程的内存存到硬盘里，切换到该进程时再从硬盘读取。
3. 虚拟内存可以为每个进程提供一个一致的地址空间，这样程序员就不需要管理内存了，这也降低了编程的复杂度。

## 程序的内存结构

+ BSS段（未初始化数据区）：通常用来存放程序中未初始化的全局变量和静态变量的一块内存区域。BSS段属于**静态分配**，程序结束后静态变量资源由系统自动释放。

+ 数据段：存放程序中已初始化的全局变量的一块内存区域。数据段也属于**静态内存分配**

+ 代码段：存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域属于只读。在代码段中，也有可能包含一些只读的常数变量

+ 栈区：由编译器自动释放，存放函数的参数值、局部变量等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存放到栈中。然后这个被调用的函数再为他的自动变量和临时变量在栈上分配空间。每调用一个函数一个新的栈就会被使用。栈区是从高地址位向低地址位增长的，是一块连续的内存区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。

+ 堆区：用于动态分配内存，位于BSS和栈中间的地址区域。由程序员申请分配和释放。堆是从低地址位向高地址位增长，采用链式存储结构。**频繁的malloc/free造成内存空间的不连续，产生碎片。当申请堆空间时库函数是按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。**

可执行程序在运行时又多出两个区域：栈区和堆区。

text段和data段在编译时已经分配了空间，而BSS段并不占用可执行文件的大小，它是由链接器来获取内存的。

bss段（未进行初始化的数据）的内容并不存放在磁盘上的程序文件中。其原因是内核在程序开始运行前将它们设置为0。需要存放在程序文件中的只有正文段和初始化数据段。

data段（已经初始化的数据）则为数据分配空间，数据保存到目标文件中。

数据段包含经过初始化的全局变量以及它们的值。BSS段的大小从可执行文件中得到，然后链接器得到这个大小的内存块，紧跟在数据段的后面。当这个内存进入程序的地址空间后全部清零。包含数据段和BSS段的整个区段此时通常称为数据区。

## 系统中的缺页中断

+ **malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。**

+ 缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。**每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。**

+ 缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：
  1. 保护CPU现场
  2. 分析中断原因
  3. 转入缺页中断处理程序进行处理
  4. 恢复CPU现场，继续执行

+ 缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：
  1. 在指令执行期间产生和处理缺页中断信号
  2. 一条指令在执行期间，可能产生多次缺页中断
  3. 缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。

## OS缺页置换算法

+ 当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。当前操作系统最常采用的缺页置换算法如下：
  + 先进先出(FIFO)算法：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。
  + 最近最少使用（LRU）算法: 置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

+ 当前最常采用的就是LRU算法。

## 并发(concurrency)和并行(parallelism)

+ 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。

+ 并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。

## 线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的

+ **线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息。其中寄存器主要包括SP PC EAX等寄存器**，其主要功能如下：
  + SP:堆栈指针，指向当前栈的栈顶地址
  + PC:程序计数器，存储下一条将要执行的指令
  + EAX:累加寄存器，用于加法乘法的缺省寄存器

## 虚拟内存置换的方式（缓存淘汰算法）

+ 比较常见的内存替换算法有：FIFO，LRU，LFU，LRU-K，2Q

> FIFO（先进先出淘汰算法）
>
> 思想：最近刚访问的，将来访问的可能性比较大。
>
> 实现：使用一个队列，新加入的页面放入队尾，每次淘汰队首的页面，即最先进入的数据，最先被淘汰。
>
> 弊端：无法体现页面冷热信息

> LFU（最不经常访问淘汰算法）
>
> 思想：如果数据过去被访问多次，那么将来被访问的频率也更高。
>
> 实现：每个数据块一个引用计数，所有数据块按照引用计数排序，具有相同引用计数的数据块则按照时间排序。每次淘汰队尾数据块。
>
> 开销：排序开销。
>
> 弊端：缓存颠簸。

> LRU（最近最少使用替换算法）
>
> 思想：如果数据最近被访问过，那么将来被访问的几率也更高。
>
> 实现：使用一个栈，新页面或者命中的页面则将该页面移动到栈底，每次替换栈顶的缓存页面。
>
> 优点：LRU算法对热点数据命中率是很高的。

## 软链接和硬链接区别

+ 为了解决文件共享问题，Linux引入了软链接和硬链接。除了为Linux解决文件共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。若1个inode号对应多个文件名，则为硬链接，即硬链接就是同一个文件使用了不同的别名,使用ln创建。若文件用户数据块中存放的内容是另一个文件的路径名指向，则该文件是软连接。软连接是一个普通文件，有自己独立的inode,但是其数据块内容比较特殊。

## 什么是大端小端以及如何判断大端小端

+ 大端是指低字节存储在高地址；小端存储是指低字节存储在低地址。我们可以根据联合体来判断该系统是大端还是小端。因为联合体变量总是从低地址存储。

## 用户态和内核态

+ 用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。
+ 用户态拥有最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据结构和程序。
+ **内核态和用户态之间的转换方式主要包括：系统调用，异常和中断。**
+ 为了安全性。在cpu的一些指令中，有的指令如果用错，将会导致整个系统崩溃。分了内核态和用户态后，当用户需要操作这些指令时候，内核为其提供了API，可以通过系统调用陷入内核，让内核去执行这些操作。

## 系统调用

+ 在计算机中，系统调用（英语：system call），又称为系统呼叫，指运行在用户空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供了用户程序与操作系统之间的接口（即系统调用是用户程序和内核交互的接口）。
+ 操作系统中的状态分为内核态和用户态。大多数系统交互式操作需求在内核态执行。如设备IO操作或者进程间通信。特权指令：一类只能在核心态下运行而不能在用户态下运行的特殊指令。不同的操作系统特权指令会有所差异，但是一般来说主要是和硬件相关的一些指令。**用户程序只在用户态下运行，有时需要访问系统核心功能，这时通过系统调用接口使用系统调用。**
+ **应用程序有时会需要一些危险的、权限很高的指令，如果把这些权限放心地交给用户程序是很危险的(比如一个进程可能修改另一个进程的内存区，导致其不能运行)，但是又不能完全不给这些权限，于是有了系统调用，危险的指令被包装成系统调用，用户程序只能调用而无权自己运行那些危险的指令。**
+ 计算机硬件的资源是有限的，为了更好的管理这些资源，所有的资源都由操作系统控制，进程只能向操作系统请求这些资源。操作系统是这些资源的唯一入口，这个入口就是系统调用。

## 用户态到内核态的转化原理

+ 用户态切换到内核态的3种方式
  1. 系统调用：这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。
  2. 异常：当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。
  3. 外围设备的中断：当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

+ 切换操作：从出发方式看，可以在认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断处理机制基本上是一样的，用户态切换到内核态的步骤主要包括
  1. 从当前进程的描述符中提取其内核栈的ss0及esp0信息。
  2. 使用ss0和esp0指向的内核栈将当前进程的cs,eip，eflags，ss,esp信息保存起来，这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。
  3. 将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。

## 五种IO模型

+ 阻塞IO：当调用 read 函数阻塞读取数据时，如果此时内核缓冲区中没有数据，就阻塞等待，这就是阻塞 IO 模型。当内核缓冲区中有数据时，read 函数将读到数据，就会将数据拷贝到应用层缓冲区。
+ 非阻塞IO：非阻塞 read 数据时，当内核缓冲区中没有数据时，程序将不会一直阻塞在 read 函，read 函数会立即返回（EWOULDBLOCK）。此时程序员可以控制程序去做其他事情。在此期间，程序员要不断的轮询调用 read 查看是否有数据到来，直到有数据到来，read 才读取数据。（忙等待，CPU利用率低）
+ 信号驱动IO：此方式，需要应用程序注册回调函数，【主动】将数据从内核空间拷贝到应用空间，是一种【拉模式】
  +  首先，应用程序需要建立信号处理程序（当数据到来时，从内核中拷贝数据到应用层）
  +  然后，当内核中数据准备好的时候，会给应用程序发送一个信号，SIGIO
  +  最后，会触发注册的信号处理函数，将数据拷贝走
+ 异步IO/完成端口：可以看到，这种模式和“信号驱动 IO”最大的区别是：当内核中数据准备好后，是内核主动的将数据拷贝到应用空间（而不是由应用层自己注册的回调函数，将数据拷贝到应用层空间）。这是一种【推模式】。内核将数据拷贝到应用层空间后，将会通知你，你之后就可以处理接下来的逻辑了。
  + 当应用程序调用 aio_read 时，内核一方面去取数据报内容返回另一方面将程序控制权还给应用程序
  + 应用程序继续执行其他的任务，是一种非阻塞的状态
  + 当内核中的数据报就绪时，由内核主动地将数据报拷贝到应用程序中，返回 aio_read 中定义好的函数处理程序
+ 异步 IO 与同步 IO 的核心区别：异步 IO 无需自己负责读写，会自动将数据从内核空间拷贝到用户空间
+ IO多路复用：IO 多路复用有一个文件描述符集合，对这个集合中的每个元素进行循环监听，处理就绪的文件描述符。IO 多路复用属于阻塞 IO，但是可以对多个 fd 进行阻塞监听

## 进程，线程，协程

https://blog.csdn.net/daaikuaichuan/article/details/82951084

+ 进程：**有自己独立的地址空间，有自己的堆**，上级挂靠单位是操作系统。**操作系统会以进程为单位，分配系统资源（CPU时间片、内存等资源），进程是资源分配的最小单位**。

+ 线程：**有时被称为轻量级进程(Lightweight Process，LWP），是操作系统调度（CPU调度）执行的最小单位**。
+ 协程：是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。

### 区别与联系

- **一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程**；
- 资源分配给进程，同一进程的所有线程共享该进程的所有资源；
- 处理机分给线程，即**真正在处理机上运行的是线程**；
- 线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。
- 极高的执行效率：因为协程切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显；
- 不需要多线程的锁机制：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

## 什么是按需分页

在操作系统中，进程是以页为单位加载到内存中的，按需分页是一种虚拟内存的管理方式。在使用请求分页的系统中，只有在尝试访问页面所在的磁盘并且该页面尚未在内存中时，也就发生了缺页异常，操作系统才会将磁盘页面复制到内存中。

## 什么是 DMA

DMA 的中文名称是直接内存访问，它意味着 CPU 授予 I/O 模块权限在不涉及 CPU 的情况下读取或写入内存。也就是 DMA 可以不需要 CPU 的参与。这个过程由称为 DMA 控制器（DMAC）的芯片管理。由于 DMA 设备可以直接在内存之间传输数据，而不是使用 CPU 作为中介，因此可以缓解总线上的拥塞。DMA 通过允许 CPU 执行任务，同时 DMA 系统通过系统和内存总线传输数据来提高系统并发性。

## 文件删除

+ 一个进程打开一个文件，然后对该文件进行写入，还没写完，然后这个终端把这个文件删了，结果会怎么样

只有当进程结束后，文件上面的内容才会清空，并且删除文件

+ 那么进程退出了这个文件还在不在

不存在

+ 不存在那么linux是怎么实现的

当文件正在被进程打开时，执行 unlink() 只会删除文件名，并不会删除文件内容，只有所有打开此文件的进程都关闭此文件后（注意当进程退出时，会自动关闭所有打开的文件），文件内容才会被真正删除

Linux是通过link的数量来控制文件删除的，只有当一个文件不存在任何link的时候，这个文件才会被删除。一般来说，每个文件都有2个link计数器:i_count 和 i_nlink。

i_count:当前文件使用者（或被调用）的数量
i_nlink:介质连接的数量（硬链接的数量）

当一个文件被某一个进程引用时，对应i_count数就会增加；当创建文件的硬链接的时候，对应i_nlink数就会增加。

对于删除命令rm而言，实际就是减少磁盘引用计数i_nlink。如果该文件正在被某个进程调用，比如系统正在写入的日志文件，执行了rm操作，虽然目录看不到了日志文件，但没有真正删除这个文件，i_count并不为0，你通过df统计就发现磁盘还没有释放。**当只有i_nlink及i_count都为0的时候，这个文件才会真正被删除。**